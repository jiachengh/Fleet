From e3ac61424e53d7973c85496e410088aa5c14f316 Mon Sep 17 00:00:00 2001
From: jiachengh <jiacheng.huang@outlook.com>
Date: Wed, 4 May 2022 20:47:26 +0800
Subject: [PATCH 4/7] start removing bloom filter

Change-Id: Ib4ef1e9cf1e53290a93ec376a090111609028f84
Signed-off-by: jiachengh <jiacheng.huang@outlook.com>
---
 compiler/optimizing/code_generator.cc         |   4 +-
 compiler/optimizing/code_generator_arm64.cc   | 347 ++++++++++++-
 compiler/optimizing/code_generator_arm64.h    |  20 +
 .../instruction_simplifier_shared.cc          |   7 +
 dex2oat/dex2oat.cc                            |   5 +-
 libartbase/base/macros.h                      |  11 +-
 runtime/Android.bp                            |   5 +-
 runtime/arch/arm/entrypoints_init_arm.cc      |   9 +
 runtime/arch/arm64/entrypoints_init_arm64.cc  |   8 +
 runtime/class_linker_test.cc                  |  24 +-
 .../quick/quick_entrypoints_list.h            |   3 +
 runtime/fault_handler.cc                      |   9 +
 runtime/gc/collector/concurrent_copying-inl.h |  81 ++-
 runtime/gc/collector/concurrent_copying.cc    | 301 +++++++----
 runtime/gc/collector/concurrent_copying.h     |  15 +
 runtime/gc/heap.cc                            |  65 +--
 runtime/gc/heap.h                             |   6 +
 runtime/gc/space/image_space.cc               |  10 +-
 runtime/gc/space/region_space-inl.h           |  24 +
 runtime/gc/space/region_space.cc              | 442 +++++++++++++++-
 runtime/gc/space/region_space.h               | 162 +++++-
 runtime/interpreter/interpreter.cc            |   5 +-
 runtime/jiacheng_activity_manager.h           |   5 +-
 runtime/jiacheng_barrier.cc                   |  42 ++
 runtime/jiacheng_barrier.h                    |  16 +
 runtime/jiacheng_bloom_filter.h               | 133 +++++
 runtime/jiacheng_cheatsheet.cc                |  34 +-
 runtime/jiacheng_cheatsheet.h                 |  38 +-
 runtime/jiacheng_cold_space.cc                | 171 -------
 runtime/jiacheng_cold_space.h                 | 103 ----
 runtime/jiacheng_debug.cc                     | 472 ++++++++++++++++++
 runtime/jiacheng_debug.h                      |  63 +++
 runtime/jiacheng_hack.cc                      | 357 ++++---------
 runtime/jiacheng_hack.h                       |  54 +-
 runtime/jiacheng_profiler.cc                  | 187 ++++---
 runtime/jiacheng_profiler.h                   |  49 +-
 runtime/jiacheng_region.cc                    |  41 --
 runtime/jiacheng_region.h                     |  59 ---
 runtime/jiacheng_swapper.cc                   | 187 +++++++
 runtime/jiacheng_swapper.h                    |  61 +++
 runtime/jiacheng_utils.cc                     | 325 ++++--------
 runtime/jiacheng_utils.h                      |  65 +--
 runtime/jni/java_vm_ext.cc                    |   1 +
 runtime/jni/jni_internal.cc                   |   3 +
 runtime/mirror/array-inl.h                    |   9 +
 runtime/mirror/array.h                        |  18 +-
 runtime/mirror/class.cc                       |   1 -
 runtime/mirror/object-inl.h                   |   7 +
 runtime/mirror/object.cc                      |   9 +
 runtime/mirror/object.h                       |  31 +-
 runtime/native/dalvik_system_VMRuntime.cc     |  11 +-
 runtime/read_barrier-inl.h                    |  44 +-
 52 files changed, 2772 insertions(+), 1387 deletions(-)
 create mode 100644 runtime/jiacheng_barrier.cc
 create mode 100644 runtime/jiacheng_barrier.h
 create mode 100644 runtime/jiacheng_bloom_filter.h
 delete mode 100644 runtime/jiacheng_cold_space.cc
 delete mode 100644 runtime/jiacheng_cold_space.h
 create mode 100644 runtime/jiacheng_debug.cc
 create mode 100644 runtime/jiacheng_debug.h
 delete mode 100644 runtime/jiacheng_region.cc
 delete mode 100644 runtime/jiacheng_region.h
 create mode 100644 runtime/jiacheng_swapper.cc
 create mode 100644 runtime/jiacheng_swapper.h

diff --git a/compiler/optimizing/code_generator.cc b/compiler/optimizing/code_generator.cc
index 2bbb570c8d..576f18f5cb 100644
--- a/compiler/optimizing/code_generator.cc
+++ b/compiler/optimizing/code_generator.cc
@@ -497,9 +497,11 @@ void CodeGenerator::InitializeCodeGeneration(size_t number_of_spill_slots,
 void CodeGenerator::CreateCommonInvokeLocationSummary(
     HInvoke* invoke, InvokeDexCallingConventionVisitor* visitor) {
   ArenaAllocator* allocator = invoke->GetBlock()->GetGraph()->GetAllocator();
+  // jiacheng start
   LocationSummary* locations = new (allocator) LocationSummary(invoke,
                                                                LocationSummary::kCallOnMainOnly);
-
+  // LocationSummary* locations = new (allocator) LocationSummary(invoke, LocationSummary::kCallOnMainAndSlowPath, true);
+  // jiacheng end
   for (size_t i = 0; i < invoke->GetNumberOfArguments(); i++) {
     HInstruction* input = invoke->InputAt(i);
     locations->SetInAt(i, visitor->GetNextLocation(input->GetType()));
diff --git a/compiler/optimizing/code_generator_arm64.cc b/compiler/optimizing/code_generator_arm64.cc
index 3086882678..99287cf900 100644
--- a/compiler/optimizing/code_generator_arm64.cc
+++ b/compiler/optimizing/code_generator_arm64.cc
@@ -840,6 +840,42 @@ class ReadBarrierForRootSlowPathARM64 : public SlowPathCodeARM64 {
   DISALLOW_COPY_AND_ASSIGN(ReadBarrierForRootSlowPathARM64);
 };
 
+// jiacheng start
+class JiachengBarrierSlowPathARM64 : public SlowPathCodeARM64 {
+ public:
+  JiachengBarrierSlowPathARM64(HInstruction* instruction, Location obj)
+      : SlowPathCodeARM64(instruction), obj_(obj) {
+  }
+
+  void EmitNativeCode(CodeGenerator* codegen) override {
+    CodeGeneratorARM64* arm64_codegen = down_cast<CodeGeneratorARM64*>(codegen);
+    LocationSummary* locations = instruction_->GetLocations();
+    DataType::Type type = DataType::Type::kUint64;
+    
+    __ Bind(GetEntryLabel());
+    SaveLiveRegisters(codegen, locations);
+
+    InvokeRuntimeCallingConvention calling_convention;
+    arm64_codegen->MoveLocation(LocationFrom(calling_convention.GetRegisterAt(0)), obj_, type);
+    arm64_codegen->InvokeRuntime(kQuickJiachengBarrier,
+                                 instruction_,
+                                 instruction_->GetDexPc(),
+                                 this);
+    RestoreLiveRegisters(codegen, locations);
+    __ B(GetExitLabel());
+  }
+
+  bool IsFatal() const override { return true; }
+
+  const char* GetDescription() const override { return "JiachengBarrierSlowPathARM64"; }
+
+ private:
+  const Location obj_;
+
+  DISALLOW_COPY_AND_ASSIGN(JiachengBarrierSlowPathARM64);
+};
+// jiacheng end
+
 #undef __
 
 Location InvokeDexCallingConventionVisitorARM64::GetNextLocation(DataType::Type type) {
@@ -1834,13 +1870,20 @@ void LocationsBuilderARM64::HandleFieldGet(HInstruction* instruction,
 
   bool object_field_get_with_read_barrier =
       kEmitCompilerReadBarrier && (instruction->GetType() == DataType::Type::kReference);
-  LocationSummary* locations =
-      new (GetGraph()->GetAllocator()) LocationSummary(instruction,
-                                                       object_field_get_with_read_barrier
-                                                           ? LocationSummary::kCallOnSlowPath
-                                                           : LocationSummary::kNoCall);
+  // jiacheng start
+  // LocationSummary* locations =
+  //     new (GetGraph()->GetAllocator()) LocationSummary(instruction,
+  //                                                      object_field_get_with_read_barrier
+  //                                                          ? LocationSummary::kCallOnSlowPath
+  //                                                          : LocationSummary::kNoCall);
+  LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kCallOnSlowPath);
+  // jiacheng end
+
   if (object_field_get_with_read_barrier && kUseBakerReadBarrier) {
-    locations->SetCustomSlowPathCallerSaves(RegisterSet::Empty());  // No caller-save registers.
+    // jiacheng start
+    // locations->SetCustomSlowPathCallerSaves(RegisterSet::Empty());  // No caller-save registers.
+    // jiacheng end
+
     // We need a temporary register for the read barrier load in
     // CodeGeneratorARM64::GenerateFieldLoadWithBakerReadBarrier()
     // only if the field is volatile or the offset is too big.
@@ -1856,6 +1899,7 @@ void LocationsBuilderARM64::HandleFieldGet(HInstruction* instruction,
     // The output overlaps for an object field get when read barriers
     // are enabled: we do not want the load to overwrite the object's
     // location, as we need it to emit the read barrier.
+
     locations->SetOut(
         Location::RequiresRegister(),
         object_field_get_with_read_barrier ? Location::kOutputOverlap : Location::kNoOutputOverlap);
@@ -1873,6 +1917,10 @@ void InstructionCodeGeneratorARM64::HandleFieldGet(HInstruction* instruction,
   DataType::Type load_type = instruction->GetType();
   MemOperand field = HeapOperand(InputRegisterAt(instruction, 0), field_info.GetFieldOffset());
 
+  // jiacheng start
+  codegen_->GenerateJiachengBarrier(instruction, base_loc);
+  // jiacheng end
+
   if (kEmitCompilerReadBarrier && kUseBakerReadBarrier &&
       load_type == DataType::Type::kReference) {
     // Object FieldGet with Baker's read barrier case.
@@ -1914,8 +1962,13 @@ void InstructionCodeGeneratorARM64::HandleFieldGet(HInstruction* instruction,
 }
 
 void LocationsBuilderARM64::HandleFieldSet(HInstruction* instruction) {
+  // jiacheng start
+  // LocationSummary* locations =
+  //     new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kNoCall);
   LocationSummary* locations =
-      new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kNoCall);
+      new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kCallOnSlowPath);
+  // jiacheng end
+
   locations->SetInAt(0, Location::RequiresRegister());
   if (IsConstantZeroBitPattern(instruction->InputAt(1))) {
     locations->SetInAt(1, Location::ConstantLocation(instruction->InputAt(1)->AsConstant()));
@@ -1937,6 +1990,10 @@ void InstructionCodeGeneratorARM64::HandleFieldSet(HInstruction* instruction,
   Offset offset = field_info.GetFieldOffset();
   DataType::Type field_type = field_info.GetFieldType();
 
+  // jiacheng start
+  codegen_->GenerateJiachengBarrier(instruction, LocationFrom(obj));
+  // jiacheng end
+  
   {
     // We use a block to end the scratch scope before the write barrier, thus
     // freeing the temporary registers so they can be used in `MarkGCCard`.
@@ -2302,13 +2359,19 @@ void InstructionCodeGeneratorARM64::VisitMultiplyAccumulate(HMultiplyAccumulate*
 void LocationsBuilderARM64::VisitArrayGet(HArrayGet* instruction) {
   bool object_array_get_with_read_barrier =
       kEmitCompilerReadBarrier && (instruction->GetType() == DataType::Type::kReference);
-  LocationSummary* locations =
-      new (GetGraph()->GetAllocator()) LocationSummary(instruction,
-                                                       object_array_get_with_read_barrier
-                                                           ? LocationSummary::kCallOnSlowPath
-                                                           : LocationSummary::kNoCall);
+  // jiacheng start
+  // LocationSummary* locations =
+  //     new (GetGraph()->GetAllocator()) LocationSummary(instruction,
+  //                                                      object_array_get_with_read_barrier
+  //                                                          ? LocationSummary::kCallOnSlowPath
+  //                                                          : LocationSummary::kNoCall);
+  LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kCallOnSlowPath);
+  // jiacheng end
+
   if (object_array_get_with_read_barrier && kUseBakerReadBarrier) {
-    locations->SetCustomSlowPathCallerSaves(RegisterSet::Empty());  // No caller-save registers.
+    // jiacheng start
+    // locations->SetCustomSlowPathCallerSaves(RegisterSet::Empty());  // No caller-save registers.
+    // jiacheng end
     if (instruction->GetIndex()->IsConstant()) {
       // Array loads with constant index are treated as field loads.
       // We need a temporary register for the read barrier load in
@@ -2353,6 +2416,10 @@ void InstructionCodeGeneratorARM64::VisitArrayGet(HArrayGet* instruction) {
   MacroAssembler* masm = GetVIXLAssembler();
   UseScratchRegisterScope temps(masm);
 
+  // jiacheng start
+  codegen_->GenerateJiachengBarrier(instruction, LocationFrom(obj));
+  // jiacheng end
+
   // The non-Baker read barrier instrumentation of object ArrayGet instructions
   // does not support the HIntermediateAddress instruction.
   DCHECK(!((type == DataType::Type::kReference) &&
@@ -2474,7 +2541,11 @@ void InstructionCodeGeneratorARM64::VisitArrayGet(HArrayGet* instruction) {
 }
 
 void LocationsBuilderARM64::VisitArrayLength(HArrayLength* instruction) {
-  LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction);
+  // jiacheng start
+  // LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction);
+  LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kCallOnSlowPath);
+  // jiacheng end
+
   locations->SetInAt(0, Location::RequiresRegister());
   locations->SetOut(Location::RequiresRegister(), Location::kNoOutputOverlap);
 }
@@ -2482,6 +2553,12 @@ void LocationsBuilderARM64::VisitArrayLength(HArrayLength* instruction) {
 void InstructionCodeGeneratorARM64::VisitArrayLength(HArrayLength* instruction) {
   uint32_t offset = CodeGenerator::GetArrayLengthOffset(instruction);
   vixl::aarch64::Register out = OutputRegister(instruction);
+  
+  // jiacheng start
+  Register obj = InputRegisterAt(instruction, 0);
+  codegen_->GenerateJiachengBarrier(instruction, LocationFrom(obj));
+  // jiacheng end
+
   {
     // Ensure that between load and MaybeRecordImplicitNullCheck there are no pools emitted.
     EmissionCheckScope guard(GetVIXLAssembler(), kMaxMacroInstructionSizeInBytes);
@@ -2497,12 +2574,16 @@ void InstructionCodeGeneratorARM64::VisitArrayLength(HArrayLength* instruction)
 void LocationsBuilderARM64::VisitArraySet(HArraySet* instruction) {
   DataType::Type value_type = instruction->GetComponentType();
 
+
+  // jiacheng start
   bool may_need_runtime_call_for_type_check = instruction->NeedsTypeCheck();
   LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(
       instruction,
       may_need_runtime_call_for_type_check ?
           LocationSummary::kCallOnSlowPath :
           LocationSummary::kNoCall);
+  // LocationSummary* locations = new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kCallOnSlowPath);
+  // jiacheng end
   locations->SetInAt(0, Location::RequiresRegister());
   locations->SetInAt(1, Location::RegisterOrConstant(instruction->InputAt(1)));
   if (IsConstantZeroBitPattern(instruction->InputAt(2))) {
@@ -2529,6 +2610,11 @@ void InstructionCodeGeneratorARM64::VisitArraySet(HArraySet* instruction) {
   MemOperand destination = HeapOperand(array);
   MacroAssembler* masm = GetVIXLAssembler();
 
+  // jiacheng start
+  // codegen_->GenerateJiachengBarrier(instruction, LocationFrom(array));
+  // codegen_->GenerateJiachengBarrierRaw(instruction, LocationFrom(array));
+  // jiacheng end
+
   if (!needs_write_barrier) {
     DCHECK(!may_need_runtime_call_for_type_check);
     if (index.IsConstant()) {
@@ -3982,6 +4068,10 @@ void InstructionCodeGeneratorARM64::VisitInvokeInterface(HInvokeInterface* invok
   // Ensure that between load and MaybeRecordImplicitNullCheck there are no pools emitted.
   if (receiver.IsStackSlot()) {
     __ Ldr(temp.W(), StackOperandFrom(receiver));
+    // jiacheng start
+    // codegen_->GenerateJiachengBarrier(invoke, LocationFrom(temp));
+    // codegen_->GenerateJiachengBarrierRaw(invoke, LocationFrom(temp));
+    // jiacheng end
     {
       EmissionCheckScope guard(GetVIXLAssembler(), kMaxMacroInstructionSizeInBytes);
       // /* HeapReference<Class> */ temp = temp->klass_
@@ -3989,6 +4079,10 @@ void InstructionCodeGeneratorARM64::VisitInvokeInterface(HInvokeInterface* invok
       codegen_->MaybeRecordImplicitNullCheck(invoke);
     }
   } else {
+    // jiacheng start
+    // codegen_->GenerateJiachengBarrier(invoke, receiver);
+    // codegen_->GenerateJiachengBarrierRaw(invoke, receiver);
+    // jiacheng end
     EmissionCheckScope guard(GetVIXLAssembler(), kMaxMacroInstructionSizeInBytes);
     // /* HeapReference<Class> */ temp = receiver->klass_
     __ Ldr(temp.W(), HeapOperandFrom(receiver, class_offset));
@@ -4007,6 +4101,12 @@ void InstructionCodeGeneratorARM64::VisitInvokeInterface(HInvokeInterface* invok
       MemOperand(temp, mirror::Class::ImtPtrOffset(kArm64PointerSize).Uint32Value()));
   uint32_t method_offset = static_cast<uint32_t>(ImTable::OffsetOfElement(
       invoke->GetImtIndex(), kArm64PointerSize));
+
+  // jiacheng start
+  // codegen_->GenerateJiachengBarrier(invoke, LocationFrom(temp));
+  // codegen_->GenerateJiachengBarrierRaw(invoke, LocationFrom(temp));
+  // jiacheng end
+
   // temp = temp->GetImtEntryAt(method_offset);
   __ Ldr(temp, MemOperand(temp, method_offset));
   // lr = temp->GetEntryPoint();
@@ -4167,6 +4267,11 @@ void CodeGeneratorARM64::GenerateVirtualCall(
   Offset entry_point = ArtMethod::EntryPointFromQuickCompiledCodeOffset(kArm64PointerSize);
 
   DCHECK(receiver.IsRegister());
+  
+  // jiacheng start
+  // GenerateJiachengBarrier(LocationFrom(receiver));
+  // codegen_->GenerateJiachengBarrierRaw(invoke, LocationFrom(receiver));
+  // jiacheng end
 
   {
     // Ensure that between load and MaybeRecordImplicitNullCheck there are no pools emitted.
@@ -4182,6 +4287,12 @@ void CodeGeneratorARM64::GenerateVirtualCall(
   // intact/accessible until the end of the marking phase (the
   // concurrent copying collector may not in the future).
   GetAssembler()->MaybeUnpoisonHeapReference(temp.W());
+
+  // jiacheng start
+  // GenerateJiachengBarrier(LocationFrom(temp));
+  // codegen_->GenerateJiachengBarrierRaw(invoke, LocationFrom(temp));
+  // jiacheng end
+
   // temp = temp->GetMethodAt(method_offset);
   __ Ldr(temp, MemOperand(temp, method_offset));
   // lr = temp->GetEntryPoint();
@@ -5704,6 +5815,12 @@ void InstructionCodeGeneratorARM64::GenerateReferenceLoadOneRegister(
     ReadBarrierOption read_barrier_option) {
   DataType::Type type = DataType::Type::kReference;
   Register out_reg = RegisterFrom(out, type);
+
+  // jiacheng start
+  // codegen_->GenerateJiachengBarrier(LocationFrom(out_reg));
+  // codegen_->GenerateJiachengBarrierRaw(instruction, LocationFrom(out_reg));
+  // jiacheng end
+  
   if (read_barrier_option == kWithReadBarrier) {
     CHECK(kEmitCompilerReadBarrier);
     if (kUseBakerReadBarrier) {
@@ -5745,6 +5862,12 @@ void InstructionCodeGeneratorARM64::GenerateReferenceLoadTwoRegisters(
   DataType::Type type = DataType::Type::kReference;
   Register out_reg = RegisterFrom(out, type);
   Register obj_reg = RegisterFrom(obj, type);
+
+  // jiacheng start
+  // codegen_->GenerateJiachengBarrier(LocationFrom(obj_reg));
+  // codegen_->GenerateJiachengBarrierRaw(instruction, LocationFrom(obj_reg));
+  // jiacheng end
+
   if (read_barrier_option == kWithReadBarrier) {
     CHECK(kEmitCompilerReadBarrier);
     if (kUseBakerReadBarrier) {
@@ -5780,6 +5903,12 @@ void CodeGeneratorARM64::GenerateGcRootFieldLoad(
     ReadBarrierOption read_barrier_option) {
   DCHECK(fixup_label == nullptr || offset == 0u);
   Register root_reg = RegisterFrom(root, DataType::Type::kReference);
+
+  // jiacheng start
+  // GenerateJiachengBarrier(LocationFrom(obj));
+  // codegen_->GenerateJiachengBarrierRaw(instruction, LocationFrom(obj));
+  // jiacheng end
+
   if (read_barrier_option == kWithReadBarrier) {
     DCHECK(kEmitCompilerReadBarrier);
     if (kUseBakerReadBarrier) {
@@ -6116,6 +6245,196 @@ void CodeGeneratorARM64::GenerateReadBarrierForRootSlow(HInstruction* instructio
   __ Bind(slow_path->GetExitLabel());
 }
 
+// jiacheng start
+void CodeGeneratorARM64::GenerateJiachengBarrier(HInstruction* instruction, Location obj) {
+  SlowPathCodeARM64* slow_path = new (GetScopedAllocator()) JiachengBarrierSlowPathARM64(instruction, obj);
+  AddSlowPath(slow_path);
+
+  __ B(slow_path->GetEntryLabel());
+  __ Bind(slow_path->GetExitLabel());
+}
+
+void CodeGeneratorARM64::GenerateJiachengBarrierRaw(HInstruction* instruction, Location obj) {
+  // UseScratchRegisterScope temps(GetVIXLAssembler());
+  vixl::aarch64::Label doneLabel;
+
+  // Register temp = temps.AcquireX();
+  // CHECK(temp.GetCode() != 0);
+  std::vector<CPURegister> registersToMaybeSave;
+  registersToMaybeSave.push_back(RegisterFrom(obj, DataType::Type::kReference));
+  LocationSummary* locations = instruction->GetLocations();
+  std::vector<CPURegister> registersToSave = IdentifyRegistersToSave(registersToMaybeSave,
+                                                                     locations);
+  GenerateSaveRegisters(registersToSave);
+  DataType::Type type = DataType::Type::kReference;
+  InvokeRuntimeCallingConvention callingConvention;
+  MoveLocation(LocationFrom(callingConvention.GetRegisterAt(0)), obj, type);
+  int32_t entryPointOffset = QUICK_ENTRY_POINT(pJiachengBarrier);
+  __ Ldr(lr, MemOperand(tr, entryPointOffset));
+  __ Blr(lr);
+  GenerateRestoreRegisters(registersToSave);
+
+  __ Bind(&doneLabel);
+}
+
+std::vector<vixl::aarch64::CPURegister> CodeGeneratorARM64::IdentifyRegistersToSave(
+                                    const std::vector<vixl::aarch64::CPURegister> & registersToMaybeSave,
+                                    LocationSummary * locations) {
+  std::set<int> coreRegCodes; 
+  std::set<int> fpRegCodes;   
+
+  for (size_t i = 0; i < registersToMaybeSave.size(); i++) {
+    CPURegister reg = registersToMaybeSave[i];
+    CHECK(reg.IsRegister() || reg.IsFPRegister());
+    int artCode = helpers::ARTRegCodeFromVIXL(reg.GetCode());
+    if (reg.IsRegister() && !IsCoreCalleeSaveRegister(artCode)) {
+      coreRegCodes.insert(reg.GetCode());
+    }
+    else if (reg.IsFPRegister() && !IsFloatingPointCalleeSaveRegister(artCode)) {
+      fpRegCodes.insert(reg.GetCode());
+    }
+  }
+
+  RegisterSet * liveRegisterSet = locations->GetLiveRegisters();
+  for (size_t i = 0; i < GetNumberOfCoreRegisters(); i++) {
+    if (!IsCoreCalleeSaveRegister(i) && liveRegisterSet->ContainsCoreRegister(i)) {
+      coreRegCodes.insert(i);
+    }
+  }
+  for (size_t i = 0; i < GetNumberOfFloatingPointRegisters(); i++) {
+    if (   !IsFloatingPointCalleeSaveRegister(i)
+        && liveRegisterSet->ContainsFloatingPointRegister(i)) {
+      fpRegCodes.insert(i);
+    }
+  }
+
+  for (int i = 0; i < 8; i++) {
+    coreRegCodes.insert(i);
+  }
+  for (int i = 0; i < 8; i++) {
+    fpRegCodes.insert(i);
+  }
+
+  std::vector<CPURegister> registersToSave;
+
+  for (auto it = coreRegCodes.begin(); it != coreRegCodes.end(); it++) {
+    registersToSave.push_back(Register::GetXRegFromCode(*it));
+  }
+  for (auto it = fpRegCodes.begin(); it != fpRegCodes.end(); it++) {
+    registersToSave.push_back(VRegister::GetDRegFromCode(*it));
+  }
+  return registersToSave;
+}
+
+const int REGISTER_WIDTH = 8;
+
+int CodeGeneratorARM64::ComputeStackGrowthSize(const std::vector<vixl::aarch64::CPURegister> & registersToSave) {
+  int stackGrowthSize = 0;
+  if (registersToSave.size() > 0) {
+    stackGrowthSize = registersToSave.size() * REGISTER_WIDTH;
+    if (stackGrowthSize % 16 > 0) {
+      stackGrowthSize = stackGrowthSize + (16 - stackGrowthSize % 16);
+    }
+  }
+  return stackGrowthSize;
+}
+
+void CodeGeneratorARM64::GetTypedRegisterLists(const std::vector<vixl::aarch64::CPURegister> & registersToSave,
+                            std::vector<vixl::aarch64::Register> & coreRegisters,
+                            std::vector<vixl::aarch64::VRegister> & vRegisters) {
+  CHECK(coreRegisters.size() == 0);
+  CHECK(vRegisters.size() == 0);
+  for (size_t i = 0; i < registersToSave.size(); i++) {
+    CPURegister reg = registersToSave[i];
+    if (reg.IsRegister()) {
+      coreRegisters.push_back(Register(reg));
+    }
+    else if (reg.IsVRegister()) {
+      vRegisters.push_back(VRegister(reg));
+    }
+  }
+  CHECK(coreRegisters.size() + vRegisters.size() == registersToSave.size());
+}
+
+void CodeGeneratorARM64::GenerateSaveRegisters(const std::vector<vixl::aarch64::CPURegister> & registersToSave) {
+  int stackGrowthSize = ComputeStackGrowthSize(registersToSave);
+
+  std::vector<Register> coreRegisters;
+  std::vector<VRegister> vRegisters;
+  GetTypedRegisterLists(registersToSave, coreRegisters, vRegisters);
+
+  if (registersToSave.size() > 0) {
+    __ Sub(sp, sp, stackGrowthSize);
+    size_t i = 0; // index in current register list
+    size_t memoryOffset = 0; // current offset from SP, in bytes
+    while (i < coreRegisters.size()) {
+      if (i < coreRegisters.size() - 1) {
+        __ Stp(coreRegisters[i], coreRegisters[i + 1], MemOperand(sp, memoryOffset));
+        i += 2;
+        memoryOffset += 2 * REGISTER_WIDTH;
+      }
+      else {
+        __ Str(coreRegisters[i], MemOperand(sp, memoryOffset));
+        i++;
+        memoryOffset += REGISTER_WIDTH;
+      }
+    }
+    i = 0;
+    while (i < vRegisters.size()) {
+      if (i < vRegisters.size() - 1) {
+        __ Stp(vRegisters[i], vRegisters[i + 1], MemOperand(sp, memoryOffset));
+        i += 2;
+        memoryOffset += 2 * REGISTER_WIDTH;
+      }
+      else {
+        __ Str(vRegisters[i], MemOperand(sp, memoryOffset));
+        i++;
+        memoryOffset += REGISTER_WIDTH;
+      }
+    }
+  }
+}
+
+void CodeGeneratorARM64::GenerateRestoreRegisters(const std::vector<vixl::aarch64::CPURegister> & savedRegisters) {
+  int stackGrowthSize = ComputeStackGrowthSize(savedRegisters);
+  std::vector<Register> coreRegisters;
+  std::vector<VRegister> vRegisters;
+  GetTypedRegisterLists(savedRegisters, coreRegisters, vRegisters);
+  if (savedRegisters.size() > 0) {
+    size_t i = 0; // index in current register list
+    size_t memoryOffset = 0; // current offset from SP, in bytes
+    while (i < coreRegisters.size()) {
+      if (i < coreRegisters.size() - 1) {
+        __ Ldp(coreRegisters[i], coreRegisters[i + 1], MemOperand(sp, memoryOffset));
+        i += 2;
+        memoryOffset += 2 * REGISTER_WIDTH;
+      }
+      else {
+        __ Ldr(coreRegisters[i], MemOperand(sp, memoryOffset));
+        i++;
+        memoryOffset += REGISTER_WIDTH;
+      }
+    }
+    i = 0;
+    while (i < vRegisters.size()) {
+      if (i < vRegisters.size() - 1) {
+        __ Ldp(vRegisters[i], vRegisters[i + 1], MemOperand(sp, memoryOffset));
+        i += 2;
+        memoryOffset += 2 * REGISTER_WIDTH;
+      }
+      else {
+        __ Ldr(vRegisters[i], MemOperand(sp, memoryOffset));
+        i++;
+        memoryOffset += REGISTER_WIDTH;
+      }
+    }
+    __ Add(sp, sp, stackGrowthSize);
+  }
+}
+
+
+// jiacheng end
+
 void LocationsBuilderARM64::VisitClassTableGet(HClassTableGet* instruction) {
   LocationSummary* locations =
       new (GetGraph()->GetAllocator()) LocationSummary(instruction, LocationSummary::kNoCall);
diff --git a/compiler/optimizing/code_generator_arm64.h b/compiler/optimizing/code_generator_arm64.h
index ada5742fc0..a996557bc1 100644
--- a/compiler/optimizing/code_generator_arm64.h
+++ b/compiler/optimizing/code_generator_arm64.h
@@ -765,6 +765,26 @@ class CodeGeneratorARM64 : public CodeGenerator {
   // artReadBarrierForRootSlow.
   void GenerateReadBarrierForRootSlow(HInstruction* instruction, Location out, Location root);
 
+  // jiacheng start
+  void GenerateJiachengBarrier(HInstruction* instruction, Location obj);
+
+  void GenerateJiachengBarrierRaw(HInstruction* instruction, Location obj);
+
+  std::vector<vixl::aarch64::CPURegister> IdentifyRegistersToSave(
+                                     const std::vector<vixl::aarch64::CPURegister> & registersToMaybeSave,
+                                     LocationSummary * locations);
+
+  int ComputeStackGrowthSize(const std::vector<vixl::aarch64::CPURegister> & registersToSave);
+
+  void GetTypedRegisterLists(const std::vector<vixl::aarch64::CPURegister> & registersToSave,
+                             std::vector<vixl::aarch64::Register> & coreRegisters,
+                             std::vector<vixl::aarch64::VRegister> & vRegisters);
+
+  void GenerateSaveRegisters(const std::vector<vixl::aarch64::CPURegister> & registersToSave);
+  void GenerateRestoreRegisters(const std::vector<vixl::aarch64::CPURegister> & savedRegisters);
+
+  // jiacheng end
+
   void GenerateNop() override;
 
   void GenerateImplicitNullCheck(HNullCheck* instruction) override;
diff --git a/compiler/optimizing/instruction_simplifier_shared.cc b/compiler/optimizing/instruction_simplifier_shared.cc
index 0f30f662cd..e8f4e9644d 100644
--- a/compiler/optimizing/instruction_simplifier_shared.cc
+++ b/compiler/optimizing/instruction_simplifier_shared.cc
@@ -233,6 +233,13 @@ bool TryExtractArrayAccessAddress(HInstruction* access,
                                   HInstruction* array,
                                   HInstruction* index,
                                   size_t data_offset) {
+  // jiacheng start
+  bool optimizationDisabled = true;
+  if (optimizationDisabled) {
+    return false;
+  }
+  // jiacheng end
+  
   if (index->IsConstant() ||
       (index->IsBoundsCheck() && index->AsBoundsCheck()->GetIndex()->IsConstant())) {
     // When the index is a constant all the addressing can be fitted in the
diff --git a/dex2oat/dex2oat.cc b/dex2oat/dex2oat.cc
index bd9019a81c..278523ec9a 100644
--- a/dex2oat/dex2oat.cc
+++ b/dex2oat/dex2oat.cc
@@ -2241,10 +2241,7 @@ class Dex2Oat final {
   }
 
   bool UseProfile() const {
-    // jiacheng start
-    // return profile_file_fd_ != -1 || !profile_file_.empty();
-    return false;
-    // jiacheng end
+    return profile_file_fd_ != -1 || !profile_file_.empty();
   }
 
   bool DoProfileGuidedOptimizations() const {
diff --git a/libartbase/base/macros.h b/libartbase/base/macros.h
index 323fa4e61b..82bd68bc37 100644
--- a/libartbase/base/macros.h
+++ b/libartbase/base/macros.h
@@ -67,11 +67,14 @@ template<typename T> ART_FRIEND_TEST(test_set_name, individual_test)
 #define APPEND_TOKENS_AFTER_EVAL_2(a, b) a ## b
 #define APPEND_TOKENS_AFTER_EVAL(a, b) APPEND_TOKENS_AFTER_EVAL_2(a, b)
 
-#ifndef NDEBUG
-#define ALWAYS_INLINE
-#else
+// jiacheng start
+// #ifndef NDEBUG
+// #define ALWAYS_INLINE
+// #else
+// #define ALWAYS_INLINE  __attribute__ ((always_inline))
+// #endif
 #define ALWAYS_INLINE  __attribute__ ((always_inline))
-#endif
+// jiacheng end
 
 // clang doesn't like attributes on lambda functions. It would be nice to say:
 //   #define ALWAYS_INLINE_LAMBDA ALWAYS_INLINE
diff --git a/runtime/Android.bp b/runtime/Android.bp
index 80db5b4e86..847cd4e90d 100644
--- a/runtime/Android.bp
+++ b/runtime/Android.bp
@@ -107,12 +107,13 @@ libart_cc_defaults {
         "java_frame_root_info.cc",
 // jiacheng start ------------------------------------
         "jiacheng_cheatsheet.cc",
-        "jiacheng_cold_space.cc",
         "jiacheng_hack.cc",
-        "jiacheng_region.cc",
         "jiacheng_activity_manager.cc",
         "jiacheng_utils.cc",
         "jiacheng_profiler.cc",
+        "jiacheng_swapper.cc",
+        "jiacheng_debug.cc",
+        "jiacheng_barrier.cc",
 // jiacheng end --------------------------------------
         "jdwp/jdwp_event.cc",
         "jdwp/jdwp_expand_buf.cc",
diff --git a/runtime/arch/arm/entrypoints_init_arm.cc b/runtime/arch/arm/entrypoints_init_arm.cc
index c1a03abd96..b98670a614 100644
--- a/runtime/arch/arm/entrypoints_init_arm.cc
+++ b/runtime/arch/arm/entrypoints_init_arm.cc
@@ -29,6 +29,10 @@
 #include "entrypoints/runtime_asm_entrypoints.h"
 #include "interpreter/interpreter.h"
 
+// jiacheng start
+#include "jiacheng_barrier.h"
+// jiacheng end
+
 namespace art {
 
 // Cast entrypoints.
@@ -78,6 +82,7 @@ extern "C" int __aeabi_idivmod(int32_t, int32_t);  // [DIV|REM]_INT[_2ADDR|_LIT8
 extern "C" int64_t __aeabi_ldivmod(int64_t, int64_t);
 
 void UpdateReadBarrierEntrypoints(QuickEntryPoints* qpoints, bool is_active) {
+  
   qpoints->pReadBarrierMarkReg00 = is_active ? art_quick_read_barrier_mark_reg00 : nullptr;
   qpoints->pReadBarrierMarkReg01 = is_active ? art_quick_read_barrier_mark_reg01 : nullptr;
   qpoints->pReadBarrierMarkReg02 = is_active ? art_quick_read_barrier_mark_reg02 : nullptr;
@@ -196,6 +201,10 @@ void InitEntryPoints(JniEntryPoints* jpoints, QuickEntryPoints* qpoints) {
   qpoints->pReadBarrierMarkReg29 = nullptr;
   qpoints->pReadBarrierSlow = artReadBarrierSlow;
   qpoints->pReadBarrierForRootSlow = artReadBarrierForRootSlow;
+  
+  // jiacheng start
+  qpoints->pJiachengBarrier = jiacheng::JiachengBarrier;
+  // jiacheng end
 }
 
 }  // namespace art
diff --git a/runtime/arch/arm64/entrypoints_init_arm64.cc b/runtime/arch/arm64/entrypoints_init_arm64.cc
index 22f0c28f45..5d982c534d 100644
--- a/runtime/arch/arm64/entrypoints_init_arm64.cc
+++ b/runtime/arch/arm64/entrypoints_init_arm64.cc
@@ -29,6 +29,10 @@
 #include "entrypoints/runtime_asm_entrypoints.h"
 #include "interpreter/interpreter.h"
 
+// jiacheng start
+#include "jiacheng_barrier.h"
+// jiacheng end
+
 namespace art {
 
 // Cast entrypoints.
@@ -192,6 +196,10 @@ void InitEntryPoints(JniEntryPoints* jpoints, QuickEntryPoints* qpoints) {
   UpdateReadBarrierEntrypoints(qpoints, /*is_active=*/ false);
   qpoints->pReadBarrierSlow = artReadBarrierSlow;
   qpoints->pReadBarrierForRootSlow = artReadBarrierForRootSlow;
+
+  // jiacheng start
+  qpoints->pJiachengBarrier = jiacheng::JiachengBarrier;
+  // jiacheng end
 }
 
 }  // namespace art
diff --git a/runtime/class_linker_test.cc b/runtime/class_linker_test.cc
index 1a91abe1ed..f5fe0b70a6 100644
--- a/runtime/class_linker_test.cc
+++ b/runtime/class_linker_test.cc
@@ -149,7 +149,10 @@ class ClassLinkerTest : public CommonRuntimeTest {
     EXPECT_EQ(4U, JavaLangObject->NumDirectMethods());
     EXPECT_EQ(11U, JavaLangObject->NumVirtualMethods());
     if (!kUseBrooksReadBarrier) {
-      EXPECT_EQ(2U, JavaLangObject->NumInstanceFields());
+      // jiacheng start
+      // EXPECT_EQ(2U, JavaLangObject->NumInstanceFields());
+      EXPECT_EQ(4U, JavaLangObject->NumInstanceFields());
+      // jiacheng end
     } else {
       EXPECT_EQ(4U, JavaLangObject->NumInstanceFields());
     }
@@ -157,6 +160,18 @@ class ClassLinkerTest : public CommonRuntimeTest {
                  "shadow$_klass_");
     EXPECT_STREQ(JavaLangObject->GetInstanceField(1)->GetName(),
                  "shadow$_monitor_");
+    // jiacheng start
+    EXPECT_STREQ(JavaLangObject->GetInstanceField(2)->GetName(),
+                 "shadow$_z_padding_");
+    EXPECT_STREQ(JavaLangObject->GetInstanceField(3)->GetName(),
+                 "shadow$_z_zflags0_");
+    EXPECT_STREQ(JavaLangObject->GetInstanceField(4)->GetName(),
+                 "shadow$_z_zflags1_");
+    EXPECT_STREQ(JavaLangObject->GetInstanceField(5)->GetName(),
+                 "shadow$_z_zflags2_");
+    EXPECT_STREQ(JavaLangObject->GetInstanceField(6)->GetName(),
+                 "shadow$_z_zflags3_");
+    // jiacheng end
     if (kUseBrooksReadBarrier) {
       EXPECT_STREQ(JavaLangObject->GetInstanceField(2)->GetName(),
                    "shadow$_x_rb_ptr_");
@@ -566,6 +581,13 @@ struct ObjectOffsets : public CheckOffsets<mirror::Object> {
   ObjectOffsets() : CheckOffsets<mirror::Object>(false, "Ljava/lang/Object;") {
     addOffset(OFFSETOF_MEMBER(mirror::Object, klass_), "shadow$_klass_");
     addOffset(OFFSETOF_MEMBER(mirror::Object, monitor_), "shadow$_monitor_");
+    // jiacheng start
+    addOffset(OFFSETOF_MEMBER(mirror::Object, z_padding_), "shadow$_z_padding_");
+    addOffset(OFFSETOF_MEMBER(mirror::Object, z_zflags0_), "shadow$_z_zflags0_");
+    addOffset(OFFSETOF_MEMBER(mirror::Object, z_zflags1_), "shadow$_z_zflags1_");
+    addOffset(OFFSETOF_MEMBER(mirror::Object, z_zflags2_), "shadow$_z_zflags2_");
+    addOffset(OFFSETOF_MEMBER(mirror::Object, z_zflags3_), "shadow$_z_zflags3_");
+    // jiacheng end
 #ifdef USE_BROOKS_READ_BARRIER
     addOffset(OFFSETOF_MEMBER(mirror::Object, x_rb_ptr_), "shadow$_x_rb_ptr_");
     addOffset(OFFSETOF_MEMBER(mirror::Object, x_xpadding_), "shadow$_x_xpadding_");
diff --git a/runtime/entrypoints/quick/quick_entrypoints_list.h b/runtime/entrypoints/quick/quick_entrypoints_list.h
index 42b680e05a..57b555955c 100644
--- a/runtime/entrypoints/quick/quick_entrypoints_list.h
+++ b/runtime/entrypoints/quick/quick_entrypoints_list.h
@@ -202,6 +202,9 @@
   V(ReadBarrierMarkReg29, mirror::Object*, mirror::Object*) \
   V(ReadBarrierSlow, mirror::Object*, mirror::Object*, mirror::Object*, uint32_t) \
   V(ReadBarrierForRootSlow, mirror::Object*, GcRoot<mirror::Object>*) \
+  /* jiacheng start*/ \
+  V(JiachengBarrier, void, uint64_t) \
+  /* jiacheng end */ \
 \
 
 #endif  // ART_RUNTIME_ENTRYPOINTS_QUICK_QUICK_ENTRYPOINTS_LIST_H_
diff --git a/runtime/fault_handler.cc b/runtime/fault_handler.cc
index 5c2830d96b..a9ce5ad2cd 100644
--- a/runtime/fault_handler.cc
+++ b/runtime/fault_handler.cc
@@ -32,6 +32,10 @@
 #include "thread-current-inl.h"
 #include "verify_object-inl.h"
 
+// jiacheng start
+#include "jiacheng_hack.h"
+// jiacheng end
+
 namespace art {
 // Static fault manger object accessed by signal handler.
 FaultManager fault_manager;
@@ -207,6 +211,11 @@ static std::ostream& PrintSignalInfo(std::ostream& os, siginfo_t* info) {
 }
 
 bool FaultManager::HandleFault(int sig, siginfo_t* info, void* context) {
+  // jiacheng start
+  if (jiacheng::HandleFault(sig, info, context)) {
+    return true;
+  }
+  // jiacheng end
   if (VLOG_IS_ON(signals)) {
     PrintSignalInfo(VLOG_STREAM(signals) << "Handling fault:" << "\n", info);
   }
diff --git a/runtime/gc/collector/concurrent_copying-inl.h b/runtime/gc/collector/concurrent_copying-inl.h
index ecf7caed2f..c50a1a057c 100644
--- a/runtime/gc/collector/concurrent_copying-inl.h
+++ b/runtime/gc/collector/concurrent_copying-inl.h
@@ -29,8 +29,8 @@
 #include "mirror/object-readbarrier-inl.h"
 
 // jiacheng start  
-#include "jiacheng_cold_space.h"
 #include "jiacheng_hack.h"
+#include "jiacheng_profiler.h"
 // jiacheng end
 
 namespace art {
@@ -154,33 +154,25 @@ inline mirror::Object* ConcurrentCopying::Mark(Thread* const self,
     // are consulted. If they look like gray but aren't really, the
     // read barriers slow path can trigger when it shouldn't. To guard
     // against this, return here if the CC collector isn't running.
-
-    // jiacheng start
-    jiacheng::GCMarkTrigger(from_ref);
-    // jiacheng end
     return from_ref;
   }
   DCHECK(region_space_ != nullptr) << "Read barrier slow path taken when CC isn't running?";
   // jiahceng start -------------------------------------_
-    if (jiacheng::ColdSpace::Current()->HasAddress(from_ref)) {
-      // Mark在ColdSpace中的对象，把该对象标灰
-      // bool success = from_ref->AtomicSetReadBarrierState(ReadBarrier::WhiteState(), ReadBarrier::GrayState());
-      bool success = from_ref->AtomicSetReadBarrierState(ReadBarrier::NonGrayState(), ReadBarrier::GrayState());
-      if (success) {
-        PushOntoMarkStack(self, from_ref);
-      }
-      jiacheng::GCMarkTrigger(from_ref);
-      return from_ref;
-    }  else if (region_space_->HasAddress(from_ref)) {
-  // if (region_space_->HasAddress(from_ref)) {
+    // if (jiacheng::ColdSpace::Current()->HasAddress(from_ref)) {
+    //   // Mark在ColdSpace中的对象，把该对象标灰
+    //   // bool success = from_ref->AtomicSetReadBarrierState(ReadBarrier::WhiteState(), ReadBarrier::GrayState());
+    //   bool success = from_ref->AtomicSetReadBarrierState(ReadBarrier::NonGrayState(), ReadBarrier::GrayState());
+    //   if (success) {
+    //     PushOntoMarkStack(self, from_ref);
+    //   }
+    //   return from_ref;
+    // }  else if (region_space_->HasAddress(from_ref)) {
+  if (region_space_->HasAddress(from_ref)) {
   // jiacheng end -------------------------------------
     space::RegionSpace::RegionType rtype = region_space_->GetRegionTypeUnsafe(from_ref);
     switch (rtype) {
       case space::RegionSpace::RegionType::kRegionTypeToSpace:
         // It's already marked.
-        // jiacheng start
-        jiacheng::GCMarkTrigger(from_ref);
-        // jiacheng end
         return from_ref;
       case space::RegionSpace::RegionType::kRegionTypeFromSpace: {
         mirror::Object* to_ref = GetFwdPtr(from_ref);
@@ -188,16 +180,16 @@ inline mirror::Object* ConcurrentCopying::Mark(Thread* const self,
           // It isn't marked yet. Mark it by copying it to the to-space.
           to_ref = Copy(self, from_ref, holder, offset);
         }
+        // jiacheng start
+        jiacheng::Profiler* profiler = jiacheng::Profiler::Current();
+        if (to_ref != from_ref && profiler->TestInAccessWS(from_ref)) {
+          profiler->RecordAccessWS(to_ref);
+        }
+        // jiacheng end
         // The copy should either be in a to-space region, or in the
         // non-moving space, if it could not fit in a to-space region.
-        // jiacheng start
-        // DCHECK(region_space_->IsInToSpace(to_ref) || heap_->non_moving_space_->HasAddress(to_ref))
-        //     << "from_ref=" << from_ref << " to_ref=" << to_ref;
-        DCHECK(region_space_->IsInToSpace(to_ref) || heap_->non_moving_space_->HasAddress(to_ref) 
-               || jiacheng::ColdSpace::Current()->HasAddress(to_ref))
+        DCHECK(region_space_->IsInToSpace(to_ref) || heap_->non_moving_space_->HasAddress(to_ref))
             << "from_ref=" << from_ref << " to_ref=" << to_ref;
-        jiacheng::GCMarkTrigger(to_ref);
-        // jiacheng end
         return to_ref;
       }
       case space::RegionSpace::RegionType::kRegionTypeUnevacFromSpace: {
@@ -205,18 +197,19 @@ inline mirror::Object* ConcurrentCopying::Mark(Thread* const self,
           if (!kFromGCThread) {
             DCHECK(IsMarkedInUnevacFromSpace(from_ref)) << "Returning unmarked object to mutator";
           }
-          // jiacheng start
-          jiacheng::GCMarkTrigger(from_ref);
-          // jiacheng end
           return from_ref;
         }
-        // jiacheng start
-        // return MarkUnevacFromSpaceRegion(self, from_ref, region_space_bitmap_);
-        mirror::Object* temp_ref = MarkUnevacFromSpaceRegion(self, from_ref, region_space_bitmap_);
-        jiacheng::GCMarkTrigger(temp_ref);
-        // jiacheng end
-        return temp_ref;
+        return MarkUnevacFromSpaceRegion(self, from_ref, region_space_bitmap_);
+      }
+      // jiacheng start
+      case space::RegionSpace::RegionType::kRegionTypeColdToSpace: {
+        // Already marked
+        return from_ref;
+      }
+      case space::RegionSpace::RegionType::kRegionTypeColdSpace: {
+        return MarkColdSpaceRegion(self, from_ref, region_space_bitmap_);
       }
+      // jiacheng end
       default:
         // The reference is in an unused region. Remove memory protection from
         // the region space and log debugging information.
@@ -228,19 +221,9 @@ inline mirror::Object* ConcurrentCopying::Mark(Thread* const self,
     }
   } else {
     if (immune_spaces_.ContainsObject(from_ref)) {
-      // jiacheng start
-      // return MarkImmuneSpace<kGrayImmuneObject>(self, from_ref);
-      mirror::Object* temp_ref = MarkImmuneSpace<kGrayImmuneObject>(self, from_ref);
-      jiacheng::GCMarkTrigger(temp_ref);
-      return temp_ref;
-      // jiacheng end
+      return MarkImmuneSpace<kGrayImmuneObject>(self, from_ref);
     } else {
-      // jiacheng start
-      // return MarkNonMoving(self, from_ref, holder, offset);
-      mirror::Object* temp_ref = MarkNonMoving(self, from_ref, holder, offset);
-      jiacheng::GCMarkTrigger(temp_ref);
-      return temp_ref;
-      // jiacheng end
+      return MarkNonMoving(self, from_ref, holder, offset);
     }
   }
 }
@@ -274,9 +257,7 @@ inline mirror::Object* ConcurrentCopying::MarkFromReadBarrier(mirror::Object* fr
 }
 
 inline mirror::Object* ConcurrentCopying::GetFwdPtr(mirror::Object* from_ref) {
-  // jiacheng start
-  // DCHECK(region_space_->IsInFromSpace(from_ref));
-  // jiacheng end
+  DCHECK(region_space_->IsInFromSpace(from_ref));
   LockWord lw = from_ref->GetLockWord(false);
   if (lw.GetState() == LockWord::kForwardingAddress) {
     mirror::Object* fwd_ptr = reinterpret_cast<mirror::Object*>(lw.ForwardingAddress());
diff --git a/runtime/gc/collector/concurrent_copying.cc b/runtime/gc/collector/concurrent_copying.cc
index 335cdc98a4..b9d5ff1824 100644
--- a/runtime/gc/collector/concurrent_copying.cc
+++ b/runtime/gc/collector/concurrent_copying.cc
@@ -48,9 +48,8 @@
 #include "well_known_classes.h"
 
 // jiacheng start
-#include "jiacheng_cold_space.h"
-#include "jiacheng_activity_manager.h"
 #include "jiacheng_profiler.h"
+#include "jiacheng_utils.h"
 #include <iostream>
 // jiacheng end
 
@@ -74,6 +73,40 @@ static constexpr size_t kSweepArrayChunkFreeSize = 1024;
 // Verify that there are no missing card marks.
 static constexpr bool kVerifyNoMissingCardMarks = kIsDebugBuild;
 
+
+// jiacheng start
+class ConcurrentCopying::RegionRememberedObjectsVisitor {
+ public:
+  explicit RegionRememberedObjectsVisitor(ConcurrentCopying* cc) : collector_(cc) {}
+
+  ALWAYS_INLINE void operator()(mirror::Object* ref) const REQUIRES_SHARED(Locks::mutator_lock_) {
+    if (ref == nullptr) {
+      return;
+    }
+    if (!collector_->TestAndSetMarkBitForRef(ref)) {
+      collector_->PushOntoLocalMarkStack(ref);
+    }
+  }
+
+ private:
+  ConcurrentCopying* const collector_;
+};
+
+class ConcurrentCopying::RegionRememberedObjectsAsRootVisitor {
+ public:
+  explicit RegionRememberedObjectsAsRootVisitor(ConcurrentCopying* cc) : collector_(cc) {}
+
+  ALWAYS_INLINE mirror::Object* operator()(mirror::Object* ref) const REQUIRES_SHARED(Locks::mutator_lock_) {
+    LOG(INFO) << "jiacheng concurrent_copying.cc 1279 ref= " << size_t(ref);
+    return collector_->MarkObject(ref);
+  }
+
+ private:
+  ConcurrentCopying* const collector_;
+};
+// jiacheng end
+
+
 ConcurrentCopying::ConcurrentCopying(Heap* heap,
                                      bool young_gen,
                                      bool use_generational_cc,
@@ -202,16 +235,10 @@ void ConcurrentCopying::RunPhases() {
   {
     ReaderMutexLock mu(self, *Locks::mutator_lock_);
     InitializePhase();
-    // jiacheng start  -------------------
-    LOG(INFO) << "jiacheng concurrent_copying.cc 175 InitializePhase Pass" << std::flush;
-    // jiacheng end ----------------------
     // In case of forced evacuation, all regions are evacuated and hence no
     // need to compute live_bytes.
     if (use_generational_cc_ && !young_gen_ && !force_evacuate_all_) {
       MarkingPhase();
-    // jiacheng start  -------------------
-    LOG(INFO) << "jiacheng concurrent_copying.cc 195 MarkingPhase Pass" << std::flush;
-    // jiacheng end ----------------------
     }
   }
   if (kUseBakerReadBarrier && kGrayDirtyImmuneObjects) {
@@ -222,10 +249,19 @@ void ConcurrentCopying::RunPhases() {
     // the pause.
     ReaderMutexLock mu(self, *Locks::mutator_lock_);
     GrayAllDirtyImmuneObjects();
-    // jiacheng start  -------------------
-    LOG(INFO) << "jiacheng concurrent_copying.cc 187 GrayAllDirtyImmuneObjects Pass" << std::flush;
-    // jiacheng end ----------------------
   }
+  // jiacheng start
+  {
+    LOG(INFO) << "jiacheng concurrent_copying.cc 220";
+    ReaderMutexLock mu(self, *Locks::mutator_lock_);
+    RegionRememberedObjectsAsRootVisitor root_visitor(this);
+    region_space_->VisitRememberedObjectsAsRoot(root_visitor);
+    // TODO remove
+    RegionRememberedObjectsVisitor visitor(this);
+    region_space_->VisitRememberedObjects(visitor);
+  }
+  // jiacheng end
+
   FlipThreadRoots();
   {
     ReaderMutexLock mu(self, *Locks::mutator_lock_);
@@ -249,13 +285,7 @@ void ConcurrentCopying::RunPhases() {
     ReaderMutexLock mu(self, *Locks::mutator_lock_);
     ReclaimPhase();
   }
-  // jiacheng start  -------------------
-  LOG(INFO) << "jiacheng concurrent_copying.cc 219 ReclaimPhase Pass" << std::flush;
-  // jiacheng end ----------------------
   FinishPhase();
-  // jiacheng start  -------------------
-  LOG(INFO) << "jiacheng concurrent_copying.cc 223 FinishPhase Pass" << std::flush;
-  // jiacheng end ----------------------
   CHECK(is_active_);
   is_active_ = false;
   thread_running_gc_ = nullptr;
@@ -1379,6 +1409,19 @@ void ConcurrentCopying::MarkingPhase() {
   }
   // Capture thread roots
   CaptureThreadRootsForMarking();
+
+  // jiacheng start
+  {
+    TimingLogger::ScopedTiming split2("VisitRegionRememberedSet", GetTimings());
+    LOG(INFO) << "jiacheng concurrent_copying.cc 1394";
+    RegionRememberedObjectsAsRootVisitor root_visitor(this);
+    region_space_->VisitRememberedObjectsAsRoot(root_visitor);
+    // TODO remove
+    RegionRememberedObjectsVisitor visitor(this);
+    region_space_->VisitRememberedObjects(visitor);
+  }
+  // jiacheng end
+
   // Process mark stack
   ProcessMarkStackForMarkingAndComputeLiveBytes();
 
@@ -1822,11 +1865,9 @@ void ConcurrentCopying::PushOntoMarkStack(Thread* const self, mirror::Object* to
         << " self->gc_marking=" << self->GetIsGcMarking()
         << " cc->is_marking=" << is_marking_;
 
-    // jiacheng start ----------------------------
-    // CHECK(self == thread_running_gc_)
-    //     << "Only GC-running thread should access the mark stack "
-    //     << "in the GC exclusive mark stack mode";
-    // jiacheng end ------------------------------
+    CHECK(self == thread_running_gc_)
+        << "Only GC-running thread should access the mark stack "
+        << "in the GC exclusive mark stack mode";
 
     // Access the GC mark stack without a lock.
     if (UNLIKELY(gc_mark_stack_->IsFull())) {
@@ -2207,18 +2248,19 @@ inline void ConcurrentCopying::ProcessMarkStackRef(mirror::Object* to_ref) {
       }
       perform_scan = true;
       break;
+    // jiacheng start
+    case space::RegionSpace::RegionType::kRegionTypeColdToSpace:
+      region_space_bitmap_->Set(to_ref);
+      perform_scan = true;
+      break;
+    case space::RegionSpace::RegionType::kRegionTypeColdSpace:
+      if(!region_space_bitmap_->Set(to_ref)) { // old word == 0
+        perform_scan = true;
+        add_to_live_bytes = true;
+      }
+      break;
+    // jiacheng end
     default:
-  // jiacheng start ---------------------------------
-  // code in android 这里不能直接用
-  // else if (jiacheng::ColdSpace::Current()->HasAddress(to_ref)) {
-  //   jiacheng::ColdSpace* cold_space = jiacheng::ColdSpace::Current();
-  //   if (!cold_space->GetMarkBitmap(to_ref)) {
-  //     cold_space->SetMarkBitmap(to_ref);
-  //     Scan(to_ref);
-  //   }
-  // }
-  // jiacheng end -----------------------------------
-
       DCHECK(!region_space_->HasAddress(to_ref)) << to_ref;
       DCHECK(!immune_spaces_.ContainsObject(to_ref));
       // Non-moving or large-object space.
@@ -2283,22 +2325,8 @@ inline void ConcurrentCopying::ProcessMarkStackRef(mirror::Object* to_ref) {
     // Leave this reference gray in the queue so that GetReferent() will trigger a read barrier. We
     
     // will change it to non-gray later in ReferenceQueue::DisableReadBarrierForReference.
-    // jiacheng start --------------------------
-    if (jiacheng::ColdSpace::Current()->HasAddress(referent)) {
-      if (kUseBakerReadBarrier) {
-        bool success = to_ref->AtomicSetReadBarrierState<std::memory_order_release>(
-            ReadBarrier::GrayState(),
-            ReadBarrier::NonGrayState());
-        DCHECK(success) << "Must succeed as we won the race.";
-      }
-    } else {
-      DCHECK(to_ref->AsReference()->GetPendingNext() != nullptr)
-          << "Left unenqueued ref gray " << to_ref;
-    }
-    // DCHECK(to_ref->AsReference()->GetPendingNext() != nullptr)
-    //     << "Left unenqueued ref gray " << to_ref;
-  // jiacheng end ----------------------------
-
+    DCHECK(to_ref->AsReference()->GetPendingNext() != nullptr)
+        << "Left unenqueued ref gray " << to_ref;
   } else {
     // We may occasionally leave a reference non-gray in the queue if its referent happens to be
     // concurrently marked after the Scan() call above has enqueued the Reference, in which case the
@@ -2419,9 +2447,7 @@ void ConcurrentCopying::CheckEmptyMarkStack() {
   } else {
     // Shared, GC-exclusive, or off.
     MutexLock mu(thread_running_gc_, mark_stack_lock_);
-    // jiacheng start -------------------------------
-    // CHECK(gc_mark_stack_->IsEmpty());
-    // jiacheng end ---------------------------------
+    CHECK(gc_mark_stack_->IsEmpty());
     CHECK(revoked_mark_stacks_.empty());
   }
 }
@@ -2826,7 +2852,21 @@ void ConcurrentCopying::AssertToSpaceInvariant(mirror::Object* obj,
           Thread::Current()->DumpJavaStack(LOG_STREAM(FATAL_WITHOUT_ABORT));
         }
         CHECK(IsMarkedInUnevacFromSpace(ref)) << ref;
-     } else {
+     } 
+     // jiacheng start
+     else if (type == RegionType::kRegionTypeColdToSpace){
+       return;
+     } else if (type == RegionType::kRegionTypeColdSpace) {
+        if (!IsMarkedInColdSpace(ref)) {
+          LOG(FATAL_WITHOUT_ABORT) << "Found unmarked reference in cold-space:";
+          region_space_->Unprotect();
+          LOG(FATAL_WITHOUT_ABORT) << DumpHeapReference(obj, offset, ref);
+          Thread::Current()->DumpJavaStack(LOG_STREAM(FATAL_WITHOUT_ABORT));
+        }
+        CHECK(IsMarkedInColdSpace(ref)) << ref;
+     }
+     // jiacheng end     
+     else {
         // Not OK: either a from-space ref or a reference in an unused region.
         if (type == RegionType::kRegionTypeFromSpace) {
           LOG(FATAL_WITHOUT_ABORT) << "Found from-space reference:";
@@ -2868,13 +2908,7 @@ void ConcurrentCopying::AssertToSpaceInvariant(mirror::Object* obj,
         LOG(FATAL) << "Invalid reference " << ref
                    << " referenced from object " << obj << " at offset " << offset;
       }
-    } 
-    // jiacheng start -------------------------
-    else if (jiacheng::ColdSpace::Current()->HasAddress(ref)) {
-      // pass
-    }
-    // jiacheng end ---------------------------
-    else {
+    } else {
       // Check to-space invariant in non-moving space.
       AssertToSpaceInvariantInNonMovingSpace(obj, ref);
     }
@@ -2937,7 +2971,20 @@ void ConcurrentCopying::AssertToSpaceInvariant(GcRootSource* gc_root_source,
           LOG(FATAL_WITHOUT_ABORT) << DumpGcRoot(ref);
         }
         CHECK(IsMarkedInUnevacFromSpace(ref)) << ref;
-      } else {
+      } 
+      // jiacheng start
+     else if (type == RegionType::kRegionTypeColdToSpace){
+       return;
+     } else if (type == RegionType::kRegionTypeColdSpace) {
+        if (!IsMarkedInColdSpace(ref)) {
+          LOG(FATAL_WITHOUT_ABORT) << "Found unmarked reference in cold-space:";
+          region_space_->Unprotect();
+          LOG(FATAL_WITHOUT_ABORT) << DumpGcRoot(ref);
+        }
+        CHECK(IsMarkedInColdSpace(ref)) << ref;
+     }
+      // jiacheng end
+      else {
         // Not OK: either a from-space ref or a reference in an unused region.
         if (type == RegionType::kRegionTypeFromSpace) {
           LOG(FATAL_WITHOUT_ABORT) << "Found from-space reference:";
@@ -3130,11 +3177,15 @@ class ConcurrentCopying::RefFieldsVisitor {
 
 template <bool kNoUnEvac>
 inline void ConcurrentCopying::Scan(mirror::Object* to_ref) {
-  // jiacheng start  -------------------------------------
-  // LOG(INFO) << "jiacheng concurrent_copying.cc 2147 Scan() to_ref= " << to_ref 
-  //           << " ColdSpace::HasAddress()= " << jiacheng::ColdSpace::Current()->HasAddress(to_ref);
-
-  // jiacheng end ----------------------------------------
+  // jiacheng start 
+  // 除了Scan还有很多其他地方对to_ref进行访问，例如检查barrier state
+  // if(region_space_->IsInColdSpace(to_ref)) {
+  //   return;
+  // }
+  if (!region_space_->IsInColdSpace(to_ref)) {
+    jiacheng::GCAccessTrigger(to_ref);
+  }
+  // jiacheng end
   // Cannot have `kNoUnEvac` when Generational CC collection is disabled.
   DCHECK(!kNoUnEvac || use_generational_cc_);
   if (kDisallowReadBarrierDuringScan && !Runtime::Current()->IsActiveTransaction()) {
@@ -3405,24 +3456,22 @@ mirror::Object* ConcurrentCopying::Copy(Thread* const self,
   size_t bytes_allocated = 0U;
   size_t dummy;
   bool fall_back_to_non_moving = false;
-  // jiacheng start --------------------------------
+  // jiacheng start
   // mirror::Object* to_ref = region_space_->AllocNonvirtual</*kForEvac=*/ true>(
   //     region_space_alloc_size, &region_space_bytes_allocated, nullptr, &dummy);
   mirror::Object* to_ref = nullptr;
-  if (region_space_alloc_size <= jiacheng::ColdSpace::kRegionSize &&
-      jiacheng::Profiler::Current()->ShouldSwapOut(from_ref)) {
-    to_ref = jiacheng::ColdSpace::Current()->Alloc(region_space_alloc_size);
-    region_space_bytes_allocated = region_space_alloc_size;
-    LOG(INFO) << "jiacheng concurrent_copying.cc 3415 ColdSpace::Current()->Alloc()" 
-              << " region_space_alloc_size= " << region_space_alloc_size 
-              << " to_ref= " << to_ref
-              << " GetAllocatedObjNum()= " << jiacheng::ColdSpace::Current()->GetAllocatedObjNum();
-  }
-  if (!to_ref) {
+  if (jiacheng::Profiler::Current()->ShouldSwapOut(from_ref)) {
+    to_ref = region_space_->AllocCold(region_space_alloc_size, &region_space_bytes_allocated, nullptr, &dummy);
+    // LOG(INFO) << "jiacheng concurrent_copying.cc 3415 region_space_->AllocCold()" 
+    //           << " region_space_alloc_size= " << region_space_alloc_size 
+    //           << " to_ref= " << to_ref
+    //           ;
+  }
+  if (to_ref == nullptr) {
     to_ref = region_space_->AllocNonvirtual</*kForEvac*/ true>(
             region_space_alloc_size, &region_space_bytes_allocated, nullptr, &dummy);
   }
-  // jiacheng end --------------------------------
+  // jiacheng end
 
   bytes_allocated = region_space_bytes_allocated;
   if (LIKELY(to_ref != nullptr)) {
@@ -3466,14 +3515,32 @@ mirror::Object* ConcurrentCopying::Copy(Thread* const self,
   to_ref->SetClass(klass);
   const size_t kObjectHeaderSize = sizeof(mirror::Object);
   DCHECK_GE(obj_size, kObjectHeaderSize);
+  // jiacheng start
+  // static_assert(kObjectHeaderSize == sizeof(mirror::HeapReference<mirror::Class>) +
+  //                   sizeof(LockWord),
+  //               "Object header size does not match");
   static_assert(kObjectHeaderSize == sizeof(mirror::HeapReference<mirror::Class>) +
-                    sizeof(LockWord),
+                    sizeof(LockWord) + sizeof(uint64_t),
                 "Object header size does not match");
+  // jiacheng end
   // Memcpy can tear for words since it may do byte copy. It is only safe to do this since the
   // object in the from space is immutable other than the lock word. b/31423258
   memcpy(reinterpret_cast<uint8_t*>(to_ref) + kObjectHeaderSize,
          reinterpret_cast<const uint8_t*>(from_ref) + kObjectHeaderSize,
          obj_size - kObjectHeaderSize);
+  // jiacheng start
+  // if (jiacheng::IsWhiteApp()) {
+  //   LOG(INFO) << "jiacheng ConcurrentCopying::Copy()"
+  //             << " from_ref= " << reinterpret_cast<size_t>(from_ref)
+  //             << " to_ref= " << reinterpret_cast<size_t>(to_ref);
+  // }
+  jiacheng::GCAccessTrigger(to_ref);
+  jiacheng::GCAccessTrigger(from_ref);
+  // jiacheng end
+
+  // jiacheng debug start
+  CHECK(region_space_->IsInFromSpace(from_ref)) << (region_space_->GetRegionType(from_ref)) << (region_space_->GetRegionType(to_ref));
+  // jiacheng debug end
 
   // Attempt to install the forward pointer. This is in a loop as the
   // lock word atomic write can fail.
@@ -3486,13 +3553,8 @@ mirror::Object* ConcurrentCopying::Copy(Thread* const self,
       // look like a valid but dead (dummy) object and keep it for
       // future reuse.
       FillWithDummyObject(self, to_ref, bytes_allocated);
-      // jiacheng start  -----------------------------------
-      if (jiacheng::ColdSpace::Current()->HasAddress(to_ref)) {
-        /* Don't do any thing */
-      }
-      else if (!fall_back_to_non_moving) {
-      // if (!fall_back_to_non_moving) {
-      // jiacheng end -----------------------------------
+
+      if (!fall_back_to_non_moving) {
         DCHECK(region_space_->IsInToSpace(to_ref));
         if (bytes_allocated > space::RegionSpace::kRegionSize) {
           // Free the large alloc.
@@ -3518,14 +3580,12 @@ mirror::Object* ConcurrentCopying::Copy(Thread* const self,
       to_ref = reinterpret_cast<mirror::Object*>(old_lock_word.ForwardingAddress());
       CHECK(to_ref != nullptr);
       CHECK_NE(to_ref, lost_fwd_ptr);
-
-      // jiacheng start ----------------------------------- 增加对ColdSpace的判断
+      // jiacheng start
       // CHECK(region_space_->IsInToSpace(to_ref) || heap_->non_moving_space_->HasAddress(to_ref))
       //     << "to_ref=" << to_ref << " " << heap_->DumpSpaces();
-      CHECK(region_space_->IsInToSpace(to_ref) || jiacheng::ColdSpace::Current()->HasAddress(to_ref) || heap_->non_moving_space_->HasAddress(to_ref))
+      CHECK(region_space_->IsInToSpace(to_ref) || heap_->non_moving_space_->HasAddress(to_ref) || region_space_->IsInColdToSpace(to_ref))
           << "to_ref=" << to_ref << " " << heap_->DumpSpaces();
-      // jiacheng end -----------------------------------
-      
+      // jiacheng end
       CHECK_NE(to_ref->GetLockWord(false).GetState(), LockWord::kForwardingAddress);
       return to_ref;
     }
@@ -3559,14 +3619,7 @@ mirror::Object* ConcurrentCopying::Copy(Thread* const self,
         bytes_moved_.fetch_add(bytes_allocated, std::memory_order_relaxed);
       }
 
-      // jiacheng start  --------------------------------
-      if (jiacheng::ColdSpace::Current()->HasAddress(to_ref)) {
-        // pass
-        // LOG(INFO) << "jiacheng concurrent_copying.cc 2516";
-      } else if (LIKELY(!fall_back_to_non_moving)) {
-      // if (LIKELY(!fall_back_to_non_moving)) {
-      // jiacheng end  --------------------------------
-
+      if (LIKELY(!fall_back_to_non_moving)) {
         DCHECK(region_space_->IsInToSpace(to_ref));
       } else {
         DCHECK(heap_->non_moving_space_->HasAddress(to_ref));
@@ -3605,15 +3658,9 @@ mirror::Object* ConcurrentCopying::IsMarked(mirror::Object* from_ref) {
   if (rtype == space::RegionSpace::RegionType::kRegionTypeFromSpace) {
     to_ref = GetFwdPtr(from_ref);
 
-    // jiacheng start ------------------------------------
-    // DCHECK(to_ref == nullptr || region_space_->IsInToSpace(to_ref) ||
-    //        heap_->non_moving_space_->HasAddress(to_ref))
-    //     << "from_ref=" << from_ref << " to_ref=" << to_ref;
     DCHECK(to_ref == nullptr || region_space_->IsInToSpace(to_ref) ||
-           heap_->non_moving_space_->HasAddress(to_ref) || 
-           jiacheng::ColdSpace::Current()->HasAddress(to_ref))
+           heap_->non_moving_space_->HasAddress(to_ref))
         << "from_ref=" << from_ref << " to_ref=" << to_ref;
-    // jiacheng end  -------------------------------------
     
   } else if (rtype == space::RegionSpace::RegionType::kRegionTypeUnevacFromSpace) {
     if (IsMarkedInUnevacFromSpace(from_ref)) {
@@ -3621,7 +3668,19 @@ mirror::Object* ConcurrentCopying::IsMarked(mirror::Object* from_ref) {
     } else {
       to_ref = nullptr;
     }
-  } else {
+  } 
+  // jiacheng start
+  else if (rtype == space::RegionSpace::RegionType::kRegionTypeColdToSpace){
+    return from_ref;
+  } else if (rtype == space::RegionSpace::RegionType::kRegionTypeColdSpace) {
+    if (IsMarkedInColdSpace(from_ref)) {
+      to_ref = from_ref;
+    } else {
+      to_ref = nullptr;
+    }
+  }
+  // jiacheng end
+  else {
     // At this point, `from_ref` should not be in the region space
     // (i.e. within an "unused" region).
     DCHECK(!region_space_->HasAddress(from_ref)) << from_ref;
@@ -3901,6 +3960,34 @@ void ConcurrentCopying::DumpPerformanceInfo(std::ostream& os) {
      << ")\n";
 }
 
+// jiacheng start
+mirror::Object* ConcurrentCopying::MarkColdSpaceRegion(Thread* const self, 
+                                                       mirror::Object* ref, 
+                                                       accounting::SpaceBitmap<kObjectAlignment>* bitmap) {
+  if (bitmap->Test(ref)) {
+    return ref;
+  }
+  bool success = ref->AtomicSetReadBarrierState(/* expected_rb_state= */ ReadBarrier::NonGrayState(),
+                                             /* rb_state= */ ReadBarrier::GrayState());
+  if (success) {
+    DCHECK_EQ(ref->GetReadBarrierState(), ReadBarrier::GrayState());
+    PushOntoMarkStack(self, ref);
+  }
+  return ref;
+}
+
+bool ConcurrentCopying::IsMarkedInColdSpace(mirror::Object* from_ref) {
+  DCHECK(region_space_->IsInColdSpace(from_ref));
+  if (from_ref->GetReadBarrierStateAcquire() == ReadBarrier::GrayState()) {
+    return true;
+  } else if (done_scanning_.load(std::memory_order_acquire)) {
+    return region_space_bitmap_->Test(from_ref);
+  }
+  return false;
+}
+
+// jiacheng end
+
 }  // namespace collector
 }  // namespace gc
 }  // namespace art
diff --git a/runtime/gc/collector/concurrent_copying.h b/runtime/gc/collector/concurrent_copying.h
index 2e5752b91e..8e369e960d 100644
--- a/runtime/gc/collector/concurrent_copying.h
+++ b/runtime/gc/collector/concurrent_copying.h
@@ -235,6 +235,10 @@ class ConcurrentCopying : public GarbageCollector {
       REQUIRES(!mark_stack_lock_, !skipped_blocks_lock_, !immune_gray_stack_lock_);
   bool IsMarkedInUnevacFromSpace(mirror::Object* from_ref)
       REQUIRES_SHARED(Locks::mutator_lock_);
+  // jiacheng start
+  bool IsMarkedInColdSpace(mirror::Object* from_ref)
+      REQUIRES_SHARED(Locks::mutator_lock_);
+  // jiacheng end
   bool IsMarkedInNonMovingSpace(mirror::Object* from_ref)
       REQUIRES_SHARED(Locks::mutator_lock_);
   bool IsNullOrMarkedHeapReference(mirror::HeapReference<mirror::Object>* field,
@@ -298,6 +302,13 @@ class ConcurrentCopying : public GarbageCollector {
       accounting::SpaceBitmap<kObjectAlignment>* bitmap)
       REQUIRES_SHARED(Locks::mutator_lock_)
       REQUIRES(!mark_stack_lock_, !skipped_blocks_lock_);
+// jiacheng start
+  mirror::Object* MarkColdSpaceRegion(Thread* const self,
+      mirror::Object* from_ref,
+      accounting::SpaceBitmap<kObjectAlignment>* bitmap)
+      REQUIRES_SHARED(Locks::mutator_lock_)
+      REQUIRES(!mark_stack_lock_, !skipped_blocks_lock_);
+// jiacheng end
   template<bool kGrayImmuneObject>
   ALWAYS_INLINE mirror::Object* MarkImmuneSpace(Thread* const self,
                                                 mirror::Object* from_ref)
@@ -483,6 +494,10 @@ class ConcurrentCopying : public GarbageCollector {
   class VerifyNoFromSpaceRefsVisitor;
   class VerifyNoMissingCardMarkVisitor;
   class ImmuneSpaceCaptureRefsVisitor;
+  // jiacheng start
+  class RegionRememberedObjectsVisitor;
+  class RegionRememberedObjectsAsRootVisitor;
+  // jiacheng end
   template <bool kAtomicTestAndSet = false> class CaptureRootsForMarkingVisitor;
   class CaptureThreadRootsForMarkingAndCheckpoint;
   template <bool kHandleInterRegionRefs> class ComputeLiveBytesAndMarkRefFieldsVisitor;
diff --git a/runtime/gc/heap.cc b/runtime/gc/heap.cc
index ee8e46beea..aee8c26560 100644
--- a/runtime/gc/heap.cc
+++ b/runtime/gc/heap.cc
@@ -93,6 +93,10 @@
 #include "verify_object-inl.h"
 #include "well_known_classes.h"
 
+// jiacheng start
+#include "jiacheng_hack.h"
+// jiacheng end
+
 namespace art {
 
 namespace gc {
@@ -725,53 +729,19 @@ void Heap::JiachengDebug() {
   // 用于显示Heap当前的信息
   Thread* self = Thread::Current();
   (void)self;
-
-  // 查看vector<> continuous_spaces_
-  {
-    ReaderMutexLock mu(self, *Locks::mutator_lock_);
-    for (size_t i = 0; i < continuous_spaces_.size(); ++i) {
-      space::ContinuousSpace* s = continuous_spaces_[i];
-      LOG(INFO) << "jiacheng heap.cc 732"
-                << " continuous_spaces_[" << i << "]" 
-                << " GetType= " << s->GetType()
-                << " ADDR= " << size_t(s)
-                ;
-    }
-
-    // 查看vector<> discontinuous_spaces_
-    for (size_t i = 0; i < discontinuous_spaces_.size(); ++i) {
-      space::DiscontinuousSpace* s = discontinuous_spaces_[i];
-      LOG(INFO) << "jiacheng heap.cc 732"
-                << " discontinuous_spaces_[" << i << "]" 
-                << " GetType= " << s->GetType()
-                << " ADDR= " << size_t(s)
-                ;
-    }
-  }
-
-  // 查看vector<> alloc_spaces_
-  for (size_t i = 0; i < alloc_spaces_.size(); ++i) {
-    space::AllocSpace* s = alloc_spaces_[i];
+  
+  MutexLock mu(self, *gc_complete_lock_);
+  LOG(INFO) << "jiacheng heap.cc 732"
+            << " last_gc_type_= " << last_gc_type_
+            << " next_gc_type_= " << next_gc_type_
+            << " current_allocator_= " << current_allocator_
+            << " current_non_moving_allocator_= " << current_non_moving_allocator_
+            ;
+  for (size_t i = 0; i < gc_plan_.size(); ++i) {
     LOG(INFO) << "jiacheng heap.cc 732"
-              << " alloc_spaces_[" << i << "]" 
-              << " ADDR= " << size_t(s)
+              << " gc_plan_[" << i << "]= " << gc_plan_[i]
               ;
   }
-
-  // 查看Heap中的Space变量
-  LOG(INFO) << "jiacheng heap.cc 732"
-            << " non_moving_space_.ADDR= " << size_t(non_moving_space_)
-            << " rosalloc_space_.ADDR= " << size_t(rosalloc_space_)
-            << " dlmalloc_space_.ADDR= " << size_t(dlmalloc_space_)
-            << " main_space_.ADDR= " << size_t(main_space_)
-            << " large_object_space_.ADDR= " << size_t(large_object_space_)
-            ;
-
-  // 其他信息
-  LOG(INFO) << "jiacheng heap.cc 732"
-            << "kDefaultLargeObjectSpaceType= " << (kDefaultLargeObjectSpaceType == space::LargeObjectSpaceType::kFreeList) ? "kFreeList" : "kMap"
-            ;
-
 }
 // jiacheng end
 
@@ -1027,6 +997,10 @@ void Heap::ThreadFlipEnd(Thread* self) {
 }
 
 void Heap::UpdateProcessState(ProcessState old_process_state, ProcessState new_process_state) {
+  // jiacheng start
+  jiacheng::UpdataAppState(old_process_state, new_process_state);
+  // jiacheng end
+  
   if (old_process_state != new_process_state) {
     const bool jank_perceptible = new_process_state == kProcessStateJankPerceptible;
     for (size_t i = 1; i <= kCollectorTransitionStressIterations; ++i) {
@@ -2884,6 +2858,9 @@ void Heap::LogGC(GcCause gc_cause, collector::GarbageCollector* collector) {
       log_gc = log_gc || pause >= long_pause_log_threshold_;
     }
   }
+  // jiacheng start
+  log_gc = true;
+  // jiacheng end
   if (log_gc) {
     const size_t percent_free = GetPercentFree();
     const size_t current_heap_size = GetBytesAllocated();
diff --git a/runtime/gc/heap.h b/runtime/gc/heap.h
index 4f266fcd5e..d7a3400637 100644
--- a/runtime/gc/heap.h
+++ b/runtime/gc/heap.h
@@ -570,6 +570,12 @@ class Heap {
     return region_space_;
   }
 
+  // jiacheng start
+  space::ZygoteSpace* GetZygoteSpace() const {
+    return zygote_space_;
+  }
+  // jiacheng end
+
   // Implements java.lang.Runtime.maxMemory, returning the maximum amount of memory a program can
   // consume. For a regular VM this would relate to the -Xmx option and would return -1 if no Xmx
   // were specified. Android apps start with a growth limit (small heap size) which is
diff --git a/runtime/gc/space/image_space.cc b/runtime/gc/space/image_space.cc
index 3e3d199d7b..659b0c8103 100644
--- a/runtime/gc/space/image_space.cc
+++ b/runtime/gc/space/image_space.cc
@@ -1419,7 +1419,6 @@ class ImageSpace::BootImageLoader {
                       /*out*/std::string* error_msg) REQUIRES_SHARED(Locks::mutator_lock_) {
     TimingLogger logger(__PRETTY_FUNCTION__, /*precise=*/ true, VLOG_IS_ON(image));
     std::string filename = GetSystemImageFilename(image_location_.c_str(), image_isa_);
-
     if (!LoadFromFile(filename,
                       validate_oat_file,
                       extra_reservation_size,
@@ -1429,7 +1428,6 @@ class ImageSpace::BootImageLoader {
                       error_msg)) {
       return false;
     }
-
     if (VLOG_IS_ON(image)) {
       LOG(INFO) << "ImageSpace::BootImageLoader::LoadFromSystem exiting "
           << boot_image_spaces->front();
@@ -1498,7 +1496,6 @@ class ImageSpace::BootImageLoader {
                                 error_msg)) {
       return false;
     }
-
     ArrayRef<const std::string> provided_locations(boot_class_path_locations_.data(),
                                                    system_hdr.GetComponentCount());
     std::vector<std::string> locations =
@@ -1537,7 +1534,6 @@ class ImageSpace::BootImageLoader {
     if (!CheckReservationExhausted(image_reservation, error_msg)) {
       return false;
     }
-
     MaybeRelocateSpaces(spaces, logger);
     boot_image_spaces->swap(spaces);
     *extra_reservation = std::move(local_extra_reservation);
@@ -1576,13 +1572,13 @@ class ImageSpace::BootImageLoader {
     PatchRelocateVisitor patch_object_visitor(relocate_visitor, relocate_visitor);
 
     mirror::Class* dcheck_class_class = nullptr;  // Used only for a DCHECK().
+
     for (const std::unique_ptr<ImageSpace>& space : spaces) {
       // First patch the image header. The `diff` is OK for patching 32-bit fields but
       // the 64-bit method fields in the ImageHeader may need a negative `delta`.
       reinterpret_cast<ImageHeader*>(space->Begin())->RelocateImage(
           (reinterpret_cast32<uint32_t>(space->Begin()) >= -diff)  // Would `begin+diff` overflow?
               ? -static_cast<int64_t>(-diff) : static_cast<int64_t>(diff));
-
       // Patch fields and methods.
       const ImageHeader& image_header = space->GetImageHeader();
       image_header.VisitPackedArtFields([&](ArtField& field) REQUIRES_SHARED(Locks::mutator_lock_) {
@@ -1614,7 +1610,6 @@ class ImageSpace::BootImageLoader {
           patch_object_visitor.template PatchGcRoot</*kMayBeNull=*/ false>(&slot);
         }
       }
-
       // Patch the class table and classes, so that we can traverse class hierarchy to
       // determine the types of other objects when we visit them later.
       if (image_header.GetClassTableSection().Size() != 0u) {
@@ -1661,7 +1656,6 @@ class ImageSpace::BootImageLoader {
         }
       }
     }
-
     // Patch class roots now, so that we can recognize mirror::Method and mirror::Constructor.
     ObjPtr<mirror::Class> method_class;
     ObjPtr<mirror::Class> constructor_class;
@@ -1683,7 +1677,6 @@ class ImageSpace::BootImageLoader {
       method_class = GetClassRoot<mirror::Method, kWithoutReadBarrier>(class_roots);
       constructor_class = GetClassRoot<mirror::Constructor, kWithoutReadBarrier>(class_roots);
     }
-
     for (size_t s = 0u, size = spaces.size(); s != size; ++s) {
       const ImageSpace* space = spaces[s].get();
       const ImageHeader& image_header = space->GetImageHeader();
@@ -1730,7 +1723,6 @@ class ImageSpace::BootImageLoader {
       DCHECK_EQ(diff, 0u);
       return;
     }
-
     PointerSize pointer_size = first_space_header.GetPointerSize();
     if (pointer_size == PointerSize::k64) {
       DoRelocateSpaces<PointerSize::k64>(spaces, diff);
diff --git a/runtime/gc/space/region_space-inl.h b/runtime/gc/space/region_space-inl.h
index 86a0a6e418..215458b1a0 100644
--- a/runtime/gc/space/region_space-inl.h
+++ b/runtime/gc/space/region_space-inl.h
@@ -151,6 +151,18 @@ inline uint64_t RegionSpace::GetBytesAllocatedInternal() {
           bytes += r->BytesAllocated();
         }
         break;
+      // jiacheng start
+      case RegionType::kRegionTypeColdToSpace:
+        if (r->IsInColdToSpace()) {
+          bytes += r->BytesAllocated();
+        }
+        break;
+      case RegionType::kRegionTypeColdSpace:
+        if (r->IsInToSpace()) {
+          bytes += r->BytesAllocated();
+        }
+        break;
+      // jiacheng end
       default:
         LOG(FATAL) << "Unexpected space type : " << kRegionType;
     }
@@ -186,6 +198,18 @@ inline uint64_t RegionSpace::GetObjectsAllocatedInternal() {
           bytes += r->ObjectsAllocated();
         }
         break;
+      // jiacheng start
+      case RegionType::kRegionTypeColdToSpace:
+        if (r->IsInColdToSpace()) {
+          bytes += r->ObjectsAllocated();
+        }
+        break;
+      case RegionType::kRegionTypeColdSpace:
+        if (r->IsInToSpace()) {
+          bytes += r->ObjectsAllocated();
+        }
+        break;
+      // jiacheng end
       default:
         LOG(FATAL) << "Unexpected space type : " << kRegionType;
     }
diff --git a/runtime/gc/space/region_space.cc b/runtime/gc/space/region_space.cc
index 36a9d0a672..181da36282 100644
--- a/runtime/gc/space/region_space.cc
+++ b/runtime/gc/space/region_space.cc
@@ -24,6 +24,12 @@
 #include "mirror/object-inl.h"
 #include "thread_list.h"
 
+// jiacheng start
+#include "mirror/object-refvisitor-inl.h"
+#include "jiacheng_utils.h"
+#include <sstream>
+// jiacheng end
+
 namespace art {
 namespace gc {
 namespace space {
@@ -47,12 +53,6 @@ static constexpr uint32_t kPoisonDeadObject = 0xBADDB01D;  // "BADDROID"
 // Whether we check a region's live bytes count against the region bitmap.
 static constexpr bool kCheckLiveBytesAgainstRegionBitmap = kIsDebugBuild;
 
-// jiacheng start
-void RegionSpace::JiachengDebug() const {
-  
-}
-// jiacheng end
-
 MemMap RegionSpace::CreateMemMap(const std::string& name,
                                  size_t capacity,
                                  uint8_t* requested_begin) {
@@ -122,7 +122,11 @@ RegionSpace::RegionSpace(const std::string& name, MemMap&& mem_map, bool use_gen
       non_free_region_index_limit_(0U),
       current_region_(&full_region_),
       evac_region_(nullptr),
-      cyclic_alloc_region_index_(0U) {
+      // jiacheng start
+      // cyclic_alloc_region_index_(0U) {
+      cyclic_alloc_region_index_(0U),
+      current_cold_region_(nullptr) {
+      // jiacheng end
   CHECK_ALIGNED(mem_map_.Size(), kRegionSize);
   CHECK_ALIGNED(mem_map_.Begin(), kRegionSize);
   DCHECK_GT(num_regions_, 0U);
@@ -335,6 +339,14 @@ void RegionSpace::ZeroLiveBytesForLargeObject(mirror::Object* obj) {
 void RegionSpace::SetFromSpace(accounting::ReadBarrierTable* rb_table,
                                EvacMode evac_mode,
                                bool clear_live_bytes) {
+  // jiacheng start
+  if (jiacheng::IsWhiteApp()) {
+    LOG(INFO) << "jiacheng region_space.cc 343 RegionSpace::SetFromSpace()"
+              << " evac_mode= " << evac_mode
+              << " clear_live_bytes= " << clear_live_bytes;
+  }
+  // jiacheng end
+  
   // Live bytes are only preserved (i.e. not cleared) during sticky-bit CC collections.
   DCHECK(use_generational_cc_ || clear_live_bytes);
   ++time_;
@@ -357,15 +369,39 @@ void RegionSpace::SetFromSpace(accounting::ReadBarrierTable* rb_table,
     RegionState state = r->State();
     RegionType type = r->Type();
     if (!r->IsFree()) {
-      DCHECK(r->IsInToSpace());
+      // jiacheng start
+      // DCHECK(r->IsInToSpace());
+      CHECK(r->IsInToSpace() || r->IsInColdToSpace());
+      // jiacheng end
       if (LIKELY(num_expected_large_tails == 0U)) {
-        DCHECK((state == RegionState::kRegionStateAllocated ||
+        // jiacheng start
+        // DCHECK((state == RegionState::kRegionStateAllocated ||
+        //         state == RegionState::kRegionStateLarge) &&
+        //        type == RegionType::kRegionTypeToSpace);
+        CHECK((state == RegionState::kRegionStateAllocated ||
                 state == RegionState::kRegionStateLarge) &&
-               type == RegionType::kRegionTypeToSpace);
+               type == RegionType::kRegionTypeToSpace || type == RegionType::kRegionTypeColdToSpace);
+        // jiacheng end
         bool should_evacuate = r->ShouldBeEvacuated(evac_mode);
         bool is_newly_allocated = r->IsNewlyAllocated();
-        if (should_evacuate) {
+        // jiacheng start
+        bool should_cold = (type == RegionType::kRegionTypeColdToSpace);
+        // if (should_evacuate) {
+        if (should_cold) {
+          r->SetAsColdSpace();
+        } else if (should_evacuate) {
+        // jiacheng end
           r->SetAsFromSpace();
+
+          // jiacheng start
+          if (jiacheng::IsWhiteApp()) {
+            LOG(INFO) << "jiacheng region_space.cc 393 RegionSpace::SetFromSpace() SetAsFromSpace()"
+                      << " r->IsNewlyAllocated()= " << r->IsNewlyAllocated()
+                      << " evac_mode= " << evac_mode
+                      << " region_index= " << r->Idx();
+          }
+          // jiacheng end
+
           DCHECK(r->IsInFromSpace());
         } else {
           r->SetAsUnevacFromSpace(clear_live_bytes);
@@ -411,6 +447,9 @@ void RegionSpace::SetFromSpace(accounting::ReadBarrierTable* rb_table,
   DCHECK_EQ(num_expected_large_tails, 0U);
   current_region_ = &full_region_;
   evac_region_ = &full_region_;
+  // jiacheng start
+  current_cold_region_ = &full_region_;
+  // jiacheng end
 }
 
 static void ZeroAndProtectRegion(uint8_t* begin, uint8_t* end) {
@@ -557,11 +596,19 @@ void RegionSpace::ClearFromSpace(/* out */ uint64_t* cleared_bytes,
         size_t regions_to_clear_bitmap = 1;
         while (i + regions_to_clear_bitmap < num_regions_) {
           Region* const cur = &regions_[i + regions_to_clear_bitmap];
-          if (!cur->AllAllocatedBytesAreLive()) {
-            DCHECK(!cur->IsLargeTail());
+          // jiacheng start
+          // if (!cur->AllAllocatedBytesAreLive()) {
+          //   DCHECK(!cur->IsLargeTail());
+          //   break;
+          // }
+          // CHECK(cur->IsInUnevacFromSpace());
+
+          if (!cur->AllAllocatedBytesAreLive() || cur->IsInColdSpace() || cur->IsInColdToSpace()) {
+            DCHECK(!cur->IsLargeTail()) << (cur->Type());
             break;
           }
-          CHECK(cur->IsInUnevacFromSpace());
+          CHECK(cur->IsInUnevacFromSpace()) << (cur->Type());
+          // jiacheng end
           cur->SetUnevacFromSpaceAsToSpace();
           ++regions_to_clear_bitmap;
         }
@@ -618,6 +665,33 @@ void RegionSpace::ClearFromSpace(/* out */ uint64_t* cleared_bytes,
         }
       }
     }
+    // jiacheng start
+    else if (r->IsInColdSpace()) {
+      // if (r->LiveBytes() == 0) {
+      //   DCHECK(!r->IsLargeTail());
+      //   *cleared_bytes += r->BytesAllocated();
+      //   *cleared_objects += r->ObjectsAllocated();
+      //   r->Clear(/*zero_and_release_pages=*/false);
+      //   size_t free_regions = 1;
+      //   // Also release RAM for large tails.
+      //   while (i + free_regions < num_regions_ && regions_[i + free_regions].IsLargeTail()) {
+      //     regions_[i + free_regions].Clear(/*zero_and_release_pages=*/false);
+      //     ++free_regions;
+      //   }
+      //   num_non_free_regions_ -= free_regions;
+      //   // When clear_bitmap is true, this clearing of bitmap is taken care in
+      //   // clear_region().
+      //   if (!clear_bitmap) {
+      //     GetLiveBitmap()->ClearRange(
+      //         reinterpret_cast<mirror::Object*>(r->Begin()),
+      //         reinterpret_cast<mirror::Object*>(r->Begin() + free_regions * kRegionSize));
+      //   }
+      //   continue;
+      // }
+      r->SetColdSpaceAsColdToSpace();
+      // r->SetColdSpaceAsToSpace();
+    }
+    // jiacheng end
     // Note r != last_checked_region if r->IsInUnevacFromSpace() was true above.
     Region* last_checked_region = &regions_[i];
     if (!last_checked_region->IsFree()) {
@@ -630,6 +704,9 @@ void RegionSpace::ClearFromSpace(/* out */ uint64_t* cleared_bytes,
   evac_region_ = nullptr;
   num_non_free_regions_ += num_evac_regions_;
   num_evac_regions_ = 0;
+  // jiacheng start
+  current_cold_region_ = nullptr;
+  // jiacheng end
 }
 
 void RegionSpace::CheckLiveBytesAgainstRegionBitmap(Region* r) {
@@ -771,6 +848,9 @@ void RegionSpace::Clear() {
   DCHECK_EQ(num_non_free_regions_, 0u);
   current_region_ = &full_region_;
   evac_region_ = &full_region_;
+  // jiacheng start
+  current_cold_region_ = &full_region_;
+  // jiacheng end
 }
 
 void RegionSpace::Protect() {
@@ -969,6 +1049,15 @@ size_t RegionSpace::AllocationSizeNonvirtual(mirror::Object* obj, size_t* usable
 }
 
 void RegionSpace::Region::Clear(bool zero_and_release_pages) {
+  // jiacheng start
+  if (jiacheng::IsWhiteApp()) {
+    LOG(INFO) << "jiacheng region_space.cc 1047 Region::Clear()"
+              << " zero_and_release_pages= " << zero_and_release_pages
+              << " region_index= " << idx_
+              << " region_type= " << type_;
+  }
+  // jiacheng end
+
   top_.store(begin_, std::memory_order_relaxed);
   state_ = RegionState::kRegionStateFree;
   type_ = RegionType::kRegionTypeNone;
@@ -981,6 +1070,10 @@ void RegionSpace::Region::Clear(bool zero_and_release_pages) {
   is_newly_allocated_ = false;
   is_a_tlab_ = false;
   thread_ = nullptr;
+
+  // jiacheng start
+  remembered_set_.clear();
+  // jiacheng end
 }
 
 RegionSpace::Region* RegionSpace::AllocateRegion(bool for_evac) {
@@ -1014,6 +1107,13 @@ RegionSpace::Region* RegionSpace::AllocateRegion(bool for_evac) {
         // following the one that was just allocated.
         cyclic_alloc_region_index_ = (region_index + 1) % num_regions_;
       }
+      // jiacheng start
+      if (jiacheng::IsWhiteApp()) {
+        LOG(INFO) << "jiacheng region_space.cc 1083 RegionSpace::AllocateRegion() "
+                  << " for_evac= " << for_evac
+                  << " region_index= " << region_index;
+      }
+      // jiacheng end
       return r;
     }
   }
@@ -1045,6 +1145,320 @@ void RegionSpace::Region::UnfreeLargeTail(RegionSpace* region_space, uint32_t al
   state_ = RegionState::kRegionStateLargeTail;
 }
 
+// jiacheng start
+
+class ColdRefVisitor {
+ public:
+  explicit ColdRefVisitor(RegionSpace::Region* region): region_(region) {}
+
+  void operator()(mirror::Object* obj, MemberOffset offset, bool is_static ATTRIBUTE_UNUSED) const 
+    REQUIRES_SHARED(Locks::mutator_lock_)
+    REQUIRES_SHARED(Locks::heap_bitmap_lock_) ALWAYS_INLINE{
+    mirror::Object* ref = obj->GetFieldObject<mirror::Object, kVerifyNone, kWithoutReadBarrier, false>(offset);
+    if (!region_->Contains(ref)) {
+      region_->AddRememberedSet(reinterpret_cast<uint8_t*>(ref));
+    }
+  }
+
+  void operator()(ObjPtr<mirror::Class> klass, ObjPtr<mirror::Reference> obj) const
+      REQUIRES_SHARED(Locks::mutator_lock_) ALWAYS_INLINE {
+    CHECK(klass->IsTypeOfReferenceClass());
+    mirror::Object* ref = obj->GetReferent();
+    if (!region_->Contains(ref)) {
+      region_->AddRememberedSet(reinterpret_cast<uint8_t*>(ref));
+    }
+  }
+
+  void VisitRootIfNonNull(mirror::CompressedReference<mirror::Object>* root) const
+      ALWAYS_INLINE
+      REQUIRES_SHARED(Locks::mutator_lock_) {
+    if (!root->IsNull()) {
+      VisitRoot(root);
+    }
+  }
+
+  void VisitRoot(mirror::CompressedReference<mirror::Object>* root) const
+      ALWAYS_INLINE
+      REQUIRES_SHARED(Locks::mutator_lock_) {
+    mirror::Object* ref = root->AsMirrorPtr();
+    if (!region_->Contains(ref)) {
+      region_->AddRememberedSet(reinterpret_cast<uint8_t*>(ref));
+    }
+  }
+
+ private:
+  RegionSpace::Region* region_;
+};
+
+class ColdWriteBackRefVisitor {
+ public:
+  explicit ColdWriteBackRefVisitor(RegionSpace::Region* region): region_(region) {}
+
+  void operator()(mirror::Object* obj, MemberOffset offset, bool is_static ATTRIBUTE_UNUSED) const 
+    REQUIRES_SHARED(Locks::mutator_lock_)
+    REQUIRES_SHARED(Locks::heap_bitmap_lock_) ALWAYS_INLINE {
+    mirror::Object* ref = obj->GetFieldObject<mirror::Object, kVerifyNone, kWithoutReadBarrier, false>(offset);
+    mirror::Object* value = reinterpret_cast<mirror::Object*>(region_->GetRememberedSetValue(reinterpret_cast<uint8_t*>(ref)));
+    if (ref != value) {
+      obj->SetFieldObject<false>(offset, value);
+    }
+  }
+
+  void operator()(ObjPtr<mirror::Class> klass, ObjPtr<mirror::Reference> obj) const
+      REQUIRES_SHARED(Locks::mutator_lock_) ALWAYS_INLINE {
+    CHECK(klass->IsTypeOfReferenceClass());
+    mirror::Object* ref = obj->GetReferent();
+    mirror::Object* value = reinterpret_cast<mirror::Object*>(region_->GetRememberedSetValue(reinterpret_cast<uint8_t*>(ref)));
+    if (ref != value) {
+      LOG(INFO) << "jiacheng region_space.cc 1172 ref != value";
+      // obj->SetFieldObject<false>(offset, value);
+    }
+  }
+
+  void VisitRootIfNonNull(mirror::CompressedReference<mirror::Object>* root) const
+      ALWAYS_INLINE
+      REQUIRES_SHARED(Locks::mutator_lock_) {
+    if (!root->IsNull()) {
+      VisitRoot(root);
+    }
+  }
+
+  void VisitRoot(mirror::CompressedReference<mirror::Object>* root) const
+      ALWAYS_INLINE
+      REQUIRES_SHARED(Locks::mutator_lock_) {
+    mirror::Object* ref = root->AsMirrorPtr();
+    mirror::Object* value = reinterpret_cast<mirror::Object*>(region_->GetRememberedSetValue(reinterpret_cast<uint8_t*>(ref)));
+    if (ref != value) {
+      LOG(INFO) << "jiacheng region_space.cc 1191 ref != value";
+      // obj->SetFieldObject<false>(offset, value);
+    }
+  }
+
+ private:
+  RegionSpace::Region* region_;
+};
+
+void RegionSpace::Region::InitRememberedSet() {
+  remembered_set_.clear();
+  if (IsFree()) {
+    return;
+  }
+  CHECK(!IsLarge() && !IsLargeTail());
+  ColdRefVisitor ref_visitor(this);
+  auto obj_visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_) {
+    obj->VisitReferences<true, kVerifyNone, kWithoutReadBarrier>(ref_visitor, ref_visitor);
+  };
+  space::RegionSpace* region_space = art::Runtime::Current()->GetHeap()->GetRegionSpace();
+  region_space->WalkNonLargeRegion(obj_visitor, this);
+
+}
+
+
+void RegionSpace::Region::WriteBackRememberedSet() {
+  remembered_set_.clear();
+  if (IsFree()) {
+    return;
+  }
+  CHECK(!IsLarge() && !IsLargeTail());
+  ColdWriteBackRefVisitor ref_visitor(this);
+  auto obj_visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_) {
+    obj->VisitReferences<true, kVerifyNone, kWithoutReadBarrier>(ref_visitor, ref_visitor);
+  };
+  space::RegionSpace* region_space = art::Runtime::Current()->GetHeap()->GetRegionSpace();
+  region_space->WalkNonLargeRegion(obj_visitor, this);
+}
+
+
+void RegionSpace::Region::AddRememberedSet(uint8_t* ref) {
+  remembered_set_[ref] = ref;
+}
+
+uint8_t* RegionSpace::Region::GetRememberedSetValue(uint8_t* ref) {
+  auto it = remembered_set_.find(ref);
+  if (it == remembered_set_.end()) {
+    return nullptr;
+  }
+  return it->second;
+}
+
+std::map<uint8_t*, uint8_t*>* RegionSpace::Region::GetRememberedSet() {
+  return &remembered_set_;
+}
+
+
+void RegionSpace::Region::UnfreeCold(RegionSpace* region_space, uint32_t alloc_time) {
+  DCHECK(IsFree());
+  alloc_time_ = alloc_time;
+  region_space->AdjustNonFreeRegionLimit(idx_);
+  type_ = RegionType::kRegionTypeColdToSpace;
+  if (kProtectClearedRegions) {
+    CheckedCall(mprotect, __FUNCTION__, Begin(), kRegionSize, PROT_READ | PROT_WRITE);
+  }
+  state_ = RegionState::kRegionStateAllocated;
+}
+
+void RegionSpace::JiachengDebug() {
+  MutexLock mu(Thread::Current(), region_lock_);
+  for (size_t i = 0; i < std::min(num_regions_, non_free_region_index_limit_); ++i) {
+    Region* r = &regions_[i];
+    std::map<uint8_t*, uint8_t*>* remembered_set = r->GetRememberedSet();
+
+    std::stringstream ss;
+    ss << "jiacheng region_space.cc 60 JiachengDebug() ";
+    ss <<  " remembered_set.size()= " << remembered_set->size() << ' ';
+    // for (auto it : *remembered_set) {
+    //   ss << " key= " << it.first << " value= " << it.second;
+    // }
+    r->Dump(ss);
+    LOG(INFO) << ss.str();
+  }
+}
+
+uint32_t RegionSpace::SwapOutCold() {
+  LOG(INFO) << "jiacheng region_space.cc 1283 RegionSpace::SwapOutCold()";
+  uint64_t num_regions = 0;
+  uint8_t* begin, * end;
+  size_t swap_out_length;
+  MutexLock mu(Thread::Current(), region_lock_);
+  for (size_t i = 0; i < std::min(num_regions_, non_free_region_index_limit_); ++i) {
+    Region* r = &regions_[i];
+    if (r->IsInColdToSpace()) {
+      begin = r->Begin();
+      end = r->Top();
+      // end = r->End();
+      swap_out_length = std::distance(begin, end);
+      jiacheng::SwapOutRange(begin, swap_out_length);
+      // 防止重新换入
+      CheckedCall(mprotect, __FUNCTION__, begin, swap_out_length, PROT_NONE);
+      ++num_regions;
+    }
+  }
+  return num_regions * kRegionSize;
+}
+
+void RegionSpace::HandleFault(mirror::Object* ref) {
+  Region* r = RefToRegionUnlocked(ref);
+  uint8_t* begin = r->Begin();
+  // uint8_t* end = r->Top();
+  uint8_t* end = r->End();
+  size_t length = std::distance(begin, end);
+  // CheckedCall(mprotect, __FUNCTION__, begin, length, PROT_READ | PROT_WRITE);
+  if (mprotect(begin, length, PROT_READ | PROT_WRITE) == 0) {
+    LOG(INFO) << "jiacheng region_space.cc 1324 HandleFault() set PROT_READ | PROT_WRITE"
+              << " ref= " << ref
+              << " begin= " << reinterpret_cast<mirror::Object*>(begin)
+              << " end= " << reinterpret_cast<mirror::Object*>(end)
+              << " length= " << length
+              << " Success!"
+              ;
+
+  } else {
+    LOG(INFO) << "jiacheng region_space.cc 1324 HandleFault() set PROT_READ | PROT_WRITE"
+              << " ref= " << ref
+              << " begin= " << reinterpret_cast<mirror::Object*>(begin)
+              << " end= " << reinterpret_cast<mirror::Object*>(end)
+              << " length= " << length
+              << " errno= " << errno
+              << " fail!"
+              ;
+  }
+
+
+}
+
+
+RegionSpace::Region* RegionSpace::AllocateColdRegion() {
+  for (size_t i = 0; i < num_regions_; ++i) {
+    // When using the cyclic region allocation strategy, try to
+    // allocate a region starting from the last cyclic allocated
+    // region marker. Otherwise, try to allocate a region starting
+    // from the beginning of the region space.
+    size_t region_index = kCyclicRegionAllocation
+        ? ((cyclic_alloc_region_index_ + i) % num_regions_)
+        : i;
+    Region* r = &regions_[region_index];
+    if (r->IsFree()) {
+      r->UnfreeCold(this, time_);
+      ++num_non_free_regions_;
+      if (kCyclicRegionAllocation) {
+        // Move the cyclic allocation region marker to the region
+        // following the one that was just allocated.
+        cyclic_alloc_region_index_ = (region_index + 1) % num_regions_;
+      }
+      LOG(INFO) << "jiacheng region_space.cc 1322 RegionSpace::AllocateColdRegion() region_index= " << region_index;
+      return r;
+    }
+  }
+  return nullptr;
+}
+
+
+mirror::Object* RegionSpace::AllocCold(size_t num_bytes,
+                          /* out */ size_t* bytes_allocated,
+                          /* out */ size_t* usable_size,
+                          /* out */ size_t* bytes_tl_bulk_allocated) {
+  DCHECK_ALIGNED(num_bytes, kAlignment);
+  mirror::Object* obj = nullptr;
+  if (LIKELY(num_bytes <= kRegionSize)) {
+    obj = current_cold_region_->Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);
+    if (LIKELY(obj != nullptr)) {
+      return obj;
+    }
+    MutexLock mu(Thread::Current(), region_lock_);
+    obj = current_cold_region_->Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);
+    if (LIKELY(obj != nullptr)) {
+      return obj;
+    }
+    Region* r = AllocateColdRegion();
+    if (LIKELY(r != nullptr)) {
+      obj = r->Alloc(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);
+      CHECK(obj != nullptr);
+      current_cold_region_ = r;
+      return obj;
+    }
+  } else {
+    obj = AllocLargeCold(num_bytes, bytes_allocated, usable_size, bytes_tl_bulk_allocated);
+  }
+  return obj;
+}
+
+mirror::Object* RegionSpace::AllocLargeCold(size_t num_bytes,
+                                /* out */ size_t* bytes_allocated,
+                                /* out */ size_t* usable_size,
+                                /* out */ size_t* bytes_tl_bulk_allocated) {
+  (void)num_bytes;
+  (void)bytes_allocated;
+  (void)usable_size;
+  (void)bytes_tl_bulk_allocated;
+  return nullptr;
+}
+
+void RegionSpace::InitColdToRegionRememberedSet() {
+  MutexLock mu(Thread::Current(), region_lock_);
+  for (size_t i = 0; i < std::min(num_regions_, non_free_region_index_limit_); ++i) {
+    Region* r = &regions_[i];
+    if (!r->IsInColdToSpace()) {
+      continue;
+    }
+    r->InitRememberedSet();
+  }
+}
+
+void RegionSpace::WriteBackRegionRememberedSet() {
+  MutexLock mu(Thread::Current(), region_lock_);
+  // FIFO because of kCyclicRegionAllocation
+  for (size_t i = 0; i < std::min(num_regions_, non_free_region_index_limit_); ++i) {
+    Region* r = &regions_[i];
+    if (!r->IsInColdToSpace()) {
+      continue;
+    }
+    r->WriteBackRememberedSet();
+    break;
+  }
+}
+
+// jiacheng end
+
 }  // namespace space
 }  // namespace gc
 }  // namespace art
diff --git a/runtime/gc/space/region_space.h b/runtime/gc/space/region_space.h
index 90cde6dd71..13ed05d927 100644
--- a/runtime/gc/space/region_space.h
+++ b/runtime/gc/space/region_space.h
@@ -153,6 +153,10 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
     kRegionTypeFromSpace,        // From-space. To be evacuated.
     kRegionTypeUnevacFromSpace,  // Unevacuated from-space. Not to be evacuated.
     kRegionTypeToSpace,          // To-space.
+    // jiacheng start
+    kRegionTypeColdSpace,
+    kRegionTypeColdToSpace,
+    // jiacheng end
     kRegionTypeNone,             // None.
   };
 
@@ -369,13 +373,12 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
     return time_;
   }
 
-  // jiacheng start
-  void JiachengDebug() const;
-  // jiacheng end
-
  private:
   RegionSpace(const std::string& name, MemMap&& mem_map, bool use_generational_cc);
 
+// jiacheng start
+  public:
+// jiacheng end
   class Region {
    public:
     Region()
@@ -390,7 +393,11 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
           is_newly_allocated_(false),
           is_a_tlab_(false),
           state_(RegionState::kRegionStateAllocated),
-          type_(RegionType::kRegionTypeToSpace) {}
+          // jiacheng start
+          // type_(RegionType::kRegionTypeToSpace) {}
+          type_(RegionType::kRegionTypeToSpace),
+          remembered_set_() {}
+          // jiacheng end
 
     void Init(size_t idx, uint8_t* begin, uint8_t* end) {
       idx_ = idx;
@@ -407,6 +414,9 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
       thread_ = nullptr;
       DCHECK_LT(begin, end);
       DCHECK_EQ(static_cast<size_t>(end - begin), kRegionSize);
+      // jiacheng start
+      remembered_set_.clear();
+      // jiacheng end
     }
 
     RegionState State() const {
@@ -423,6 +433,24 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
                                         /* out */ size_t* bytes_allocated,
                                         /* out */ size_t* usable_size,
                                         /* out */ size_t* bytes_tl_bulk_allocated);
+    // jiacheng start
+    void InitRememberedSet();
+
+    void WriteBackRememberedSet();
+
+    void AddRememberedSet(uint8_t* ref);
+
+    uint8_t* GetRememberedSetValue(uint8_t* ref);
+
+    std::map<uint8_t*, uint8_t*>* GetRememberedSet();
+
+    template <typename Visitor>
+    void VisitRegionRememberedObjects(const Visitor& visitor) REQUIRES_SHARED(Locks::mutator_lock_) {
+      for (auto& x : remembered_set_) {
+        visitor(reinterpret_cast<mirror::Object*>(x.second));
+      }
+    }
+    // jiacheng end
 
     bool IsFree() const {
       bool is_free = (state_ == RegionState::kRegionStateFree);
@@ -438,6 +466,11 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
     void Unfree(RegionSpace* region_space, uint32_t alloc_time)
         REQUIRES(region_space->region_lock_);
 
+    // jiacheng start
+    void UnfreeCold(RegionSpace* region_space, uint32_t alloc_time)
+        REQUIRES(region_space->region_lock_);
+    // jiacheng end
+
     // Given a free region, declare it non-free (allocated) and large.
     void UnfreeLarge(RegionSpace* region_space, uint32_t alloc_time)
         REQUIRES(region_space->region_lock_);
@@ -504,6 +537,16 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
       return type_ == RegionType::kRegionTypeUnevacFromSpace;
     }
 
+    // jiacheng start
+    bool IsInColdSpace() const {
+      return type_ == RegionType::kRegionTypeColdSpace;
+    }
+
+    bool IsInColdToSpace() const {
+      return type_ == RegionType::kRegionTypeColdToSpace;
+    }
+    // jiacheng end
+
     bool IsInNoSpace() const {
       return type_ == RegionType::kRegionTypeNone;
     }
@@ -542,6 +585,27 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
       type_ = RegionType::kRegionTypeToSpace;
     }
 
+    // jiacheng start
+    void SetAsColdSpace() {
+      is_newly_allocated_ = false;
+      type_ = RegionType::kRegionTypeColdSpace;
+    }
+
+    void SetAsColdToSpace() {
+      type_ = RegionType::kRegionTypeColdToSpace;
+    }
+
+    void SetColdSpaceAsColdToSpace() {
+      DCHECK(!IsFree() && IsInColdSpace());
+      type_ = RegionType::kRegionTypeColdToSpace;
+    }
+
+    void SetColdSpaceAsToSpace() {
+      DCHECK(!IsFree() && IsInColdSpace());
+      type_ = RegionType::kRegionTypeToSpace;
+    }
+    // jiacheng end
+
     // Return whether this region should be evacuated. Used by RegionSpace::SetFromSpace.
     ALWAYS_INLINE bool ShouldBeEvacuated(EvacMode evac_mode);
 
@@ -623,9 +687,17 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
     RegionState state_;                 // The region state (see RegionState).
     RegionType type_;                   // The region type (see RegionType).
 
+    // jiacheng start
+    std::map<uint8_t*, uint8_t*> remembered_set_;  // TODO: Change to java object so as to process in GC process easily
+    // jiacheng end
+
     friend class RegionSpace;
   };
 
+  // jiacheng start
+  private:
+  // jiacheng end
+
   template<bool kToSpaceOnly, typename Visitor>
   ALWAYS_INLINE void WalkInternal(Visitor&& visitor) NO_THREAD_SAFETY_ANALYSIS;
 
@@ -723,6 +795,82 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
   // objects earlier in debug mode.
   void PoisonDeadObjectsInUnevacuatedRegion(Region* r);
 
+  // jiacheng start
+public:
+  bool IsInColdSpace(mirror::Object* ref) {
+    if (HasAddress(ref)) {
+      Region* r = RefToRegionUnlocked(ref);
+      return r->IsInColdSpace();
+    }
+    return false;
+  }
+
+  bool IsInColdToSpace(mirror::Object* ref) {
+    if (HasAddress(ref)) {
+      Region* r = RefToRegionUnlocked(ref);
+      return r->IsInColdToSpace();
+    }
+    return false;
+  }
+
+  void JiachengDebug() REQUIRES(!region_lock_);
+
+  uint32_t SwapOutCold() REQUIRES(!region_lock_);
+
+  void HandleFault(mirror::Object* ref) REQUIRES(!region_lock_);
+
+  Region* AllocateColdRegion() REQUIRES(region_lock_);
+
+  mirror::Object* AllocCold(size_t num_bytes,
+                            /* out */ size_t* bytes_allocated,
+                            /* out */ size_t* usable_size,
+                            /* out */ size_t* bytes_tl_bulk_allocated) REQUIRES(!region_lock_);
+
+  mirror::Object* AllocLargeCold(size_t num_bytes,
+                                /* out */ size_t* bytes_allocated,
+                                /* out */ size_t* usable_size,
+                                /* out */ size_t* bytes_tl_bulk_allocated) REQUIRES(!region_lock_);
+
+  void InitColdToRegionRememberedSet() REQUIRES(!region_lock_);
+
+  void WriteBackRegionRememberedSet() REQUIRES(!region_lock_);
+
+  template<typename Visitor>
+  void VisitRememberedObjectsAsRoot(Visitor& visitor) REQUIRES(!region_lock_) REQUIRES_SHARED(Locks::mutator_lock_) {
+    Thread* self = Thread::Current();
+    LOG(INFO) << "jiacheng region_space.h 839 VisitRememberedObjectsAsRoot() ";
+    MutexLock mu(self, region_lock_);
+    for (size_t i = 0; i < std::min(num_regions_, non_free_region_index_limit_); ++i) {
+      Region* r = &regions_[i];
+      if (!r->IsInColdSpace()) {
+        continue;
+      }
+      std::map<uint8_t*, uint8_t*>* remembered_set = r->GetRememberedSet();
+      for (auto& it : *remembered_set) {
+        uint8_t** ref = &(it.second);
+        *ref = reinterpret_cast<uint8_t*>(visitor(reinterpret_cast<mirror::Object*>(*ref)));
+      }
+      LOG(INFO) << "jiacheng region_space.h 850 i= " << i;
+    }
+  }
+
+  template<typename Visitor>
+  void VisitRememberedObjects(Visitor& visitor) REQUIRES(!region_lock_) REQUIRES_SHARED(Locks::mutator_lock_) {
+    Thread* self = Thread::Current();
+    LOG(INFO) << "jiacheng region_space.h 858 VisitRememberedObjects() ";
+    MutexLock mu(self, region_lock_);
+    for (size_t i = 0; i < std::min(num_regions_, non_free_region_index_limit_); ++i) {
+      Region* r = &regions_[i];
+      if (!r->IsInColdSpace()) {
+        continue;
+      }
+      r->VisitRegionRememberedObjects(visitor);
+      LOG(INFO) << "jiacheng region_space.h 866 i= " << i;
+    }
+  }
+private:
+  // jiacheng end
+
   Mutex region_lock_ DEFAULT_MUTEX_ACQUIRED_AFTER;
 
   // Cached version of Heap::use_generational_cc_.
@@ -762,6 +910,10 @@ class RegionSpace final : public ContinuousMemMapAllocSpace {
   // Mark bitmap used by the GC.
   std::unique_ptr<accounting::ContinuousSpaceBitmap> mark_bitmap_;
 
+  // jiacheng start
+  Region* current_cold_region_;
+  // jiacheng end
+
   DISALLOW_COPY_AND_ASSIGN(RegionSpace);
 };
 
diff --git a/runtime/interpreter/interpreter.cc b/runtime/interpreter/interpreter.cc
index db116f5a63..137a0cbe9c 100644
--- a/runtime/interpreter/interpreter.cc
+++ b/runtime/interpreter/interpreter.cc
@@ -241,7 +241,10 @@ enum InterpreterImplKind {
 #if ART_USE_CXX_INTERPRETER
 static constexpr InterpreterImplKind kInterpreterImplKind = kSwitchImplKind;
 #else
-static constexpr InterpreterImplKind kInterpreterImplKind = kMterpImplKind;
+// jiacheng start
+// static constexpr InterpreterImplKind kInterpreterImplKind = kMterpImplKind;
+static constexpr InterpreterImplKind kInterpreterImplKind = kSwitchImplKind;
+// jiacheng end
 #endif
 
 static inline JValue Execute(
diff --git a/runtime/jiacheng_activity_manager.h b/runtime/jiacheng_activity_manager.h
index d548b8af0d..e16197cc85 100644
--- a/runtime/jiacheng_activity_manager.h
+++ b/runtime/jiacheng_activity_manager.h
@@ -1,9 +1,8 @@
-#ifndef JIACHENG_ACTIVITY_MANAGER_H_
-#define JIACHENG_ACTIVITY_MANAGER_H_
+#ifndef ART_RUNTIME_JIACHENG_ACTIVITY_MANAGER_H_
+#define ART_RUNTIME_JIACHENG_ACTIVITY_MANAGER_H_
 
 #include <set>
 #include <map>
-#include <atomic>
 
 #include "base/mutex.h"
 
diff --git a/runtime/jiacheng_barrier.cc b/runtime/jiacheng_barrier.cc
new file mode 100644
index 0000000000..4f518bbb6d
--- /dev/null
+++ b/runtime/jiacheng_barrier.cc
@@ -0,0 +1,42 @@
+#include "jiacheng_barrier.h"
+#include "jiacheng_profiler.h"
+#include "jiacheng_utils.h"
+
+#include "mirror/object.h"
+
+namespace art {
+namespace jiacheng {
+
+
+void JiachengBarrier(uint64_t obj) {
+    if (!obj) {
+        return;
+    }
+    if (!IsWhiteApp()) {
+        return;
+    }
+    Profiler* profiler = Profiler::Current();
+    if (profiler->GetPerceptibleFlag()) {
+        return;
+    }
+
+    // jiacheng debug start
+
+    // static size_t cnt = 0;
+    // cnt += 1;
+    // if (cnt % 100 == 0) {
+    //     LOG(INFO) << "jiacheng JiachengBarrier() " << "obj= " << obj;
+    //     cnt = 0;
+    // }
+
+    // jiacheng debug end
+    
+    if (!profiler->GetDuringGcFlag()) {
+        profiler->RecordAccessWS(reinterpret_cast<mirror::Object *>(obj));
+    } else {
+        // profiler->RecordGcWS(reinterpret_cast<mirror::Object *>(obj));
+    }
+}
+
+}
+}
\ No newline at end of file
diff --git a/runtime/jiacheng_barrier.h b/runtime/jiacheng_barrier.h
new file mode 100644
index 0000000000..5cbf1a372d
--- /dev/null
+++ b/runtime/jiacheng_barrier.h
@@ -0,0 +1,16 @@
+#ifndef ART_RUNTIME_JIACHENG_BARRIER_H_
+#define ART_RUNTIME_JIACHENG_BARRIER_H_
+
+#include "base/mutex.h"
+
+namespace art {
+namespace jiacheng {
+
+// void JiachengBarrier(uint64_t obj) REQUIRES_SHARED(Locks::mutator_lock_);
+void JiachengBarrier(uint64_t obj);
+
+
+} // namespace jiacheng
+} // namespace art
+
+#endif
\ No newline at end of file
diff --git a/runtime/jiacheng_bloom_filter.h b/runtime/jiacheng_bloom_filter.h
new file mode 100644
index 0000000000..eade861eae
--- /dev/null
+++ b/runtime/jiacheng_bloom_filter.h
@@ -0,0 +1,133 @@
+#ifndef ART_RUNTIME_JIACHENG_BLOOM_FILTER_H_
+#define ART_RUNTIME_JIACHENG_BLOOM_FILTER_H_
+
+/*
+* Code inspired by:
+* https://github.com/jvirkki/libbloom/blob/master/bloom.c
+*/
+
+#include <cinttypes>
+#include <cmath>
+#include <cstddef>
+#include <cstdlib>
+#include <cassert>
+
+namespace art{
+namespace jiacheng {
+
+class BloomFilter {
+public:
+    /*
+    * BloomFilter: initialize a bloom filter.
+    *
+    * Parameters:
+    *   entries: The expected number of elements that will be added
+    *   fp_rate: The desired upper bound on the false positive rate
+    */
+    BloomFilter(uint64_t entries, double fp_rate):hash_() {
+        assert(fp_rate < 1 && fp_rate > 0);
+
+        double num, denom, bpe, dentries;
+        num = std::log(fp_rate);
+        denom = 0.480453013918201; // ln(2)^2
+        bpe = -(num / denom);
+
+        dentries = (double)entries;
+        bits_ = (uint_fast32_t)(dentries * bpe);
+
+        if (bits_ % 8) {
+            byte_size_ = (bits_ / 8) + 1;
+        } else {
+            byte_size_ = bits_ / 8;
+        }
+        hash_num_ = (uint_fast16_t)std::ceil(0.693147180559945 * bpe); // ln(2)
+        bf_ = (uint8_t*)calloc(byte_size_, sizeof(uint8_t));
+        assert(bf_ != NULL);
+    }
+
+    ~BloomFilter() {
+        free(bf_);
+    }
+
+    /*
+    * Add: add an item to a bloom filter.
+    *
+    * Parameters:
+    *   element: the data that should be added
+    *
+    * Returns:
+    *    false - element was not present and was added
+    *    true - element (or a collision) had already been added previously
+    */
+    bool Add(uint64_t element) {
+        uint64_t hits = 0;
+
+        uint32_t a = hash_(element);
+        uint32_t b = hash_(a);
+        uint32_t x;
+
+        for (uint32_t i = 0; i < hash_num_; i++) {
+            x = (a + i * b) % bits_;
+    #define THREAD_SAFE true
+    #ifdef THREAD_SAFE
+            if (__sync_fetch_and_or(bf_ + (x >> 3), (uint8_t)(1 << (x & 7)))) {
+                hits++;
+            }
+    #else
+            if (*(bf_ + (x >> 3)) & (1 << (x & 7))) {
+                hits++;
+            }
+            *(bf_ + (x >> 3)) |= (1 << (x & 7));
+    #endif
+        }
+
+        if (hits == hash_num_) {
+            return true;
+        }
+        return false;
+    }
+
+    /*
+    * Check: check if an item is in the bloom filter.
+    *
+    * Parameters:
+    *   element: the data that should be checked
+    *
+    * Returns:
+    *    false - element is not present
+    *    true - element is present (or a collision)
+    */
+    bool Check(uint64_t element) {
+        uint64_t hits = 0;
+        uint32_t x;
+
+        uint32_t a = hash_(element);
+        uint32_t b = hash_(a);
+        for (uint32_t i = 0; i < hash_num_; i++) {
+            x = (a + i * b) % bits_;
+            if (*(bf_ + (x >> 3)) & (1 << (x & 7))) {
+                hits++;
+            } else {
+                return false;
+            }
+        }
+        return hits == hash_num_;
+    }
+
+    void Clear() {
+        std::memset(bf_, 0, byte_size_);
+    }
+
+
+private:
+    std::hash<uint64_t> hash_;
+    uint32_t byte_size_;
+    uint_fast32_t bits_;        // Number of bits in the bloom filter buffer
+    uint_fast16_t hash_num_;    // Number of hashes used per element added
+    uint8_t *bf_;               // Location of the underlying bit field
+};
+
+} // namespace jiacheng
+} // namespace art
+
+#endif
\ No newline at end of file
diff --git a/runtime/jiacheng_cheatsheet.cc b/runtime/jiacheng_cheatsheet.cc
index eb0d51034d..0bcf1547ac 100644
--- a/runtime/jiacheng_cheatsheet.cc
+++ b/runtime/jiacheng_cheatsheet.cc
@@ -1,26 +1,26 @@
-#include "jiacheng_cheatsheet.h"
+// #include "jiacheng_cheatsheet.h"
 
 
-namespace art {
-namespace jiacheng {
+// namespace art {
+// namespace jiacheng {
 
 
-void CheatSheet::AddRememberedSet(uint8_t *obj) {
-    remembered_set_.insert(obj);
-}
+// void CheatSheet::AddRememberedSet(uint8_t *obj) {
+//     remembered_set_.insert(obj);
+// }
 
-void CheatSheet::AddColdSet(uint8_t *obj) {
-    cold_set_.insert(obj);
-}
+// void CheatSheet::AddColdSet(uint8_t *obj) {
+//     cold_set_.insert(obj);
+// }
 
-bool CheatSheet::InRememberedSet(uint8_t *obj) {
-    return remembered_set_.find(obj) != remembered_set_.end();
-}
+// bool CheatSheet::InRememberedSet(uint8_t *obj) {
+//     return remembered_set_.find(obj) != remembered_set_.end();
+// }
 
-bool CheatSheet::InColdSet(uint8_t *obj) {
-    return cold_set_.find(obj) != cold_set_.end();
-}
+// bool CheatSheet::InColdSet(uint8_t *obj) {
+//     return cold_set_.find(obj) != cold_set_.end();
+// }
 
 
-}
-}
\ No newline at end of file
+// }
+// }
\ No newline at end of file
diff --git a/runtime/jiacheng_cheatsheet.h b/runtime/jiacheng_cheatsheet.h
index 7ce875dbb9..9df19d195c 100644
--- a/runtime/jiacheng_cheatsheet.h
+++ b/runtime/jiacheng_cheatsheet.h
@@ -1,28 +1,26 @@
-#ifndef JIACHENG_CHEATSHEET_H_
-#define JIACHENG_CHEATSHEET_H_
+// #ifndef ART_RUNTIME_JIACHENG_CHEATSHEET_H_
+// #define ART_RUNTIME_JIACHENG_CHEATSHEET_H_
 
-#include <set>
+// #include <set>
 
-namespace art {
-namespace jiacheng {
+// namespace art {
+// namespace jiacheng {
 
-class CheatSheet {
-public:
-    CheatSheet();
-    ~CheatSheet();
+// class CheatSheet {
+// public:
+//     CheatSheet();
+//     ~CheatSheet();
 
-    void AddRememberedSet(uint8_t *obj);
-    void AddColdSet(uint8_t *obj);
+//     void AddRememberedSet(uint8_t *obj);
+//     void AddColdSet(uint8_t *obj);
 
-    bool InRememberedSet(uint8_t *obj);
-    bool InColdSet(uint8_t * obj);
+//     bool InRememberedSet(uint8_t *obj);
+//     bool InColdSet(uint8_t * obj);
 
-    std::set<uint8_t*> remembered_set_;
-    std::set<uint8_t*> cold_set_;
-    std::set<uint8_t*> hot_set_;
-};
+//     std::map<uint8_t*, uint32_t> remembered_set_;
+// };
 
-}
-}
+// }
+// }
 
-#endif
\ No newline at end of file
+// #endif
\ No newline at end of file
diff --git a/runtime/jiacheng_cold_space.cc b/runtime/jiacheng_cold_space.cc
deleted file mode 100644
index c26a6bf6b7..0000000000
--- a/runtime/jiacheng_cold_space.cc
+++ /dev/null
@@ -1,171 +0,0 @@
-#include <fstream>
-#include <thread>
-#include <chrono>
-#include <atomic>
-#include <sys/mman.h>
-
-#include "base/mem_map.h"
-#include "gc/space/region_space.h"
-#include "base/mutex.h"
-#include "thread_list.h"
-#include "thread-current-inl.h"
-
-#include "jiacheng_hack.h"
-#include "jiacheng_cold_space.h"
-#include "jiacheng_region.h"
-
-
-namespace art{
-namespace jiacheng {
-
-Mutex ColdSpace::singleton_lock_("Cold Space Singleton Lock", kLoggingLock);
-
-ColdSpace* ColdSpace::cold_space_ = nullptr;
-
-ColdSpace::ColdSpace(MemMap* mem_map):
-    region_lock_("Cold Space Lock", kLoggingLock),
-    mem_map_(mem_map),
-    begin_(mem_map->Begin()),
-    end_(mem_map->End()),
-    num_regions_(mem_map->Size() / kRegionSize),
-    top_region_idx_(0U),
-    current_region_(nullptr),
-    madvice_top_region_idx_(0),
-    allocated_obj_num_(0),
-    mark_bitmap_(),
-    remembered_set_(),
-    remembered_root_stack_() {
-    
-    regions_.reset(new Region[num_regions_]);
-    uint8_t* region_addr = mem_map->Begin();
-    for (size_t i = 0; i < num_regions_; ++i, region_addr += kRegionSize) {
-        regions_[i].Init(i, region_addr, region_addr + kRegionSize);
-    }
-    current_region_ = &regions_[top_region_idx_++];
-
-}
-
-ColdSpace::~ColdSpace() {}
-
-ColdSpace* ColdSpace::Current() {
-    if (cold_space_ == nullptr) {
-        Thread* self = Thread::Current();
-        singleton_lock_.ExclusiveLock(self);
-        if (cold_space_ == nullptr) {
-            cold_space_ = Create();
-        }
-        singleton_lock_.ExclusiveUnlock(self);
-    }
-    return cold_space_;
-}
-
-
-ColdSpace* ColdSpace::Create() {
-    std::string error_msg;
-    MemMap mem_map = MemMap::MapAnonymous("Cold Space",
-                                            nullptr,
-                                            kCapacitySize + kRegionSize,
-                                            PROT_READ | PROT_WRITE,
-                                            true,
-                                            false,
-                                            nullptr,
-                                            &error_msg);
-
-    // if (!mem_map) {
-    //     LOG(INFO) << "jiacheng jiacheng_cold_space.cc 75 mem_map=nullptr error_msg= " << error_msg; 
-    // }
-    return new ColdSpace(&mem_map);
-}
-
-void ColdSpace::JiachengDebug() {
-    LOG(INFO) << "jiacheng jiacheng_cold_space.cc 62 " << "mem_map_= " << size_t(mem_map_); 
-    LOG(INFO) << "jiacheng jiacheng_cold_space.cc 62 " << "num_regions_= " << num_regions_; 
-    LOG(INFO) << "jiacheng jiacheng_cold_space.cc 62 " << "top_region_idx_= " << top_region_idx_; 
-    LOG(INFO) << "jiacheng jiacheng_cold_space.cc 62 " << "current_region_= " << current_region_; 
-    LOG(INFO) << "jiacheng jiacheng_cold_space.cc 62 " << "allocated_obj_num_= " << allocated_obj_num_.load(); 
-}
-
-
-mirror::Object* ColdSpace::Alloc(size_t num_bytes) {
-    num_bytes = RoundUp(num_bytes, kAlignment);
-    mirror::Object* obj;
-    obj = current_region_->Alloc(num_bytes);
-    if (obj != nullptr) {
-        allocated_obj_num_.fetch_add(1);
-        return obj;
-    }
-    Region* r = AllocateRegion();
-    if (r == nullptr) {
-        LOG(INFO) << "jiacheng jiacheng_cold_space.cc 83 AllocateRegion() ColdSpace已满!";
-        return nullptr;
-    }
-    current_region_ = r;
-    obj = current_region_->Alloc(num_bytes);
-    if (obj != nullptr) {
-        allocated_obj_num_.fetch_add(1);
-    }
-    return obj;
-}
-
-Region* ColdSpace::AllocateRegion() {
-    if (top_region_idx_ >= num_regions_) {
-        return nullptr;
-    }
-    return &regions_[top_region_idx_++];
-}
-
-void ColdSpace::SwapOut() {
-    // if (madvice_top_region_idx_ < top_region_idx_ - 1) { // 把Current之前的Region进行Swap
-    //     uint8_t* begin = regions_[madvice_top_region_idx_].Begin();
-    //     uint8_t* end = regions_[top_region_idx_ - 2].End();
-    //     LOG(INFO) << "jiacheng jiacheng_cold_space.cc 111 begin= " << size_t(begin) << " end= " << size_t(end) 
-    //               << " madvice_top_region_idx_= " << madvice_top_region_idx_
-    //               << " top_region_idx_= " << top_region_idx_;
-    //     madvise(begin, reinterpret_cast<size_t>(end) - reinterpret_cast<size_t>(begin) - 1, 233);
-    //     madvice_top_region_idx_ = top_region_idx_ - 1;
-    // }
-    if (0 < top_region_idx_ - 1) { // 把Current之前的Region进行Swap
-        uint8_t* begin = regions_[0].Begin();
-        uint8_t* end = regions_[top_region_idx_ - 2].End();
-        LOG(INFO) << "jiacheng jiacheng_cold_space.cc 111 begin= " << size_t(begin) << " end= " << size_t(end) 
-                  << " madvice_top_region_idx_= " << madvice_top_region_idx_
-                  << " top_region_idx_= " << top_region_idx_;
-        madvise(begin, reinterpret_cast<size_t>(end) - reinterpret_cast<size_t>(begin) - 1, 233);
-        // madvice_top_region_idx_ = top_region_idx_ - 1;
-    }
-}
-
-bool ColdSpace::HasAddress(mirror::Object* obj) const {
-    const uint8_t* byte_ptr = reinterpret_cast<const uint8_t*>(obj);
-    return byte_ptr >= Begin() && byte_ptr < End();
-}
-
-bool ColdSpace::GetMarkBitmap(mirror::Object* to_ref) {
-    return mark_bitmap_.find(to_ref) != remembered_set_.end();
-}
-
-void ColdSpace::SetMarkBitmap(mirror::Object* to_ref) {
-    mark_bitmap_.insert(to_ref);
-}
-
-void ColdSpace::ResetMarkBitmap() {
-    mark_bitmap_.clear();
-}
-
-void ColdSpace::AddRememberedSet(mirror::Object* obj) {
-    remembered_set_.insert(obj);
-}
-
-// 把Obj对象中包含的所有引用加入的根集
-void ColdSpace::AddRememberedRootSet(mirror::Object* obj) {
-    remembered_root_stack_.push_back(obj);
-}
-
-// 得到GC之前的根集合
-std::vector<mirror::Object*>* ColdSpace::GetRememberedRootStack() {
-    return &(remembered_root_stack_);
-}
-
-
-} // namespace jiacheng
-} // namespace art
diff --git a/runtime/jiacheng_cold_space.h b/runtime/jiacheng_cold_space.h
deleted file mode 100644
index 46e8242bcb..0000000000
--- a/runtime/jiacheng_cold_space.h
+++ /dev/null
@@ -1,103 +0,0 @@
-#ifndef JIACHENG_COLD_SPACE_H_
-#define JIACHENG_COLD_SPACE_H_
-
-#include <atomic>
-#include "base/mutex.h"
-
-namespace art{
-
-namespace mirror {
-class Object;
-}  // namespace mirror
-
-class MemMap;
-
-// ------------ START -------------
-namespace jiacheng {
-
-class Region;
-
-class ColdSpace {
-public: 
-  ColdSpace(MemMap* mem_map);
-  ~ColdSpace();
-
-  static Mutex singleton_lock_;
-  static ColdSpace* cold_space_; 
-
-  static ColdSpace* Create();
-  static ColdSpace* Current();
-
-  void JiachengDebug();
-
-  mirror::Object* Alloc(size_t num_bytes);
-
-  Region* AllocateRegion();
-
-  void SwapOut();
-
-  bool HasAddress(mirror::Object* obj) const;
-
-  bool GetMarkBitmap(mirror::Object* to_ref);
-
-  void SetMarkBitmap(mirror::Object* to_ref);
-
-  void ResetMarkBitmap();
-
-  void AddRememberedSet(mirror::Object* obj);
-
-  void AddRememberedRootSet(mirror::Object* obj);
-
-  std::vector<mirror::Object*>* GetRememberedRootStack();
-
-  uint8_t* Begin() const {
-    return begin_;
-  }
-
-  uint8_t* End() const {
-    return end_;
-  }
-
-  size_t GetAllocatedObjNum() const {
-    return allocated_obj_num_.load();
-  }
-
-
-  // ---------------- 变量开始 ----------------------
-  // Object alignment within the space.
-  static constexpr size_t kAlignment = kObjectAlignment;
-  // The region size.
-  static constexpr size_t kRegionSize = 4 * KB;
-  // The capacity size.
-  static constexpr size_t kCapacitySize = kRegionSize * 1024 * 100; // 400MB
-
-  Mutex region_lock_;
-
-  MemMap* mem_map_;
-
-  uint8_t* begin_;
-  uint8_t* end_;
-
-  std::unique_ptr<Region[]> regions_;
-
-  size_t num_regions_;             
-
-  size_t top_region_idx_;
-
-  Region* current_region_;         
-
-  size_t madvice_top_region_idx_;
-
-  std::atomic<size_t> allocated_obj_num_;
-
-  std::set<mirror::Object*> mark_bitmap_;
-
-  std::set<mirror::Object*> remembered_set_;
-
-  std::vector<mirror::Object*> remembered_root_stack_;
-};
-
-
-} // namespace jiacheng
-} // namespace art
-#endif
\ No newline at end of file
diff --git a/runtime/jiacheng_debug.cc b/runtime/jiacheng_debug.cc
new file mode 100644
index 0000000000..9b699efcd7
--- /dev/null
+++ b/runtime/jiacheng_debug.cc
@@ -0,0 +1,472 @@
+#include <chrono>
+#include <atomic>
+#include <thread>
+#include <random>
+#include <sstream>
+#include <fstream>
+
+#include <unistd.h>
+#include <sys/syscall.h>
+
+#include "gc/accounting/card_table.h"
+#include "gc/heap.h"
+#include "gc/space/space-inl.h"
+#include "gc/heap-visit-objects-inl.h"
+#include "gc/space/zygote_space.h"
+#include "gc/space/bump_pointer_space-inl.h"
+#include "gc/space/bump_pointer_space-walk-inl.h"
+#include "gc/space/dlmalloc_space-inl.h"
+#include "gc/space/image_space.h"
+#include "gc/space/large_object_space.h"
+#include "gc/space/malloc_space.h"
+#include "gc/space/region_space-inl.h"
+#include "gc/space/rosalloc_space-inl.h"
+#include "mirror/class-inl.h"
+#include "obj_ptr-inl.h"
+#include "scoped_thread_state_change-inl.h"
+#include "thread_list.h"
+#include "gc/accounting/mod_union_table-inl.h"
+#include "gc/accounting/remembered_set.h"
+#include "base/mutex.h"
+#include "read_barrier_config.h"
+
+#include "jiacheng_debug.h"
+#include "jiacheng_utils.h"
+
+namespace art {
+namespace jiacheng {
+
+static Mutex working_set_lock("Profiler Singleton Lock", kLoggingLock);
+static std::set<mirror::Object*> working_set;
+static std::set<size_t> page_working_set;
+static size_t all_object_size;
+
+void RecordWorkingSet(mirror::Object* obj) {
+    Thread* self = Thread::Current();
+    working_set_lock.ExclusiveLock(self);
+    if (working_set.find(obj) == working_set.end()) {
+        size_t object_size = 0;
+        {
+            ReaderMutexLock mu(self, *Locks::mutator_lock_); 
+            object_size = obj->SizeOf();
+        }
+        all_object_size += object_size;
+        size_t begin_addr = reinterpret_cast<size_t>(obj);
+        size_t end_addr = begin_addr + object_size;
+        while (begin_addr < end_addr) {
+            page_working_set.insert(begin_addr >> 12);
+            begin_addr += 1 << 12;
+        }
+        working_set.insert(obj);
+    }
+    
+    working_set_lock.ExclusiveUnlock(self);
+}
+
+void ClearAndPrintWorkingSet() {
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    size_t total_memory = heap->GetTotalMemory();
+    size_t total_active_page = 0;
+    size_t total_active_object = 0;
+    Thread* self = Thread::Current();
+
+    working_set_lock.ExclusiveLock(self);
+    total_active_page = page_working_set.size() << 12;
+    total_active_object = all_object_size;
+    working_set.clear();
+    page_working_set.clear();
+    all_object_size = 0;
+    working_set_lock.ExclusiveUnlock(self);
+
+    LOG(INFO) << "jiacheng jiacheng_debug.cc 78 ClearAndPrintWorkingSet()"
+              << " active_object= " << total_active_object
+              << " active_page= " << total_active_page
+              << " total_memory= " << total_memory
+              << std::flush;
+}
+
+
+typedef void(*WalkCallback)(void *start, void *end, size_t num_bytes, void* callback_arg);
+
+// 对ColdSpace中的Region进行Swap
+void SwapOutAll() {
+    // 对所有Space中的对象进行Swap
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    Thread* self = Thread::Current();
+    const std::vector<gc::space::ContinuousSpace*>* continues_spaces;
+    {
+        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
+        continues_spaces = &(heap->GetContinuousSpaces());
+    }
+    for (auto space : *continues_spaces) {
+        CurrentThreadSleepSecond(1);
+        SwapOutSpace(space);
+    }
+    const std::vector<gc::space::DiscontinuousSpace*>& discontinues_spaces = heap->GetDiscontinuousSpaces();
+    for (auto space : discontinues_spaces) {
+        CurrentThreadSleepSecond(1);
+        SwapOutSpace(space);
+    }    
+
+    // 不直接使用SwapOutSpace()函数对所有Space中的对象进行Swap
+    // LOG(INFO) << "jiacheng jiacheng_hack.cc 180 SwapOut()";
+    // ColdSpace* cold_space = ColdSpace::Current();
+    // cold_space->SwapOut();
+}
+
+
+void SwapOutSpace(gc::space::Space* space) {
+    Thread* self = Thread::Current();
+    gc::space::SpaceType space_type = space->GetType();
+    
+    WalkCallback walk_callback = [](void* start, void* end, size_t /*num_bytes*/, void* ) {
+        // if (start != end && ActivityManager::Current()->ShouldSwapOut(reinterpret_cast<mirror::Object*>(start))) {
+        if (start != end) {
+            LOG(INFO) << "jiacheng_hack.cc 143 ShouldSwapOut() obj= " << size_t(start) << " size= " << size_t(end) - size_t(start);
+            madvise(start, reinterpret_cast<size_t>(end) - reinterpret_cast<size_t>(start), 233);
+        }
+    };    
+    auto visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_){
+        // if (obj && ActivityManager::Current()->ShouldSwapOut(obj)) {
+        if (obj) {
+            LOG(INFO) << "jiacheng_hack.cc 150 ShouldSwapOut() obj= " << size_t(obj) << " size= " << obj->SizeOf();
+            madvise(static_cast<void *>(obj), obj->SizeOf(), 233);
+        }
+    };
+    switch (space_type) {
+        case gc::space::kSpaceTypeImageSpace: {
+            // gc::space::ImageSpace* this_space = space->AsImageSpace();
+            break;
+        }
+        case gc::space::kSpaceTypeMallocSpace: {
+            gc::space::MallocSpace* this_space = space->AsMallocSpace();
+            this_space->Walk(walk_callback, nullptr);
+            break;
+        }
+        case gc::space::kSpaceTypeZygoteSpace: {
+            // gc::space::ZygoteSpace* this_space = space->AsZygoteSpace();
+            break;
+        }
+        case gc::space::kSpaceTypeBumpPointerSpace: {
+            gc::space::BumpPointerSpace* this_space = space->AsBumpPointerSpace();
+            { 
+                WriterMutexLock mu(self, *Locks::mutator_lock_);  
+                this_space -> Walk(visitor);
+            }
+            break;
+        }
+        case gc::space::kSpaceTypeLargeObjectSpace: {
+            gc::space::LargeObjectSpace* this_space = space->AsLargeObjectSpace();
+            this_space->Walk(walk_callback, nullptr);
+            break;
+        }
+        case gc::space::kSpaceTypeRegionSpace: {
+            gc::space::RegionSpace* this_space = space->AsRegionSpace();   
+            {
+                WriterMutexLock mu(self, *Locks::mutator_lock_);  
+                this_space -> Walk(visitor);
+            }
+            break;
+        }
+        default:
+            LOG(INFO) << "jiacheng " << "jiacheng_hack.cc 100. Can not find space.";
+    }
+}
+
+
+/* ------------------- debug --------------------- */
+
+// 查看Object在哪个Space里面
+std::string GetSpaceFromObject(mirror::Object* obj) {
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    if (!heap) {
+        return "no_heap";
+    }
+    gc::space::RegionSpace* region_space = heap->GetRegionSpace();
+    gc::space::LargeObjectSpace* large_object_space = heap->GetLargeObjectsSpace();
+    gc::space::MallocSpace* non_moving_space = heap->GetNonMovingSpace();
+    gc::space::ZygoteSpace* zygote_space = heap->GetZygoteSpace();
+    const std::vector<gc::space::ImageSpace*>& boot_image_spaces = heap->GetBootImageSpaces();
+    
+    if (region_space && region_space->Contains(obj)) {
+        return "region_space";
+    } else if (non_moving_space && non_moving_space->Contains(obj)) {
+        return "non_moving_space";
+    } else if (large_object_space && large_object_space->Contains(obj)) {
+        return "large_object_space";
+    } else if (zygote_space && zygote_space->Contains(obj)) {
+        return "zygote_space";
+    } 
+    for (gc::space::ImageSpace* space : boot_image_spaces) {
+        if (space->Contains(obj)) {
+            return "boot_image_spaces";
+        }
+    }
+
+    Thread* self = Thread::Current();
+    {
+        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
+        const std::vector<gc::space::ContinuousSpace*>& continues_spaces = heap->GetContinuousSpaces();
+        for (size_t i = 0; i < continues_spaces.size(); ++i) {
+            gc::space::ContinuousSpace* space = continues_spaces[i];
+            if (space->Contains(obj)) {
+                return "continues_spaces-" + std::to_string(i) + "-" + space->GetName();
+            }
+        }
+    }
+
+    return "other_space";
+}
+
+class ObjectInfo {
+public:
+    ObjectInfo(size_t object_address, size_t object_size, std::string&& space)
+        : object_address_(object_address), object_size_(object_size), space_(space) {}
+
+    std::string ToString() const {
+        std::ostringstream string_stream;
+        string_stream << "address= " << object_address_
+                      << " size= " << object_size_
+                      << " space= " << space_;
+        return string_stream.str();
+    }
+
+private:
+    size_t object_address_;
+    size_t object_size_;
+    std::string space_;
+};
+
+void PrintRegionSpaceInformation(uint32_t info_key) {
+    Thread* self = Thread::Current();
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    gc::space::RegionSpace* region_space = heap->GetRegionSpace();
+    std::vector<ObjectInfo> object_infomations;
+    auto visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_) {
+        if (obj != nullptr) {
+            size_t object_address, object_size;
+            object_address = reinterpret_cast<size_t>(obj);
+            object_size = obj->SizeOf();
+            std::string space = "region_space";
+            object_infomations.emplace_back(ObjectInfo(object_address, object_size, std::move(space)));
+        }
+    }; 
+    {
+        WriterMutexLock mu(self, *Locks::mutator_lock_);  
+        region_space -> Walk(visitor);
+    }
+    for (const auto& info : object_infomations) {
+        LOG(INFO) << "jiacheng jiacheng_utils.cc 269 "
+                  << " key= " << info_key 
+                  << " info= " << info.ToString();
+    }
+}
+
+void PrintLargeObjectSpaceInformation(uint32_t info_key) {
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    gc::space::LargeObjectSpace* large_object_space = heap->GetLargeObjectsSpace();
+    // std::vector<ObjectInfo> object_infomations;
+    WalkCallback walk_callback = [](void* start, void* end, size_t /*num_bytes*/, void* info_key) {
+        if (start != end) {
+            size_t object_address, object_size;
+            object_address = reinterpret_cast<size_t>(start);
+            object_size = size_t(end) - size_t(start);
+            std::string space = "large_object_space";
+            ObjectInfo info(object_address, object_size, std::move(space));
+            // object_infomations.emplace_back(ObjectInfo(object_address, object_size, std::move(space)));
+            LOG(INFO) << "jiacheng jiacheng_utils.cc 269 "
+                        << " key= " << *((uint32_t *)(info_key))
+                        << " info= " << info.ToString();
+        }
+    }; 
+    large_object_space->Walk(walk_callback, &info_key);
+    // for (const auto& info : object_infomations) {
+
+    // }
+}
+
+void PrintNonMovingSpaceInformation(uint32_t info_key) {
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    gc::space::MallocSpace* non_moving_space = heap->GetNonMovingSpace();
+    // std::vector<ObjectInfo> object_infomations;
+    WalkCallback walk_callback = [](void* start, void* end, size_t /*num_bytes*/, void* info_key) {
+        if (start != end) {
+            size_t object_address, object_size;
+            object_address = reinterpret_cast<size_t>(start);
+            object_size = size_t(end) - size_t(start);
+            std::string space = "non_moving_space";
+            ObjectInfo info(object_address, object_size, std::move(space));
+            // object_infomations.emplace_back(ObjectInfo(object_address, object_size, std::move(space)));
+            LOG(INFO) << "jiacheng jiacheng_utils.cc 269 "
+                        << " key= " << *((uint32_t *)(info_key))
+                        << " info= " << info.ToString();
+        }
+    }; 
+    non_moving_space->Walk(walk_callback, &info_key);
+    // for (const auto& info : object_infomations) {
+    //     LOG(INFO) << "jiacheng jiacheng_utils.cc 269 "
+    //               << " key= " << info_key 
+    //               << " info= " << info.ToString();
+    // }
+}
+
+void PrintHeapObjectInformation() {
+    // std::vector<ObjectInfo> object_infomations;
+
+    // gc::Heap* heap = Runtime::Current()->GetHeap();
+    // Thread* self = Thread::Current();
+    // {
+    //     auto visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_) {
+    //         if (obj != nullptr) {
+    //             size_t object_address, object_size;
+    //             object_address = reinterpret_cast<size_t>(obj);
+    //             object_size = obj->SizeOf();
+    //             std::string space = GetSpaceFromObject(obj);
+    //             object_infomations.emplace_back(ObjectInfo(object_address, object_size, std::move(space)));
+    //         }
+    //     };        
+    //     ScopedObjectAccess soa(self);
+    //     heap->VisitObjects(visitor);
+    // }
+    // uint32_t key = GenerateRandomKey();
+    // for (const auto& info : object_infomations) {
+    //     LOG(INFO) << "jiacheng jiacheng_utils.cc 269 "
+    //               << " key= " << key 
+    //               << " info= " << info.ToString();
+    // }
+    uint32_t key = GenerateRandomKey();
+    PrintLargeObjectSpaceInformation(key);
+    PrintRegionSpaceInformation(key);
+    PrintNonMovingSpaceInformation(key);
+
+}
+
+void VisitMemMap(const MemMap* mem_map) {
+    LOG(INFO) << "jiacheng VisitMemMap ";
+    LOG(INFO) << (*mem_map);
+    uint8_t* begin = mem_map->Begin();
+    uint8_t* end = mem_map->End();
+    void* base_begin = mem_map->BaseBegin();
+    void* base_end = mem_map->BaseEnd();
+    LOG(INFO) << "begin= " << reinterpret_cast<size_t>(begin) << ' '
+              << "end= " << reinterpret_cast<size_t>(end) << ' '
+              << "base_begin= " << reinterpret_cast<size_t>(base_begin) << ' '
+              << "base_end= " << reinterpret_cast<size_t>(base_end);
+    // print every byte
+    // for(uint8_t* p = begin; p != end; ++p) {
+    //     LOG(INFO) << static_cast<int>(*p);
+    // }
+
+}
+
+template<size_t kAlignment>
+void VisitSpaceBitmap(const gc::accounting::SpaceBitmap<kAlignment>* ) {
+}
+
+void VisitHeapBitmap(const gc::accounting::HeapBitmap* ) {
+}
+
+void VisitRememberedSet(const gc::accounting::RememberedSet* remembered_set) {
+    LOG(INFO) << "jiacheng VisitRememberedSet ";
+    auto table = const_cast<gc::accounting::RememberedSet*>(remembered_set);
+    {
+        ReaderMutexLock mu(Thread::Current(), *Locks::mutator_lock_);
+        table->Dump(LOG_STREAM(INFO));
+    }
+
+}
+
+void VisitModUnionTableToZygoteAllocspace(const gc::accounting::ModUnionTable* mod_union_table) {
+    LOG(INFO) << "jiacheng VisitModUnionTableToZygoteAllocspace ";
+    auto table = const_cast<gc::accounting::ModUnionTableToZygoteAllocspace*>(static_cast<const gc::accounting::ModUnionTableToZygoteAllocspace*>(mod_union_table));
+    {
+        ReaderMutexLock mu(Thread::Current(), *Locks::mutator_lock_);
+        table->Dump(LOG_STREAM(INFO));
+    }
+}
+
+void VisitModUnionTableCardCache(const gc::accounting::ModUnionTable* mod_union_table) {
+    LOG(INFO) << "jiacheng VisitModUnionTableCardCache ";
+    auto table = const_cast<gc::accounting::ModUnionTableCardCache*>(static_cast<const gc::accounting::ModUnionTableCardCache*>(mod_union_table));
+    {
+        ReaderMutexLock mu(Thread::Current(), *Locks::mutator_lock_);
+        table->Dump(LOG_STREAM(INFO));
+    }
+}
+
+void VisitCardTable(const gc::accounting::CardTable* card_table) {
+    (void)card_table;
+    LOG(INFO) << "jiacheng VisitCardTable ";
+    // MemMap* mem_map = &(card_table->mem_map_);
+    // uint8_t* const biased_begin = card_table->biased_begin_;
+    // const size_t offset = card_table->offset_;
+
+    // VisitMemMap(mem_map);
+    // LOG(INFO) << "biased_begin= " << reinterpret_cast<size_t>(biased_begin);
+    // LOG(INFO) << "offset= " << offset;
+}
+
+void DebugPrintModUnionAndRememberSet() {
+    if (Runtime::Current()->IsZygote()) {
+        return;
+    }
+    if (!Runtime::Current()->InJankPerceptibleProcessState()) {
+      LOG(INFO) << "jiacheng " << "InJankPerceptibleProcessState" ;
+      return;
+    }
+    // if (jiacheng::CheckHot()) {
+    //   LOG(INFO) << "jiacheng " << "CheckHot";
+    //   return;
+    // }  
+
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+
+    Thread* self = Thread::Current();
+    const std::vector<gc::space::ContinuousSpace*>* continues_spaces;
+    {
+        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
+        continues_spaces = &(heap->GetContinuousSpaces());
+    }
+    for (auto space : *continues_spaces) {
+        LOG(INFO) << space->GetName();
+        gc::space::SpaceType space_type = space->GetType();
+        gc::accounting::ModUnionTable* mod_union_table = heap->FindModUnionTableFromSpace(space);
+        gc::accounting::RememberedSet* remembered_set = heap->FindRememberedSetFromSpace(space);
+        if (mod_union_table) {
+            LOG(INFO) << "jiacheng mod_union_table";
+            if (space_type == gc::space::kSpaceTypeZygoteSpace) {
+                VisitModUnionTableCardCache(mod_union_table);
+            } else if (space_type == gc::space::kSpaceTypeImageSpace) {
+                VisitModUnionTableToZygoteAllocspace(mod_union_table);
+            }
+        } 
+        if (remembered_set) {
+            LOG(INFO) << "jiacheng remembered_set";
+            VisitRememberedSet(remembered_set);
+        }
+        if (mod_union_table == nullptr && remembered_set == nullptr) {
+            LOG(INFO) << "nullptr";
+        }
+    }
+    const std::vector<gc::space::DiscontinuousSpace*>* discontinues_spaces = &(heap->GetDiscontinuousSpaces());
+    for (auto space : *discontinues_spaces) {
+        LOG(INFO) << space->GetName();
+        gc::accounting::ModUnionTable* mod_union_table = heap->FindModUnionTableFromSpace(space);
+        gc::accounting::RememberedSet* remembered_set = heap->FindRememberedSetFromSpace(space);
+        if (mod_union_table) {
+            LOG(INFO) << "jiacheng mod_union_table";
+        } 
+        if (remembered_set) {
+            LOG(INFO) << "jiacheng remembered_set";
+        }
+        if (mod_union_table == nullptr && remembered_set == nullptr) {
+            LOG(INFO) << "nullptr";
+        }
+    }
+}
+
+
+
+
+}
+}
\ No newline at end of file
diff --git a/runtime/jiacheng_debug.h b/runtime/jiacheng_debug.h
new file mode 100644
index 0000000000..67f2cb8d75
--- /dev/null
+++ b/runtime/jiacheng_debug.h
@@ -0,0 +1,63 @@
+#ifndef ART_RUNTIME_JIACHENG_DEBUG_H_
+#define ART_RUNTIME_JIACHENG_DEBUG_H_
+
+namespace art {
+
+namespace gc {
+namespace space {
+    class Space;
+} // namespace space
+namespace accounting {
+    template <size_t kAlignment> class SpaceBitmap;
+    class HeapBitmap;
+    class RememberedSet;
+    class ModUnionTable;
+    class CardTable;
+} // namespace accounting
+} // namespace gc
+
+namespace mirror {
+    class Object;
+} // namespace mirror
+
+class MemMap;
+
+namespace jiacheng {
+
+void RecordWorkingSet(mirror::Object* obj);
+
+void ClearAndPrintWorkingSet();
+
+void SwapOutAll();
+
+void SwapOutSpace(gc::space::Space* space);
+
+/* ------------------- debug --------------------- */
+
+std::string GetSpaceFromObject(mirror::Object* obj);
+
+void PrintHeapObjectInformation();
+
+void VisitMemMap(const MemMap* mem_map);
+
+template<size_t kAlignment>
+void VisitSpaceBitmap(const gc::accounting::SpaceBitmap<kAlignment>* );
+
+void VisitHeapBitmap(const gc::accounting::HeapBitmap* );
+
+void VisitRememberedSet(const gc::accounting::RememberedSet* remembered_set);
+
+void VisitModUnionTableToZygoteAllocspace(const gc::accounting::ModUnionTable* mod_union_table);
+
+void VisitModUnionTableCardCache(const gc::accounting::ModUnionTable* mod_union_table);
+
+void VisitCardTable(const gc::accounting::CardTable* card_table);
+
+void DebugPrintModUnionAndRememberSet();
+
+
+} // namespace jiacheng
+} // namespace art
+
+
+#endif
\ No newline at end of file
diff --git a/runtime/jiacheng_hack.cc b/runtime/jiacheng_hack.cc
index 5ed1982c64..1a573d317b 100644
--- a/runtime/jiacheng_hack.cc
+++ b/runtime/jiacheng_hack.cc
@@ -1,96 +1,66 @@
-#include <fstream>
-#include <thread>
-#include <chrono>
-#include <atomic>
 #include <string>
-#include <sys/mman.h>
 
+#include "runtime.h"
+#include "gc/heap.h"
+#include "gc/space/region_space.h"
+#include "gc/collector/garbage_collector.h"
+#include "base/utils.h"
+
+#include <sys/mman.h>
 
 #include "jiacheng_hack.h"
-#include "jiacheng_cold_space.h"
 #include "jiacheng_activity_manager.h"
 #include "jiacheng_utils.h"
 #include "jiacheng_profiler.h"
+#include "jiacheng_swapper.h"
+
 
-#include "gc/accounting/card_table.h"
-#include "gc/space/space-inl.h"
-#include "gc/heap.h"
-#include "gc/space/zygote_space.h"
-#include "gc/space/bump_pointer_space-inl.h"
-#include "gc/space/bump_pointer_space-walk-inl.h"
-#include "gc/space/dlmalloc_space-inl.h"
-#include "gc/space/image_space.h"
-#include "gc/space/large_object_space.h"
-#include "gc/space/malloc_space.h"
-#include "gc/space/region_space-inl.h"
-#include "gc/space/rosalloc_space-inl.h"
-#include "mirror/class-inl.h"
-#include "obj_ptr-inl.h"
-#include "scoped_thread_state_change-inl.h"
-#include "thread_list.h"
-#include "gc/accounting/mod_union_table-inl.h"
-#include "gc/accounting/remembered_set.h"
-#include "base/mutex.h"
 
-#include "read_barrier_config.h"
 
 namespace art{
 namespace jiacheng {
 
 typedef void(*WalkCallback)(void *start, void *end, size_t num_bytes, void* callback_arg);
 
+bool HandleFault(int sig, siginfo_t* info, void* context) {
+    (void)context;
+    if (!IsWhiteApp()) {
+        return false;
+    }
+    LOG(INFO) << " jiacheng fault_handler.cc HandleFault()" 
+            << " sig= " << sig
+            << " info->si_addr= " << reinterpret_cast<mirror::Object*>(info->si_addr)
+            << " info->si_signo= " << info->si_signo
+            << " info->si_errno= " << info->si_errno
+            << " info->si_code= " << info->si_code
+            ;
+    mirror::Object *ref = reinterpret_cast<mirror::Object *>(info->si_addr);
+
+    gc::space::RegionSpace* region_space = Runtime::Current()->GetHeap()->GetRegionSpace();
+    if (region_space->HasAddress(ref)) {
+        region_space->HandleFault(ref);
+        return true;
+    } else {
+        return false;
+    }
+}
+
 // 在App启动的main函数中调用该函数
 void OnAppStart() {
-    Runtime* runtime = Runtime::Current();
-    const std::string& process_package_name = runtime->GetProcessPackageName();
-
-    LOG(INFO) << "jiacheng jiacheng_hack.cc 53" 
-              << " OnAppStart()"
-              << " process_package_name= " << process_package_name
-              ;
-    // 在APP启动时，异步调用
-    auto func = [&]()->void {
-        // ActivityManager* activity_manager = ActivityManager::Current();
-        for (;;) {
-            // if (!activity_manager->GetInGC()) {
-            //     SwapOut();
-            //     LOG(INFO) << "jiacheng jiacheng_hack.cc 144 执行换出!";
-            // }
-
-            gc::Heap* heap = runtime->GetHeap();
-            heap->JiachengDebug();
-
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-            CurrentThreadSleepNano(1000000000);
-        }
-    };
-    std::thread on_app_start_thread(func);
-    on_app_start_thread.detach();
+    if (!IsWhiteApp()) {
+        return;
+    }
+    LOG(INFO) << "jiacheng jiacheng_hack.cc OnAppStart()"
+              << " package_name= " << GetCurrentPackageName();
+    Profiler* profiler = Profiler::Current();
+    profiler->SetStartTime(art::NanoTime());
+    (void)profiler;
+    
+    Swapper* swapper = Swapper::Current();
+    (void)swapper;
 }
 
-/* 
- * AMS通过在系统启动的时候注册的service调用该函数
- * enum ActivityState {
- *     INITIALIZING, 0
- *     RESUMED, 1
- *     PAUSING, 2
- *     PAUSED, 3 
- *     STOPPING, 4
- *     STOPPED, 5
- *     FINISHING, 6
- *     DESTROYING, 7
- *     DESTROYED 8
- *}
- */
+// AMS通过在系统启动的时候注册的service调用该函数
 void UpdateActivityState(const char* package_name, const char* activity_name, int state) { 
     (void)package_name;
     std::string name(activity_name);
@@ -98,212 +68,99 @@ void UpdateActivityState(const char* package_name, const char* activity_name, in
 }
 
 
-/*
- * 每次GC开始的时候，调用该方法
- */
-void BeforeGarbageCollectorRun(const gc::collector::GarbageCollector* collector) {
-    LOG(INFO) << "jiacheng" << " BeforeGarbageCollectorRun" 
-              << " NanoTime= " << NanoTime()
-              << " GarbageCollector.GetName()= " << collector->GetName()
-              << " GetGcType()= " << collector->GetGcType();
-
-    // ActivityManager* activity_manager = ActivityManager::Current();
-    // (void)activity_manager;
-
-    // Profiler* profiler = Profiler::Current();
-    // profiler->SetDuringGcFlag();
-    // profiler->JiachengDebug();
-    // profiler->ClearReadWorkingSet();
-    // profiler->ClearGcWorkingSet();
-
-}
+void UpdataAppState(ProcessState old_process_state, ProcessState new_process_state) {
+    if (!IsWhiteApp()) {
+        return;
+    }
+    Profiler* profiler = Profiler::Current();
+    uint64_t start_time = profiler->GetStartTime();
+    if (start_time == 0 || art::NanoTime() - start_time < 1000000000) {
+        return;
+    }
 
-/*
- * 每次GC结束的时候，调用该方法
- */
-void AfterGarbageCollectorRun(const gc::collector::GarbageCollector* collector) {
-    // ActivityManager* activity_manager = ActivityManager::Current();
-    // Debug();
-    // SwapOut();
-    // activity_manager->ForgetWorkingSet();
-    // ColdSpace::Current()->ResetMarkBitmap();
-    const gc::collector::Iteration* iteration = collector->GetCurrentIteration();
-    
-    LOG(INFO) << "jiacheng" << " AfterGarbageCollectorRun" 
-              << " NanoTime= " << NanoTime()
-              << " GcCause= " << iteration->GetGcCause()
-              << " GetGcType= " << collector->GetGcType();
+    std::string package_name = GetCurrentPackageName();
+    LOG(INFO) << "jiacheng jiacheng_hack.cc 111 UpdataAppState() "
+              << " package_name= " << package_name 
+              << " old_process_state= " << old_process_state
+              << " new_process_state= " << new_process_state
+              ;
 
-    // Profiler* profiler = Profiler::Current();
-    // profiler->ClearDuringGcFlag();
-    // profiler->IncreaseGcNumber();
-    // profiler->InitColdSet();
-    // profiler->JiachengDebug();
+    if (new_process_state == kProcessStateJankImperceptible) {
+        profiler->ClearPerceptibleFlag();
+    } else {
+        profiler->SetPerceptibleFlag();
+    }
 
-    // profiler->ClearReadWorkingSet();
-    // profiler->ClearGcWorkingSet();
 }
 
-/*
- * 每次发生读屏障的时候，调用该方法
- */
-
-void ReadBarrierTrigger(mirror::Object* obj) {
-    (void)obj;
-    if (Runtime::Current()->IsZygote()) {
+// 每次GC开始的时候，调用该方法
+void BeforeGarbageCollectorRun(const gc::collector::GarbageCollector* collector) {
+    if (!IsWhiteApp()) {
         return;
     }
-    // if (!Runtime::Current()->InJankPerceptibleProcessState()) {
-    //     return;
-    // }
-
-    // com.jiacheng.activitylifecycletest = 34
-    // com.taobao.taobao = 17
-    // const std::string& package_name = Runtime::Current()->GetProcessPackageName();
-    // if (!(package_name.length() == 17 && package_name[4] == 't')) { 
-    //     return;
-    // }
+    LOG(INFO) << "jiacheng jiacheng_hack.cc 89 BeforeGarbageCollectorRun()" 
+              << " NanoTime= " << NanoTime()
+              << " GarbageCollector.GetName()= " << collector->GetName()
+              << " GetGcType()= " << collector->GetGcType();
 
     Profiler* profiler = Profiler::Current();
-    (void)profiler;
-
-    // profiler->RecordReadWorkingSet(obj);
-    // ActivityManager::Current()->RecordWS(obj);
-
+    profiler->SetDuringGcFlag();
 }
 
-void GCMarkTrigger(mirror::Object* obj) {
-    (void)obj;
-    if (Runtime::Current()->IsZygote()) {
+// 每次GC结束的时候，调用该方法
+void AfterGarbageCollectorRun(const gc::collector::GarbageCollector* collector) {
+    if (!IsWhiteApp()) {
         return;
     }
-    // if (!Runtime::Current()->InJankPerceptibleProcessState()) {
-    //     return;
-    // }
+    const gc::collector::Iteration* iteration = collector->GetCurrentIteration();
     
-    // com.jiacheng.activitylifecycletest = 34
-    // com.taobao.taobao = 17
-    // const std::string& package_name = Runtime::Current()->GetProcessPackageName();
-    // if (!(package_name.length() == 17 && package_name[4] == 't')) { 
-    //     return;
-    // }
+    LOG(INFO) << "jiacheng jiacheng_hack.cc 106 AfterGarbageCollectorRun()" 
+              << " NanoTime= " << NanoTime()
+              << " GcCause= " << iteration->GetGcCause()
+              << " GetGcType= " << collector->GetGcType();
 
     Profiler* profiler = Profiler::Current();
-    (void)profiler;
-
-    // profiler->RecordGcWorkingSet(obj);
-}
+    profiler->IncreaseGcNumber();
+    profiler->ClearDuringGcFlag();
+    
+    profiler->JiachengDebug();
 
-void Debug() {
-    ColdSpace::Current()->JiachengDebug();
-    ActivityManager::Current()->JiachengDebug();
+    // profiler->ClearAccessWS();
+    profiler->ClearGcWS();
 
-    Runtime* runtime = Runtime::Current();
-    gc::Heap* heap = runtime->GetHeap();
 
-    heap->JiachengDebug();
+    Runtime::Current()->GetHeap()->GetRegionSpace()->InitColdToRegionRememberedSet();
+    // jiacheng debug start
+    Runtime::Current()->GetHeap()->GetRegionSpace()->JiachengDebug();
+    // jiacheng debug end
 }
 
-// 对ColdSpace中的Region进行Swap
-void SwapOut() {
-    if (Runtime::Current()->IsZygote()) {
+// GC访问内存的时候，调用该方法
+// 1. Copy过程的from_ref和to_ref
+// 2. Scan过程
+void GCAccessTrigger(mirror::Object* obj) {
+    if (!obj) {
         return;
     }
-    // if (activity_set.size() < 2 || GC_time.load() < 10) {
-    //     return;
-    // }
-    if (Runtime::Current()->InJankPerceptibleProcessState()) {
+    if (!IsWhiteApp()) {
         return;
     }
-    // com.jiacheng.activitylifecycletest = 34
-    // com.taobao.taobao = 17
-    // const std::string& package_name = Runtime::Current()->GetProcessPackageName();
-    // if (!(package_name.length() == 17 && package_name[4] == 't')) { 
-    //     return;
-    // }
+    Profiler* profiler = Profiler::Current();
+    profiler->RecordGcWS(obj);
+}
 
-    // 对所有Space中的对象进行Swap
-    gc::Heap* heap = Runtime::Current()->GetHeap();
-    Thread* self = Thread::Current();
-    const std::vector<gc::space::ContinuousSpace*>* continues_spaces;
-    {
-        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
-        continues_spaces = &(heap->GetContinuousSpaces());
-    }
-    for (auto space : *continues_spaces) {
-        LOG(INFO) << "jiacheng_hack.cc 185 SwapOut() continues_spaces " << space->GetName();
-        madvise(space->Begin(), space->Size(), 233);
-        // SwapOutSpace(space);
-    }
-    const std::vector<gc::space::DiscontinuousSpace*>& discontinues_spaces = heap->GetDiscontinuousSpaces();
-    for (auto space : discontinues_spaces) {
-        SwapOutSpace(space);
-    }    
+void JiachengDebug() {
+    // ActivityManager::Current()->JiachengDebug();
+    LOG(INFO) << "jiacheng jiacheng_hack.cc 177 Debug() "
+              << "CodeGeneratorARM64::MarkGCCard()";
+    // Runtime* runtime = Runtime::Current();
+    // gc::Heap* heap = runtime->GetHeap();
 
-    // 不直接使用SwapOutSpace()函数对所有Space中的对象进行Swap
-    // LOG(INFO) << "jiacheng jiacheng_hack.cc 180 SwapOut()";
-    // ColdSpace* cold_space = ColdSpace::Current();
-    // cold_space->SwapOut();
+
+    // heap->JiachengDebug();
 }
 
 
-void SwapOutSpace(gc::space::Space* space) {
-    Thread* self = Thread::Current();
-    gc::space::SpaceType space_type = space->GetType();
-    
-    WalkCallback walk_callback = [](void* start, void* end, size_t /*num_bytes*/, void* ) {
-        // if (start != end && ActivityManager::Current()->ShouldSwapOut(reinterpret_cast<mirror::Object*>(start))) {
-        if (start != end) {
-            LOG(INFO) << "jiacheng_hack.cc 143 ShouldSwapOut() obj= " << size_t(start) << " size= " << size_t(end) - size_t(start);
-            madvise(start, reinterpret_cast<size_t>(end) - reinterpret_cast<size_t>(start), 233);
-        }
-    };    
-    auto visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_){
-        // if (obj && ActivityManager::Current()->ShouldSwapOut(obj)) {
-        if (obj) {
-            LOG(INFO) << "jiacheng_hack.cc 150 ShouldSwapOut() obj= " << size_t(obj) << " size= " << obj->SizeOf();
-            madvise(static_cast<void *>(obj), obj->SizeOf(), 233);
-        }
-    };
-    switch (space_type) {
-        case gc::space::kSpaceTypeImageSpace: {
-            // gc::space::ImageSpace* this_space = space->AsImageSpace();
-            break;
-        }
-        case gc::space::kSpaceTypeMallocSpace: {
-            gc::space::MallocSpace* this_space = space->AsMallocSpace();
-            this_space->Walk(walk_callback, nullptr);
-            break;
-        }
-        case gc::space::kSpaceTypeZygoteSpace: {
-            // gc::space::ZygoteSpace* this_space = space->AsZygoteSpace();
-            break;
-        }
-        case gc::space::kSpaceTypeBumpPointerSpace: {
-            gc::space::BumpPointerSpace* this_space = space->AsBumpPointerSpace();
-            { 
-                WriterMutexLock mu(self, *Locks::mutator_lock_);  
-                this_space -> Walk(visitor);
-            }
-            break;
-        }
-        case gc::space::kSpaceTypeLargeObjectSpace: {
-            gc::space::LargeObjectSpace* this_space = space->AsLargeObjectSpace();
-            this_space->Walk(walk_callback, nullptr);
-            break;
-        }
-        case gc::space::kSpaceTypeRegionSpace: {
-            gc::space::RegionSpace* this_space = space->AsRegionSpace();   
-            {
-                WriterMutexLock mu(self, *Locks::mutator_lock_);  
-                this_space -> Walk(visitor);
-            }
-            break;
-        }
-        default:
-            LOG(INFO) << "jiacheng " << "jiacheng_hack.cc 100. Can not find space.";
-    }
-}
 
 } // namespace jiacheng
 } // namespace art
diff --git a/runtime/jiacheng_hack.h b/runtime/jiacheng_hack.h
index 7737067873..fbe645e66e 100644
--- a/runtime/jiacheng_hack.h
+++ b/runtime/jiacheng_hack.h
@@ -1,70 +1,38 @@
-#ifndef JIACHENG_HACK_H_
-#define JIACHENG_HACK_H_
+#ifndef ART_RUNTIME_JIACHENG_HACK_H_
+#define ART_RUNTIME_JIACHENG_HACK_H_
 
-#include <set>
+#include "process_state.h"
+#include "signal.h"
 
 namespace art{
 
 namespace gc {
-namespace accounting {
-template<size_t kAlignment> class SpaceBitmap;
-class HeapBitmap;
-class RememberedSet;
-class ModUnionTable;
-class CardTable;
-} // namespace accounting
-
-namespace space {
-class Space;
-class ImageSpace;
-class MallocSpace;
-class ZygoteSpace;
-class BumpPointerSpace;
-class LargeObjectSpace;
-class RegionSpace;
-} // namespace space
-
 namespace collector {
 class GarbageCollector;
 } // namespace collector
-
-class Heap;
-
 } // namespace gc
 
 namespace mirror {
-class Class;
 class Object;
-template<class T> class ObjectArray;
-}  // namespace mirror
-
-class Thread;
-class MemMap;
-class MemberOffset;
+} // namespace mirror
 
 namespace jiacheng {
 
-// ---------------- 前端事件 --------------
+bool HandleFault(int sig, siginfo_t* info, void* context);
+
 void OnAppStart();
 
 void UpdateActivityState(const char* package_name, const char* activity_name, int state);
 
-// ---------------- ART事件 --------------
+void UpdataAppState(ProcessState old_process_state, ProcessState new_process_state);
+
 void BeforeGarbageCollectorRun(const gc::collector::GarbageCollector* collector);
 
 void AfterGarbageCollectorRun(const gc::collector::GarbageCollector* collector);
 
-void ReadBarrierTrigger(mirror::Object* obj);
-
-void GCMarkTrigger(mirror::Object* obj);
-
-// ---------------- 内部调用 --------------
-void Debug();
-
-void SwapOut();
-
-void SwapOutSpace(gc::space::Space* space);
+void GCAccessTrigger(mirror::Object* obj);
 
+void JiachengDebug();
 
 } // namespace jiacheng
 } // namespace art
diff --git a/runtime/jiacheng_profiler.cc b/runtime/jiacheng_profiler.cc
index cddaa2e394..42c2c6cdae 100644
--- a/runtime/jiacheng_profiler.cc
+++ b/runtime/jiacheng_profiler.cc
@@ -1,13 +1,35 @@
 #include "jiacheng_profiler.h"
+#include "jiacheng_utils.h"
+#include "jiacheng_debug.h"
 
 #include "thread-inl.h"
 
 namespace art {
 namespace jiacheng {
 
+
 Mutex Profiler::singleton_lock_("Profiler Singleton Lock", kLoggingLock);
 Profiler* Profiler::instance_(nullptr); 
 
+Profiler::Profiler():
+    access_bloom_filter_(1000000, 1e-4),
+    read_working_set_(),
+    read_working_set_lock_("read_working_set_lock", kJiachengWorkingSetLock),
+    access_working_set_size_(0),
+    gc_bloom_filter_(1000000, 1e-4),
+    gc_working_set_(),
+    gc_working_set_lock_("gc_working_set_lock", kJiachengWorkingSetLock),
+    gc_working_set_size_(0),
+    cold_set_(),
+    cold_set_lock_("cold_set_lock", kJiachengColdSpaceLock),
+    during_gc_flag_(false),
+    perceptible_flag_(true),
+    gc_number_(0),
+    start_time_(0) {
+}
+
+Profiler::~Profiler() = default;
+
 Profiler* Profiler::Create() {
     Profiler* it = new Profiler();
     return it;
@@ -25,70 +47,72 @@ Profiler* Profiler::Current() {
     return instance_;
 }
 
-Profiler::Profiler():
-    read_working_set_(),
-    read_working_set_lock_("read_working_set_lock", kJiachengWorkingSetLock),
-    gc_working_set_(),
-    gc_working_set_lock_("gc_working_set_lock", kJiachengWorkingSetLock),
-    cold_set_(),
-    cold_set_lock_("cold_set_lock", kJiachengColdSpaceLock),
-    during_gc_flag_(false),
-    gc_number_(0) {
-}
-
-Profiler::~Profiler() = default;
-
 void Profiler::JiachengDebug() {
-    Thread* self = Thread::Current();
-
-    gc_working_set_lock_.ExclusiveLock(self);
-    size_t gc_working_set_size = gc_working_set_.size();
-    gc_working_set_lock_.ExclusiveUnlock(self);
-
-    read_working_set_lock_.ExclusiveLock(self);
-    size_t read_working_set_size = read_working_set_.size();
-    read_working_set_lock_.ExclusiveUnlock(self);
-
-    cold_set_lock_.ExclusiveLock(self);
-    size_t cold_set_size = cold_set_.size();
-    cold_set_lock_.ExclusiveUnlock(self);
-
     LOG(INFO) << "jiacheng jiacheng_profiler.cc 39" 
-              << " gc_working_set_.size()= " << gc_working_set_size
-              << " read_working_set_.size()= " << read_working_set_size
-              << " cold_set_.size()= " << cold_set_size
+              << " access_working_set_size= " << access_working_set_size_.load()
+              << " gc_working_set_size_= " << gc_working_set_size_.load()
               << " during_gc_flag_= " << during_gc_flag_.load()
+              << " perceptible_flag_= " << perceptible_flag_.load()
               << " gc_number_= " << gc_number_.load()
+              << std::flush
               ;
 }
 
+void Profiler::RecordAccessWS(mirror::Object* obj) {
+    // Thread* self = Thread::Current();
+    // read_working_set_lock_.ExclusiveLock(self);
+    // read_working_set_.insert(obj);
+    // read_working_set_lock_.ExclusiveUnlock(self);
 
-void Profiler::RecordReadWorkingSet(mirror::Object* obj) {
-    Thread* self = Thread::Current();
-    read_working_set_lock_.ExclusiveLock(self);
-    read_working_set_.insert(obj);
-    read_working_set_lock_.ExclusiveUnlock(self);
+    if (!access_bloom_filter_.Add(reinterpret_cast<uint64_t>(obj))) {
+        access_working_set_size_.fetch_add(1);
+    }
 }
 
-void Profiler::ClearReadWorkingSet() {
-    Thread* self = Thread::Current();
-    read_working_set_lock_.ExclusiveLock(self);
-    read_working_set_.clear();
-    read_working_set_lock_.ExclusiveUnlock(self);
+void Profiler::ClearAccessWS() {
+    // Thread* self = Thread::Current();
+    // read_working_set_lock_.ExclusiveLock(self);
+    // read_working_set_.clear();
+    // read_working_set_lock_.ExclusiveUnlock(self);
+
+    access_bloom_filter_.Clear();
+    access_working_set_size_.store(0);
 }
 
-void Profiler::RecordGcWorkingSet(mirror::Object* obj) {
-    Thread* self = Thread::Current();
-    gc_working_set_lock_.ExclusiveLock(self);
-    gc_working_set_.insert(obj);
-    gc_working_set_lock_.ExclusiveUnlock(self);
+bool Profiler::TestInAccessWS(mirror::Object* obj) {
+    // Thread* self = Thread::Current();
+    // read_working_set_lock_.ExclusiveLock(self);
+    // bool result = (read_working_set_.find(obj) != read_working_set_.end());
+    // read_working_set_lock_.ExclusiveUnlock(self);
+    return access_bloom_filter_.Check(reinterpret_cast<uint64_t>(obj));
 }
 
-void Profiler::ClearGcWorkingSet() {
-    Thread* self = Thread::Current();
-    gc_working_set_lock_.ExclusiveLock(self);
-    gc_working_set_.clear();
-    gc_working_set_lock_.ExclusiveUnlock(self);
+
+void Profiler::RecordGcWS(mirror::Object* obj) {
+    // Thread* self = Thread::Current();
+    // gc_working_set_lock_.ExclusiveLock(self);
+    // gc_working_set_.insert(obj);
+    // gc_working_set_lock_.ExclusiveUnlock(self);
+    if (!gc_bloom_filter_.Add(reinterpret_cast<uint64_t>(obj))) {
+        gc_working_set_size_.fetch_add(1);
+    }
+}
+
+void Profiler::ClearGcWS() {
+    // Thread* self = Thread::Current();
+    // gc_working_set_lock_.ExclusiveLock(self);
+    // gc_working_set_.clear();
+    // gc_working_set_lock_.ExclusiveUnlock(self);
+    gc_bloom_filter_.Clear();
+    gc_working_set_size_.store(0);
+}
+
+bool Profiler::TestInGcWS(mirror::Object* obj) {
+    // Thread* self = Thread::Current();
+    // gc_working_set_lock_.ExclusiveLock(self);
+    // bool result = (gc_working_set_.find(obj) != gc_working_set_.end());
+    // gc_working_set_lock_.ExclusiveUnlock(self);
+    return gc_bloom_filter_.Check(reinterpret_cast<uint64_t>(obj));
 }
 
 void Profiler::SetDuringGcFlag() {
@@ -99,8 +123,35 @@ void Profiler::ClearDuringGcFlag() {
     during_gc_flag_.store(0);
 }
 
-bool Profiler::GetDuringGcFlag() {
-    return during_gc_flag_.load();
+// bool Profiler::GetDuringGcFlag() {
+//     return during_gc_flag_.load();
+// }
+
+void Profiler::SetPerceptibleFlag() {
+    perceptible_flag_.store(1);
+}
+
+void Profiler::ClearPerceptibleFlag() {
+    perceptible_flag_.store(0);
+}
+
+bool Profiler::GetPerceptibleFlag() {
+    return perceptible_flag_.load();
+}
+
+bool Profiler::ShouldSwapOut(mirror::Object* obj) {
+    // jiacheng debug start
+    if(!IsWhiteApp()) {
+        return false;
+    }
+    if (GetPerceptibleFlag()) {
+        return false;
+    }
+    return !TestInAccessWS(obj);
+
+    // (void)obj;
+    // return false;
+    // jiacheng debug end
 }
 
 void Profiler::IncreaseGcNumber() {
@@ -111,38 +162,14 @@ uint32_t Profiler::GetGcNumber() {
     return gc_number_.load();
 }
 
-void Profiler::InitColdSet() {
-    Thread* self = Thread::Current();
-    cold_set_lock_.ExclusiveLock(self);
-    cold_set_.clear();
 
-    // GC工作集 - Read工作集
-    gc_working_set_lock_.ExclusiveLock(self);
-    for (mirror::Object* obj : gc_working_set_) {
-        cold_set_.insert(obj);
-    }
-    gc_working_set_lock_.ExclusiveUnlock(self);
-
-    read_working_set_lock_.ExclusiveLock(self);
-    for (mirror::Object* obj : read_working_set_) {
-        cold_set_.erase(obj);
-    }
-    read_working_set_lock_.ExclusiveUnlock(self);
-    
-    cold_set_lock_.ExclusiveUnlock(self);
+void Profiler::SetStartTime(uint64_t start_time) {
+    start_time_.store(start_time);
 }
 
-bool Profiler::ShouldSwapOut(mirror::Object* obj) {
-    (void)obj;
-    // Thread* self = Thread::Current();
-    // cold_set_lock_.ExclusiveLock(self);
-    // bool res = cold_set_.find(obj) != cold_set_.end();
-    // cold_set_lock_.ExclusiveUnlock(self);
-    // return res;
-    return false;
+uint64_t Profiler::GetStartTime() {
+    return start_time_.load();
 }
-
-
  
 } // namespace jiacheng
 } // namespace art
\ No newline at end of file
diff --git a/runtime/jiacheng_profiler.h b/runtime/jiacheng_profiler.h
index 44076311df..500cbd55c7 100644
--- a/runtime/jiacheng_profiler.h
+++ b/runtime/jiacheng_profiler.h
@@ -7,6 +7,8 @@
 
 #include "base/mutex.h"
 
+#include "jiacheng_bloom_filter.h"
+
 namespace art {
 
 namespace mirror {
@@ -21,6 +23,7 @@ public:
     static Profiler* instance_; 
 
     static Profiler* Create();
+
     static Profiler* Current();
 
     Profiler();
@@ -28,36 +31,47 @@ public:
 
     void JiachengDebug();
 
-    void RecordReadWorkingSet(mirror::Object* obj);
-
-    void ClearReadWorkingSet();
-
-    void RecordGcWorkingSet(mirror::Object* obj);
+    // Mutator的工作集估计
+    void RecordAccessWS(mirror::Object* obj);
+    void ClearAccessWS();
+    bool TestInAccessWS(mirror::Object* obj);
 
-    void ClearGcWorkingSet();
+    // GC的工作集估计
+    void RecordGcWS(mirror::Object* obj);
+    void ClearGcWS();
+    bool TestInGcWS(mirror::Object* obj);
 
     void SetDuringGcFlag();
-
     void ClearDuringGcFlag();
 
-    bool GetDuringGcFlag();
+    bool GetDuringGcFlag() {
+        return during_gc_flag_.load();
+    }
 
-    void IncreaseGcNumber();
+    void SetPerceptibleFlag();
+    void ClearPerceptibleFlag();
+    bool GetPerceptibleFlag();
 
-    uint32_t GetGcNumber();
+    bool ShouldSwapOut(mirror::Object* obj);
 
-    void InitColdSet();
+    void IncreaseGcNumber();
+    uint32_t GetGcNumber();
 
-    bool ShouldSwapOut(mirror::Object* obj);
+    void SetStartTime(uint64_t start_time);
+    uint64_t GetStartTime();
 
 private:
-    // Mutator的Read Working Set
+    // Mutator的Working Set
+    BloomFilter access_bloom_filter_;
     std::set<mirror::Object*> read_working_set_;
     Mutex read_working_set_lock_;
+    std::atomic<uint32_t> access_working_set_size_;
 
-    // GC的Read Working Set
+    // GC的Working Set
+    BloomFilter gc_bloom_filter_;
     std::set<mirror::Object*> gc_working_set_;
     Mutex gc_working_set_lock_;
+    std::atomic<uint32_t> gc_working_set_size_;
 
     // 需要换出去的对象集合Cold Set
     std::set<mirror::Object*> cold_set_;
@@ -66,8 +80,15 @@ private:
     // 每次GC开始的时候设置为true, GC结束的时候设置为false
     std::atomic<bool> during_gc_flag_;
 
+    // APP当前在前台还是后台
+    std::atomic<bool> perceptible_flag_;
+
     // 历史GC发生的总次数
     std::atomic<uint32_t> gc_number_;
+
+    std::atomic<uint64_t> start_time_;
+
+
 };
 
 }
diff --git a/runtime/jiacheng_region.cc b/runtime/jiacheng_region.cc
deleted file mode 100644
index fd954565e8..0000000000
--- a/runtime/jiacheng_region.cc
+++ /dev/null
@@ -1,41 +0,0 @@
-#include "jiacheng_region.h"
-
-namespace art {
-namespace jiacheng {
-
-Region::Region():idx_(-1),begin_(nullptr),top_(nullptr),end_(nullptr) {
-}
-
-Region::~Region() {}
-
-void Region::Init(size_t idx, uint8_t* begin, uint8_t* end) {
-    idx_ = idx;
-    begin_ = begin;
-    top_.store(begin);
-    end_ = end;
-}
-
-mirror::Object* Region::Alloc(size_t num_bytes) {
-    uint8_t* old_top;
-    uint8_t* new_top;
-
-    old_top = top_.load();
-    new_top = old_top + num_bytes;
-    if (new_top > end_) {
-        return nullptr;
-    }
-    top_.store(new_top);
-    return reinterpret_cast<mirror::Object*>(old_top);
-}
-
-void Region::Clear() {
-    top_.store(begin_);
-}
-
-bool Region::IsFree() const {
-    return top_.load() == begin_;
-}
-
-
-} // namespace jiacheng
-} // namespace art
\ No newline at end of file
diff --git a/runtime/jiacheng_region.h b/runtime/jiacheng_region.h
deleted file mode 100644
index fedfb28994..0000000000
--- a/runtime/jiacheng_region.h
+++ /dev/null
@@ -1,59 +0,0 @@
-#ifndef JIACHENG_REGION_H_
-#define JIACHENG_REGION_H_
-
-#include <atomic>
-
-namespace art{
-namespace mirror {
-    class Object;
-}
-
-// ------------ START -------------
-namespace jiacheng {
-
-class Region {
-public:
-    Region();
-    ~Region();
-
-    void Init(size_t idx, uint8_t* begin, uint8_t* end);
-
-    mirror::Object* Alloc(size_t num_bytes);
-
-    void Clear();
-
-    bool IsFree() const;
-
-    size_t Idx() const {
-        return idx_;
-    }
-
-    uint8_t* Begin() const {
-        return begin_;
-    }
-
-    uint8_t* Top() const {
-        return top_.load();
-    }
-
-    uint8_t* End() const {
-        return end_;
-    }
-
-    bool Contains(mirror::Object* ref) const {
-        return begin_ <= reinterpret_cast<uint8_t*>(ref) && reinterpret_cast<uint8_t*>(ref) < end_;
-    }
-
-// ---------------- 变量开始 ----------------------
-
-    size_t idx_;                        // 该Region在ColdSpace中的索引
-    uint8_t* begin_;                    // 这个Region的起始地址
-    std::atomic<uint8_t*> top_;         // Allocation的位置
-    uint8_t* end_;                      // 这个Region的结束地址
-
-};
-
-
-} // namespace jiacheng
-} // namespace art
-#endif
\ No newline at end of file
diff --git a/runtime/jiacheng_swapper.cc b/runtime/jiacheng_swapper.cc
new file mode 100644
index 0000000000..9755a4688c
--- /dev/null
+++ b/runtime/jiacheng_swapper.cc
@@ -0,0 +1,187 @@
+#include "jiacheng_swapper.h"
+
+#include "jiacheng_profiler.h"
+#include "jiacheng_utils.h"
+#include "jiacheng_debug.h"
+
+#include "thread-inl.h"
+#include "runtime.h"
+#include "gc/heap.h"
+#include "gc/space/space-inl.h"
+#include "gc/space/region_space.h"
+#include "gc/space/image_space.h"
+#include "gc/space/malloc_space.h"
+#include "gc/space/zygote_space.h"
+#include "gc/space/bump_pointer_space.h"
+#include "gc/space/large_object_space.h"
+
+namespace art {
+namespace jiacheng {
+
+typedef void(*WalkCallback)(void *start, void *end, size_t num_bytes, void* callback_arg);
+
+Mutex Swapper::singleton_lock_("Swapper Singleton Lock", kLoggingLock);;
+Swapper* Swapper::instance_(nullptr); 
+
+Swapper* Swapper::Create() {
+    Swapper* it = new Swapper();
+    it->Start();
+    return it;
+}
+
+Swapper* Swapper::Current() {
+    if (instance_ == nullptr) {
+        Thread* self = Thread::Current();
+        singleton_lock_.ExclusiveLock(self);
+        if (instance_ == nullptr) {
+            instance_ = Create();
+        }
+        singleton_lock_.ExclusiveUnlock(self);
+    }
+    return instance_;
+}
+
+Swapper::Swapper():swap_thread_(nullptr) {}
+
+Swapper::~Swapper() = default;
+
+
+void Swapper::Run() {
+    Profiler* profiler = Profiler::Current();
+    bool gc_flag, perceptible_flag;
+    while (true) {
+        CurrentThreadSleepSecond(30);
+        gc_flag = profiler->GetDuringGcFlag();
+        perceptible_flag = profiler->GetPerceptibleFlag();
+        LOG(INFO) << "jiacheng jiacheng_swapper.cc 43 Run() swapper thread" 
+                  << " gc_flag= " << gc_flag
+                  << " perceptible_flag= " << perceptible_flag
+                  ;
+        if (!gc_flag && !perceptible_flag) {
+            // jiacheng debug start
+            // SwapOutHeap();
+            // jiacheng debug end
+        }
+        profiler->JiachengDebug();
+        profiler->ClearAccessWS();
+
+        // jiacheng debug start
+        // ClearAndPrintWorkingSet();
+        // jiacheng debug end
+    }
+}
+
+void Swapper::Start() {
+    swap_thread_ = new std::thread(&Swapper::Run, this);
+    swap_thread_->detach();
+}
+
+void Swapper::SwapOutHeap() {
+    gc::Heap* heap = Runtime::Current()->GetHeap();
+    Thread* self = Thread::Current();
+    const std::vector<gc::space::ContinuousSpace*>* continues_spaces;
+    {
+        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
+        continues_spaces = &(heap->GetContinuousSpaces());
+    }
+    for (gc::space::ContinuousSpace* space : *continues_spaces) {
+        switch (space->GetType()) {
+            case gc::space::kSpaceTypeImageSpace: {
+                gc::space::ImageSpace* this_space = space->AsImageSpace();
+                SwapOutImageSpace(this_space);
+                break;
+            }
+            case gc::space::kSpaceTypeMallocSpace: {
+                gc::space::MallocSpace* this_space = space->AsMallocSpace();
+                SwapOutMallocSpace(this_space);
+                break;
+            }
+            case gc::space::kSpaceTypeZygoteSpace: {
+                gc::space::ZygoteSpace* this_space = space->AsZygoteSpace();
+                SwapOutZygoteSpace(this_space);
+                break;
+            }
+            case gc::space::kSpaceTypeBumpPointerSpace: {
+                gc::space::BumpPointerSpace* this_space = space->AsBumpPointerSpace();
+                SwapOutBumpPointerSpace(this_space);
+                break;
+            }
+            case gc::space::kSpaceTypeLargeObjectSpace: {
+                gc::space::LargeObjectSpace* this_space = space->AsLargeObjectSpace();
+                SwapOutLargeObjectSpace(this_space);
+                break;
+            }
+            case gc::space::kSpaceTypeRegionSpace: {
+                gc::space::RegionSpace* this_space = space->AsRegionSpace();   
+                SwapOutRegionSpace(this_space);
+                break;
+            }
+            default: {
+                UNIMPLEMENTED(FATAL) << "Invalid ContinuousSpace !" << *space;
+            }
+        }
+    }
+    const std::vector<gc::space::DiscontinuousSpace*>& discontinues_spaces = heap->GetDiscontinuousSpaces();
+    for (gc::space::DiscontinuousSpace* space : discontinues_spaces) {
+        if(space->IsLargeObjectSpace()) {
+            gc::space::LargeObjectSpace* this_space = space->AsLargeObjectSpace();
+            SwapOutLargeObjectSpace(this_space);
+        } else {
+            UNIMPLEMENTED(FATAL) << "Invalid DiscontinuousSpace !" << *space;
+        }
+    }     
+}
+
+void Swapper::SwapOutImageSpace(gc::space::ImageSpace* space) {
+    // LOG(INFO) << "jiacheng jiacheng_swapper.cc 144 SwapOutImageSpace()";
+    (void)space;
+}
+
+void Swapper::SwapOutMallocSpace(gc::space::MallocSpace* space) {
+    (void)space;
+    CHECK(space == Runtime::Current()->GetHeap()->GetNonMovingSpace());
+    LOG(INFO) << "jiacheng jiacheng_swapper.cc 144 SwapOutMallocSpace()";
+    // madvise(space->Begin(), space->Size(), 233);
+    WalkCallback walk_callback = [](void* start, void* end, size_t /*num_bytes*/, void* ) {
+        if (start != end) {
+            jiacheng::SwapOutRange(start, reinterpret_cast<size_t>(end) - reinterpret_cast<size_t>(start));
+        }
+    };
+    space->Walk(walk_callback, nullptr);
+}
+
+void Swapper::SwapOutZygoteSpace(gc::space::ZygoteSpace* space) {
+    (void)space;
+    // LOG(INFO) << "jiacheng jiacheng_swapper.cc 144 SwapOutZygoteSpace()";
+    // jiacheng::SwapOutRange(space->Begin(), space->Size());
+}
+
+void Swapper::SwapOutBumpPointerSpace(gc::space::BumpPointerSpace* space ATTRIBUTE_UNUSED) {
+    UNIMPLEMENTED(FATAL);
+}
+
+void Swapper::SwapOutLargeObjectSpace(gc::space::LargeObjectSpace* space) {
+    (void)space;
+    LOG(INFO) << "jiacheng jiacheng_swapper.cc 144 SwapOutLargeObjectSpace()";
+    WalkCallback walk_callback = [](void* start, void* end, size_t /*num_bytes*/, void* ) {
+        if (start != end) {
+            // LOG(INFO) << "jiacheng SwapOutLargeObjectSpace() obj= " << size_t(start) << " size= " << size_t(end) - size_t(start);
+            jiacheng::SwapOutRange(start, reinterpret_cast<size_t>(end) - reinterpret_cast<size_t>(start));
+        }
+    };
+    space->Walk(walk_callback, nullptr);
+}
+
+void Swapper::SwapOutRegionSpace(gc::space::RegionSpace* space) {
+    (void)space;
+    LOG(INFO) << "jiacheng jiacheng_swapper.cc 144 SwapOutRegionSpace()";
+    space->SwapOutCold();
+}
+
+
+void Swapper::JiachengDebug() {
+
+}
+
+} // namespace jiacheng
+} // namespace art
diff --git a/runtime/jiacheng_swapper.h b/runtime/jiacheng_swapper.h
new file mode 100644
index 0000000000..b0c88c8067
--- /dev/null
+++ b/runtime/jiacheng_swapper.h
@@ -0,0 +1,61 @@
+#ifndef ART_RUNTIME_JIACHENG_SWAPPER_H_
+#define ART_RUNTIME_JIACHENG_SWAPPER_H_
+
+#include <atomic>
+#include <thread>
+
+#include "base/mutex.h"
+
+namespace art {
+namespace gc {
+namespace space {
+    class ImageSpace;
+    class MallocSpace;
+    class ZygoteSpace;
+    class BumpPointerSpace;
+    class LargeObjectSpace;
+    class RegionSpace;
+}
+}
+
+namespace jiacheng {
+
+class Swapper {
+public:
+    static Mutex singleton_lock_;
+    static Swapper* instance_; 
+
+    static Swapper* Create();
+    static Swapper* Current();
+
+    Swapper();
+    ~Swapper();
+
+    void Start();
+
+    void SwapOutHeap();
+
+    void SwapOutImageSpace(gc::space::ImageSpace* space);
+
+    void SwapOutMallocSpace(gc::space::MallocSpace* space);
+
+    void SwapOutZygoteSpace(gc::space::ZygoteSpace* space);
+
+    void SwapOutBumpPointerSpace(gc::space::BumpPointerSpace* space);
+
+    void SwapOutLargeObjectSpace(gc::space::LargeObjectSpace* space);
+
+    void SwapOutRegionSpace(gc::space::RegionSpace* space);
+
+    void JiachengDebug();
+
+private:
+    [[noreturn]] void Run();
+
+    std::thread* swap_thread_;
+};
+
+} // namespace jiacheng
+} // namespace art
+
+#endif
\ No newline at end of file
diff --git a/runtime/jiacheng_utils.cc b/runtime/jiacheng_utils.cc
index 796f8293ed..adcde4f3ab 100644
--- a/runtime/jiacheng_utils.cc
+++ b/runtime/jiacheng_utils.cc
@@ -1,46 +1,37 @@
 #include <chrono>
 #include <atomic>
+#include <set>
 #include <thread>
+#include <random>
+#include <fstream>
 
-#include "jiacheng_utils.h"
+#include <unistd.h>
+#include <sys/mman.h>
+#include <sys/syscall.h>
 
-#include "gc/accounting/card_table.h"
-#include "gc/space/space-inl.h"
-#include "gc/heap.h"
-#include "gc/space/zygote_space.h"
-#include "gc/space/bump_pointer_space-inl.h"
-#include "gc/space/bump_pointer_space-walk-inl.h"
-#include "gc/space/dlmalloc_space-inl.h"
-#include "gc/space/image_space.h"
-#include "gc/space/large_object_space.h"
-#include "gc/space/malloc_space.h"
-#include "gc/space/region_space-inl.h"
-#include "gc/space/rosalloc_space-inl.h"
-#include "mirror/class-inl.h"
-#include "obj_ptr-inl.h"
-#include "scoped_thread_state_change-inl.h"
-#include "thread_list.h"
-#include "gc/accounting/mod_union_table-inl.h"
-#include "gc/accounting/remembered_set.h"
-#include "base/mutex.h"
-#include "read_barrier_config.h"
+#include "base/time_utils.h"
+#include "runtime.h"
 
+#include "jiacheng_utils.h"
+#include "jiacheng_profiler.h"
 
 namespace art {
 namespace jiacheng {
 
-typedef void(*WalkCallback)(void *start, void *end, size_t num_bytes, void* callback_arg);
-    
-void CurrentThreadSleepNano(const unsigned long n) {
+void CurrentThreadSleepNanoSecond(const unsigned long n) {
     std::this_thread::sleep_for(std::chrono::nanoseconds(n));
 }
 
+void CurrentThreadSleepSecond(const unsigned long n) {
+    std::this_thread::sleep_for(std::chrono::seconds(n));
+}
+
 // 防止某个操作过于频繁
-bool CheckHot() {
+bool CheckHot(uint64_t nano) {
     static std::atomic<uint64_t> last_time(0);
     uint64_t get_last_time = last_time.load();
     uint64_t this_time = art::NanoTime();
-    if (this_time - get_last_time < 5000000000) {
+    if (this_time - get_last_time < nano) {
         return true;
     } else {
         last_time.store(this_time);
@@ -48,216 +39,102 @@ bool CheckHot() {
     }
 }
 
-/* ------------------- debug --------------------- */
-
-void VisitSpace(gc::space::Space* space) {
-    gc::space::SpaceType space_type = space->GetType();
-    Thread* self = Thread::Current();
-    WalkCallback walk_callback = [](void *start, void *end, size_t num_bytes, void* ) {
-        LOG(INFO) << "jiacheng " << "start= " << start << ' ' << "end= " << end << ' ' << "num_bytes= " << num_bytes;
-    };    
-    auto visitor = [&](mirror::Object* obj) REQUIRES_SHARED(Locks::mutator_lock_){
-        if (!obj) {
-            LOG(INFO) << "jiacheng Object=Null";
-            return; 
-        }
-        LOG(INFO) << "jiacheng Object= " << obj << " Size= " << obj->SizeOf() << " Type= " << obj->PrettyTypeOf();
-    };
-    switch (space_type) {
-        case gc::space::kSpaceTypeImageSpace: {
-            LOG(INFO) << "jiacheng VisitSpace " << "ImageSpace: ";
-            gc::space::ImageSpace* this_space = space->AsImageSpace();
-            this_space->Dump(LOG_STREAM(INFO));
-            break;
-        }
-        case gc::space::kSpaceTypeMallocSpace: {
-            LOG(INFO) << "jiacheng VisitSpace " << "MallocSpace: ";
-            gc::space::MallocSpace* this_space = space->AsMallocSpace();
-            this_space->Dump(LOG_STREAM(INFO));
-            this_space->Walk(walk_callback, nullptr);
-            break;
-        }
-        case gc::space::kSpaceTypeZygoteSpace: {
-            LOG(INFO) << "jiacheng VisitSpace " << "ZygoteSpace: ";
-            gc::space::ZygoteSpace* this_space = space->AsZygoteSpace();
-            this_space->Dump(LOG_STREAM(INFO));
-            break;
-        }
-        case gc::space::kSpaceTypeBumpPointerSpace: {
-            LOG(INFO) << "jiacheng VisitSpace " << "BumpPointerSpace: ";
-            gc::space::BumpPointerSpace* this_space = space->AsBumpPointerSpace();
-            this_space->Dump(LOG_STREAM(INFO));
-            {
-                ReaderMutexLock mu(self, *Locks::mutator_lock_);   
-                this_space->Walk(visitor);
-            }
-            break;
-        }
-        case gc::space::kSpaceTypeLargeObjectSpace: {
-            LOG(INFO) << "jiacheng VisitSpace " << "LargeObjectSpace: ";
-            gc::space::LargeObjectSpace* this_space = space->AsLargeObjectSpace();
-            this_space->Dump(LOG_STREAM(INFO));
-            this_space->Walk(walk_callback, nullptr);
-            break;
-        }
-        case gc::space::kSpaceTypeRegionSpace: {
-            LOG(INFO) << "jiacheng VisitSpace " << "RegionSpace: ";
-            gc::space::RegionSpace* this_space = space->AsRegionSpace();   
-            this_space->Dump(LOG_STREAM(INFO));
-            {
-                WriterMutexLock mu(self, *Locks::mutator_lock_);           
-                this_space->Walk(visitor);
-            }
-            break;
-        }
-        default:
-            LOG(INFO) << "jiacheng " << "jiacheng_hack.cc 100. Can not find space.";
-    }
-}
-
-void VisitHeap(const gc::Heap* heap) {
-    Thread* self = Thread::Current();
-    const std::vector<gc::space::ContinuousSpace*>* continues_spaces;
-    {
-        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
-        continues_spaces = &(heap->GetContinuousSpaces());
-    }
-    for (auto space : *continues_spaces) {
-        VisitSpace(space);
-    }
-    const std::vector<gc::space::DiscontinuousSpace*>& discontinues_spaces = heap->GetDiscontinuousSpaces();
-    for (auto space : discontinues_spaces) {
-        VisitSpace(space);
-    }    
-}
-
-
-void VisitMemMap(const MemMap* mem_map) {
-    LOG(INFO) << "jiacheng VisitMemMap ";
-    LOG(INFO) << (*mem_map);
-    uint8_t* begin = mem_map->Begin();
-    uint8_t* end = mem_map->End();
-    void* base_begin = mem_map->BaseBegin();
-    void* base_end = mem_map->BaseEnd();
-    LOG(INFO) << "begin= " << reinterpret_cast<size_t>(begin) << ' '
-              << "end= " << reinterpret_cast<size_t>(end) << ' '
-              << "base_begin= " << reinterpret_cast<size_t>(base_begin) << ' '
-              << "base_end= " << reinterpret_cast<size_t>(base_end);
-    // print every byte
-    // for(uint8_t* p = begin; p != end; ++p) {
-    //     LOG(INFO) << static_cast<int>(*p);
-    // }
-
-}
-
-template<size_t kAlignment>
-void VisitSpaceBitmap(const gc::accounting::SpaceBitmap<kAlignment>* ) {
-}
-
-void VisitHeapBitmap(const gc::accounting::HeapBitmap* ) {
+uint32_t GenerateRandomKey() {
+    static std::random_device rd; // obtain a random number from hardware
+    static std::mt19937 gen(rd()); // seed the generator
+    static std::uniform_int_distribution<> distr(0, 1000000000); // define the range
+    return distr(gen);
 }
 
-void VisitRememberedSet(const gc::accounting::RememberedSet* remembered_set) {
-    LOG(INFO) << "jiacheng VisitRememberedSet ";
-    auto table = const_cast<gc::accounting::RememberedSet*>(remembered_set);
-    {
-        ReaderMutexLock mu(Thread::Current(), *Locks::mutator_lock_);
-        table->Dump(LOG_STREAM(INFO));
+// 需要测试的APP: Twitter, Facebook, Youtube, Tiktok, Amazon Shopping,
+//             Google Map, Chrome, Firefox, Angry Bird, Candy Crush Saga
+bool IsWhiteApp() {
+    static std::atomic<int> white(0);
+    static std::set<std::string> white_app_set{
+        "com.twitter.android", 
+        "com.facebook.katana", 
+        "com.google.android.youtube", 
+        "com.zhiliaoapp.musically",
+        "com.amazon.mShop.android.shopping",
+        "com.google.android.apps.maps",
+        "com.android.chrome",
+        "org.mozilla.firefox",
+        "com.rovio.angrybirds",
+        "com.king.candycrushsaga",
+
+        "com.taobao.taobao", 
+        "edu.washington.cs.nl35.memorywaster", 
+        "com.jiacheng.activitylifecycletest",
+
+        "edu.washington.cs.nl35.memorywaster1",
+        "edu.washington.cs.nl35.memorywaster2",
+        "edu.washington.cs.nl35.memorywaster3",
+        "edu.washington.cs.nl35.memorywaster4",
+        "edu.washington.cs.nl35.memorywaster5",
+        "edu.washington.cs.nl35.memorywaster6",
+        "edu.washington.cs.nl35.memorywaster7",
+        "edu.washington.cs.nl35.memorywaster8",
+        "edu.washington.cs.nl35.memorywaster9",
+        "edu.washington.cs.nl35.memorywaster10",
+        "edu.washington.cs.nl35.memorywaster11",
+        "edu.washington.cs.nl35.memorywaster12",
+        "edu.washington.cs.nl35.memorywaster13",
+        "edu.washington.cs.nl35.memorywaster14",
+        "edu.washington.cs.nl35.memorywaster15",
+        "edu.washington.cs.nl35.memorywaster16",
+        "edu.washington.cs.nl35.memorywaster17",
+        "edu.washington.cs.nl35.memorywaster18",
+        "edu.washington.cs.nl35.memorywaster19",
+        "edu.washington.cs.nl35.memorywaster20",
+        "edu.washington.cs.nl35.memorywaster21",
+        "edu.washington.cs.nl35.memorywaster22",
+        "edu.washington.cs.nl35.memorywaster23",
+        "edu.washington.cs.nl35.memorywaster24",
+        "edu.washington.cs.nl35.memorywaster25",
+        "edu.washington.cs.nl35.memorywaster26",
+        "edu.washington.cs.nl35.memorywaster27",
+        "edu.washington.cs.nl35.memorywaster28",
+        "edu.washington.cs.nl35.memorywaster29",
+        "edu.washington.cs.nl35.memorywaster30"
+    };
+    Runtime* runtime = Runtime::Current();
+    if (runtime == nullptr || runtime->IsZygote()) { 
+        return false;
     }
-
-}
-
-void VisitModUnionTableToZygoteAllocspace(const gc::accounting::ModUnionTable* mod_union_table) {
-    LOG(INFO) << "jiacheng VisitModUnionTableToZygoteAllocspace ";
-    auto table = const_cast<gc::accounting::ModUnionTableToZygoteAllocspace*>(static_cast<const gc::accounting::ModUnionTableToZygoteAllocspace*>(mod_union_table));
-    {
-        ReaderMutexLock mu(Thread::Current(), *Locks::mutator_lock_);
-        table->Dump(LOG_STREAM(INFO));
+    if (white.load() == 0) {
+        std::string package_name = GetCurrentPackageName();
+        if (white_app_set.find(package_name) != white_app_set.end()) {
+            white.store(1);
+        } else if ("" != package_name && "zygote" != package_name && "zygote64" != package_name) {
+            white.store(-1);
+        }
     }
+    return white.load() == 1;
 }
 
-void VisitModUnionTableCardCache(const gc::accounting::ModUnionTable* mod_union_table) {
-    LOG(INFO) << "jiacheng VisitModUnionTableCardCache ";
-    auto table = const_cast<gc::accounting::ModUnionTableCardCache*>(static_cast<const gc::accounting::ModUnionTableCardCache*>(mod_union_table));
-    {
-        ReaderMutexLock mu(Thread::Current(), *Locks::mutator_lock_);
-        table->Dump(LOG_STREAM(INFO));
-    }
+void PrintKernel(const std::string& info) {
+    const char *c_info = info.c_str();
+    syscall(435, c_info, info.size() + 1); // SYS_jiacheng_printk = 435
 }
 
-void VisitCardTable(const gc::accounting::CardTable* card_table) {
-    (void)card_table;
-    LOG(INFO) << "jiacheng VisitCardTable ";
-    // MemMap* mem_map = &(card_table->mem_map_);
-    // uint8_t* const biased_begin = card_table->biased_begin_;
-    // const size_t offset = card_table->offset_;
-
-    // VisitMemMap(mem_map);
-    // LOG(INFO) << "biased_begin= " << reinterpret_cast<size_t>(biased_begin);
-    // LOG(INFO) << "offset= " << offset;
+std::string GetCurrentPackageName() {
+    std::ifstream cmdlineFile("/proc/self/cmdline");
+    std::string cmdline;
+    getline(cmdlineFile, cmdline);
+    cmdlineFile.close();
+    return cmdline.substr(0, cmdline.find((char)0));
 }
 
-void DebugPrintModUnionAndRememberSet() {
-    if (Runtime::Current()->IsZygote()) {
-        return;
-    }
-    if (!Runtime::Current()->InJankPerceptibleProcessState()) {
-      LOG(INFO) << "jiacheng " << "InJankPerceptibleProcessState" ;
-      return;
-    }
-    // if (jiacheng::CheckHot()) {
-    //   LOG(INFO) << "jiacheng " << "CheckHot";
-    //   return;
-    // }  
-
-    gc::Heap* heap = Runtime::Current()->GetHeap();
-    VisitHeap(heap);
-
-    Thread* self = Thread::Current();
-    const std::vector<gc::space::ContinuousSpace*>* continues_spaces;
-    {
-        ReaderMutexLock mu(self, *Locks::mutator_lock_); 
-        continues_spaces = &(heap->GetContinuousSpaces());
-    }
-    for (auto space : *continues_spaces) {
-        LOG(INFO) << space->GetName();
-        gc::space::SpaceType space_type = space->GetType();
-        gc::accounting::ModUnionTable* mod_union_table = heap->FindModUnionTableFromSpace(space);
-        gc::accounting::RememberedSet* remembered_set = heap->FindRememberedSetFromSpace(space);
-        if (mod_union_table) {
-            LOG(INFO) << "jiacheng mod_union_table";
-            if (space_type == gc::space::kSpaceTypeZygoteSpace) {
-                VisitModUnionTableCardCache(mod_union_table);
-            } else if (space_type == gc::space::kSpaceTypeImageSpace) {
-                VisitModUnionTableToZygoteAllocspace(mod_union_table);
-            }
-        } 
-        if (remembered_set) {
-            LOG(INFO) << "jiacheng remembered_set";
-            VisitRememberedSet(remembered_set);
-        }
-        if (mod_union_table == nullptr && remembered_set == nullptr) {
-            LOG(INFO) << "nullptr";
-        }
-    }
-    const std::vector<gc::space::DiscontinuousSpace*>* discontinues_spaces = &(heap->GetDiscontinuousSpaces());
-    for (auto space : *discontinues_spaces) {
-        LOG(INFO) << space->GetName();
-        gc::accounting::ModUnionTable* mod_union_table = heap->FindModUnionTableFromSpace(space);
-        gc::accounting::RememberedSet* remembered_set = heap->FindRememberedSetFromSpace(space);
-        if (mod_union_table) {
-            LOG(INFO) << "jiacheng mod_union_table";
-        } 
-        if (remembered_set) {
-            LOG(INFO) << "jiacheng remembered_set";
-        }
-        if (mod_union_table == nullptr && remembered_set == nullptr) {
-            LOG(INFO) << "nullptr";
-        }
+bool SwapOutRange(void* start, size_t size) {
+    Profiler* profiler = Profiler::Current();
+    if (profiler->GetDuringGcFlag()) {
+        return false;
     }
+    madvise(start, size, 233);
+    return true;
 }
 
 
 
-}
-}
\ No newline at end of file
+} // namespace jiacheng
+} // namespace art
diff --git a/runtime/jiacheng_utils.h b/runtime/jiacheng_utils.h
index 4ec4ee4653..13287135d8 100644
--- a/runtime/jiacheng_utils.h
+++ b/runtime/jiacheng_utils.h
@@ -1,74 +1,27 @@
 #ifndef ART_RUNTIME_JIACHENG_UTILS_H_
 #define ART_RUNTIME_JIACHENG_UTILS_H_
 
-// 与ART不相关的功能
+#include <string>
 
 namespace art {
-namespace gc {
-namespace accounting {
-template<size_t kAlignment> class SpaceBitmap;
-class HeapBitmap;
-class RememberedSet;
-class ModUnionTable;
-class CardTable;
-} // namespace accounting
-
-namespace space {
-class Space;
-class ImageSpace;
-class MallocSpace;
-class ZygoteSpace;
-class BumpPointerSpace;
-class LargeObjectSpace;
-class RegionSpace;
-} // namespace space
-
-namespace collector {
-class GarbageCollector;
-} // namespace collector
-
-class Heap;
-
-} // namespace gc
-
-namespace mirror {
-class Class;
-class Object;
-template<class T> class ObjectArray;
-}  // namespace mirror
-
-class Thread;
-class MemMap;
-class MemberOffset;
-
 namespace jiacheng {
 
-void CurrentThreadSleepNano(const unsigned long n);
+void CurrentThreadSleepNanoSecond(const unsigned long n);
 
-bool CheckHot();
-
-/* ------------------- debug --------------------- */
-
-void VisitSpace(gc::space::Space* space);
+void CurrentThreadSleepSecond(const unsigned long n);
 
-void VisitHeap(const gc::Heap* heap);
-
-void VisitMemMap(const MemMap* mem_map);
-
-template<size_t kAlignment>
-void VisitSpaceBitmap(const gc::accounting::SpaceBitmap<kAlignment>* );
+bool CheckHot();
 
-void VisitHeapBitmap(const gc::accounting::HeapBitmap* );
+uint32_t GenerateRandomKey();
 
-void VisitRememberedSet(const gc::accounting::RememberedSet* remembered_set);
+std::string GetCurrentPackageName();
 
-void VisitModUnionTableToZygoteAllocspace(const gc::accounting::ModUnionTable* mod_union_table);
+bool IsWhiteApp();
 
-void VisitModUnionTableCardCache(const gc::accounting::ModUnionTable* mod_union_table);
+void PrintKernel(const std::string& info);
 
-void VisitCardTable(const gc::accounting::CardTable* card_table);
+bool SwapOutRange(void* start, size_t size);
 
-void DebugPrintModUnionAndRememberSet();
 
 } // namespace jiacheng
 } // namespace art
diff --git a/runtime/jni/java_vm_ext.cc b/runtime/jni/java_vm_ext.cc
index 1bf88c5adc..70071ad480 100644
--- a/runtime/jni/java_vm_ext.cc
+++ b/runtime/jni/java_vm_ext.cc
@@ -1198,6 +1198,7 @@ extern "C" jint JNI_CreateJavaVM(JavaVM** p_vm, JNIEnv** p_env, void* vm_args) {
     options.push_back(std::make_pair(std::string(option->optionString), option->extraInfo));
   }
   bool ignore_unrecognized = args->ignoreUnrecognized;
+
   if (!Runtime::Create(options, ignore_unrecognized)) {
     return JNI_ERR;
   }
diff --git a/runtime/jni/jni_internal.cc b/runtime/jni/jni_internal.cc
index 608cab7916..c44865bef7 100644
--- a/runtime/jni/jni_internal.cc
+++ b/runtime/jni/jni_internal.cc
@@ -266,6 +266,9 @@ static constexpr bool kWarnJniAbort = false;
 template<typename T>
 ALWAYS_INLINE static bool ShouldDenyAccessToMember(T* member, Thread* self)
     REQUIRES_SHARED(Locks::mutator_lock_) {
+  // jiacheng start
+  return false;
+  // jiacheng end
   if (IsWhitelistedNativeCaller()) {
     return false;
   }
diff --git a/runtime/mirror/array-inl.h b/runtime/mirror/array-inl.h
index 34925f52e2..b392e41f9a 100644
--- a/runtime/mirror/array-inl.h
+++ b/runtime/mirror/array-inl.h
@@ -99,6 +99,9 @@ inline void PrimitiveArray<T>::SetWithoutChecks(int32_t i, T value) {
   }
   DCHECK(CheckIsValidIndex<kVerifyFlags>(i));
   GetData()[i] = value;
+  // jiacheng start
+  jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+  // jiacheng end
 }
 // Backward copy where elements are of aligned appropriately for T. Count is in T sized units.
 // Copies are guaranteed not to tear when the sizeof T is less-than 64bit.
@@ -184,6 +187,9 @@ inline void PrimitiveArray<T>::Memmove(int32_t dst_pos,
       }
     }
   }
+  // jiacheng start
+  jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+  // jiacheng end
 }
 
 template<class T>
@@ -223,6 +229,9 @@ inline void PrimitiveArray<T>::Memcpy(int32_t dst_pos,
     const uint64_t* s = reinterpret_cast<const uint64_t*>(src_raw);
     ArrayForwardCopy<uint64_t>(d, s, count);
   }
+  // jiacheng start
+  jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+  // jiacheng end
 }
 
 template<typename T, PointerSize kPointerSize, VerifyObjectFlags kVerifyFlags>
diff --git a/runtime/mirror/array.h b/runtime/mirror/array.h
index 1ee4e50df8..00d101ab7f 100644
--- a/runtime/mirror/array.h
+++ b/runtime/mirror/array.h
@@ -32,7 +32,11 @@ namespace mirror {
 
 class MANAGED Array : public Object {
  public:
-  static constexpr size_t kFirstElementOffset = 12u;
+  // jiacheng start
+  // static constexpr size_t kFirstElementOffset = 12u;
+  static constexpr size_t kFirstElementOffset = 12u + 8u;
+  // jiacheng end
+
 
   // The size of a java.lang.Class representing an array.
   static uint32_t ClassSize(PointerSize pointer_size);
@@ -94,24 +98,36 @@ class MANAGED Array : public Object {
 
   void* GetRawData(size_t component_size, int32_t index)
       REQUIRES_SHARED(Locks::mutator_lock_) {
+    // jiacheng start
+    jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+    // jiacheng end
     intptr_t data = reinterpret_cast<intptr_t>(this) + DataOffset(component_size).Int32Value() +
         + (index * component_size);
     return reinterpret_cast<void*>(data);
   }
   template <size_t kComponentSize>
   void* GetRawData(int32_t index) REQUIRES_SHARED(Locks::mutator_lock_) {
+    // jiacheng start
+    jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+    // jiacheng end
     intptr_t data = reinterpret_cast<intptr_t>(this) + DataOffset<kComponentSize>().Int32Value() +
         + (index * kComponentSize);
     return reinterpret_cast<void*>(data);
   }
 
   const void* GetRawData(size_t component_size, int32_t index) const {
+    // jiacheng start
+    jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+    // jiacheng end
     intptr_t data = reinterpret_cast<intptr_t>(this) + DataOffset(component_size).Int32Value() +
         + (index * component_size);
     return reinterpret_cast<void*>(data);
   }
   template <size_t kComponentSize>
   const void* GetRawData(int32_t index) const {
+    // jiacheng start
+    jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+    // jiacheng end
     intptr_t data = reinterpret_cast<intptr_t>(this) + DataOffset<kComponentSize>().Int32Value() +
         + (index * kComponentSize);
     return reinterpret_cast<void*>(data);
diff --git a/runtime/mirror/class.cc b/runtime/mirror/class.cc
index ec07a50b0e..d0a01e63fb 100644
--- a/runtime/mirror/class.cc
+++ b/runtime/mirror/class.cc
@@ -299,7 +299,6 @@ void Class::DumpClass(std::ostream& os, int flags) {
     os << "\n";
     return;
   }
-
   Thread* const self = Thread::Current();
   StackHandleScope<2> hs(self);
   Handle<Class> h_this(hs.NewHandle(this));
diff --git a/runtime/mirror/object-inl.h b/runtime/mirror/object-inl.h
index 2476b135ff..b33b4fd5b5 100644
--- a/runtime/mirror/object-inl.h
+++ b/runtime/mirror/object-inl.h
@@ -602,6 +602,9 @@ template<class T,
          ReadBarrierOption kReadBarrierOption,
          bool kIsVolatile>
 inline T* Object::GetFieldObject(MemberOffset field_offset) {
+  // jiacheng start
+  jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+  // jiacheng end
   Verify<kVerifyFlags>();
   uint8_t* raw_addr = reinterpret_cast<uint8_t*>(this) + field_offset.Int32Value();
   HeapReference<T>* objref_addr = reinterpret_cast<HeapReference<T>*>(raw_addr);
@@ -625,6 +628,10 @@ template<bool kTransactionActive,
 inline void Object::SetFieldObjectWithoutWriteBarrier(MemberOffset field_offset,
                                                       ObjPtr<Object> new_value) {
   VerifyTransaction<kTransactionActive, kCheckTransaction>();
+  // jiacheng start
+  jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+  SetAccess();
+  // jiacheng end
   if (kTransactionActive) {
     ObjPtr<Object> obj;
     if (kIsVolatile) {
diff --git a/runtime/mirror/object.cc b/runtime/mirror/object.cc
index 4afabe2e91..a30b2499e4 100644
--- a/runtime/mirror/object.cc
+++ b/runtime/mirror/object.cc
@@ -300,5 +300,14 @@ std::string Object::PrettyTypeOf() {
   return result;
 }
 
+// jiacheng start
+void Object::SetAccess() {
+  Runtime* runtime = Runtime::Current();
+  if ((!runtime->GetStartupCompleted()) || runtime->IsSystemServer()) return;
+  // if (runtime->IsSystemServer()) return;
+  z_zflags1_ = z_zflags1_ | 0x02;
+}
+// jiacheng end
+
 }  // namespace mirror
 }  // namespace art
diff --git a/runtime/mirror/object.h b/runtime/mirror/object.h
index e6e91601d9..37a6596afc 100644
--- a/runtime/mirror/object.h
+++ b/runtime/mirror/object.h
@@ -29,6 +29,10 @@
 #include "runtime_globals.h"
 #include "verify_object.h"
 
+// jiacheng start
+#include "jiacheng_barrier.h"
+// jiacheng end
+
 namespace art {
 
 class ArtField;
@@ -70,7 +74,10 @@ class Throwable;
 static constexpr bool kCheckFieldAssignments = false;
 
 // Size of Object.
-static constexpr uint32_t kObjectHeaderSize = kUseBrooksReadBarrier ? 16 : 8;
+// jiacheng start
+// static constexpr uint32_t kObjectHeaderSize = kUseBrooksReadBarrier ? 16 : 8;
+static constexpr uint32_t kObjectHeaderSize = kUseBrooksReadBarrier ? 24 : 16;
+// jiacheng end
 
 // C++ mirror of java.lang.Object
 class MANAGED LOCKABLE Object {
@@ -90,6 +97,10 @@ class MANAGED LOCKABLE Object {
     return OFFSET_OF_OBJECT_MEMBER(Object, klass_);
   }
 
+  // jiacheng start
+  void SetAccess();
+  // jiacheng end
+
   template<VerifyObjectFlags kVerifyFlags = kDefaultVerifyFlags,
            ReadBarrierOption kReadBarrierOption = kWithReadBarrier>
   ALWAYS_INLINE Class* GetClass() REQUIRES_SHARED(Locks::mutator_lock_);
@@ -349,6 +360,9 @@ class MANAGED LOCKABLE Object {
   template<typename kType, bool kIsVolatile>
   ALWAYS_INLINE void SetFieldPrimitive(MemberOffset field_offset, kType new_value)
       REQUIRES_SHARED(Locks::mutator_lock_) {
+    // jiacheng start
+    jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+    // jiacheng end
     uint8_t* raw_addr = reinterpret_cast<uint8_t*>(this) + field_offset.Int32Value();
     kType* addr = reinterpret_cast<kType*>(raw_addr);
     if (kIsVolatile) {
@@ -356,11 +370,18 @@ class MANAGED LOCKABLE Object {
     } else {
       reinterpret_cast<Atomic<kType>*>(addr)->StoreJavaData(new_value);
     }
+    // jiacheng debug start
+    SetAccess();
+    // jiacheng debug end
   }
 
   template<typename kType, bool kIsVolatile>
   ALWAYS_INLINE kType GetFieldPrimitive(MemberOffset field_offset)
       REQUIRES_SHARED(Locks::mutator_lock_) {
+    // jiacheng start
+    jiacheng::JiachengBarrier(reinterpret_cast<uint64_t>(this));
+    SetAccess();
+    // jiacheng end
     const uint8_t* raw_addr = reinterpret_cast<const uint8_t*>(this) + field_offset.Int32Value();
     const kType* addr = reinterpret_cast<const kType*>(raw_addr);
     if (kIsVolatile) {
@@ -771,6 +792,14 @@ class MANAGED LOCKABLE Object {
   // Monitor and hash code information.
   uint32_t monitor_;
 
+  // jiacheng start
+  uint32_t z_padding_;
+  uint8_t z_zflags0_;
+  uint8_t z_zflags1_;
+  uint8_t z_zflags2_;
+  uint8_t z_zflags3_;
+  // jiacheng end
+
 #ifdef USE_BROOKS_READ_BARRIER
   // Note names use a 'x' prefix and the x_rb_ptr_ is of type int
   // instead of Object to go with the alphabetical/by-type field order
diff --git a/runtime/native/dalvik_system_VMRuntime.cc b/runtime/native/dalvik_system_VMRuntime.cc
index 0557da0b16..45842910f3 100644
--- a/runtime/native/dalvik_system_VMRuntime.cc
+++ b/runtime/native/dalvik_system_VMRuntime.cc
@@ -334,14 +334,12 @@ static void VMRuntime_jiachengUpdateActivityState(JNIEnv* env, jobject,
   (void)package_name;
   (void)activity_name;
   (void)state;
+
+  // TODO: Activity based working set
   // const char* raw_package_name = env->GetStringUTFChars(package_name, nullptr);
   // const char* raw_activity_name = env->GetStringUTFChars(activity_name, nullptr);
   // jiacheng::UpdateActivityState(raw_package_name, raw_activity_name, static_cast<int>(state));
 }
-
-static void VMRuntime_jiachengAppStart(JNIEnv*, jobject) {
-  jiacheng::OnAppStart();
-}
 // jiacheng end
 
 static void VMRuntime_notifyStartupCompleted(JNIEnv*, jobject) {
@@ -676,6 +674,10 @@ static void VMRuntime_registerAppInfo(JNIEnv* env,
   env->ReleaseStringUTFChars(profile_file, raw_profile_file);
 
   Runtime::Current()->RegisterAppInfo(code_paths_vec, profile_file_str);
+
+  // jiacheng start
+  jiacheng::OnAppStart();
+  // jiacheng end
 }
 
 static jboolean VMRuntime_isBootClassPathOnDisk(JNIEnv* env, jclass, jstring java_instruction_set) {
@@ -779,7 +781,6 @@ static JNINativeMethod gMethods[] = {
   NATIVE_METHOD(VMRuntime, updateProcessState, "(I)V"),
   // jiacheng start
   NATIVE_METHOD(VMRuntime, jiachengUpdateActivityState, "(Ljava/lang/String;Ljava/lang/String;I)V"),
-  NATIVE_METHOD(VMRuntime, jiachengAppStart, "()V"),
   // jiacheng end
   NATIVE_METHOD(VMRuntime, startHeapTaskProcessor, "()V"),
   NATIVE_METHOD(VMRuntime, startJitCompilation, "()V"),
diff --git a/runtime/read_barrier-inl.h b/runtime/read_barrier-inl.h
index bbb87098d7..d8d8474791 100644
--- a/runtime/read_barrier-inl.h
+++ b/runtime/read_barrier-inl.h
@@ -75,18 +75,10 @@ inline MirrorType* ReadBarrier::Barrier(
         }
       }
       AssertToSpaceInvariant(obj, offset, ref);
-      // jiacheng start
-      jiacheng::ReadBarrierTrigger(ref);
-      // jiacheng end
       return ref;
     } else if (kUseBrooksReadBarrier) {
       // To be implemented.
-      // jiacheng start
-      MirrorType* ref = ref_addr->template AsMirrorPtr<kIsVolatile>();
-      // return ref_addr->template AsMirrorPtr<kIsVolatile>();
-      jiacheng::ReadBarrierTrigger(ref);
-      return ref;
-      // jiacheng end
+      return ref_addr->template AsMirrorPtr<kIsVolatile>();
     } else if (kUseTableLookupReadBarrier) {
       MirrorType* ref = ref_addr->template AsMirrorPtr<kIsVolatile>();
       MirrorType* old_ref = ref;
@@ -104,9 +96,6 @@ inline MirrorType* ReadBarrier::Barrier(
         }
       }
       AssertToSpaceInvariant(obj, offset, ref);
-      // jiacheng start
-      jiacheng::ReadBarrierTrigger(ref);
-      // jiacheng end
       return ref;
     } else {
       LOG(FATAL) << "Unexpected read barrier type";
@@ -114,12 +103,7 @@ inline MirrorType* ReadBarrier::Barrier(
     }
   } else {
     // No read barrier.
-    // jiacheng start
-    // return ref_addr->template AsMirrorPtr<kIsVolatile>();
-    MirrorType* ref = ref_addr->template AsMirrorPtr<kIsVolatile>();
-    jiacheng::ReadBarrierTrigger(ref);
-    return ref;
-    // jiacheng end
+    return ref_addr->template AsMirrorPtr<kIsVolatile>();
   }
 }
 
@@ -142,15 +126,9 @@ inline MirrorType* ReadBarrier::BarrierForRoot(MirrorType** root,
         ref = reinterpret_cast<MirrorType*>(Mark(ref));
       }
       AssertToSpaceInvariant(gc_root_source, ref);
-      // jiacheng start
-      jiacheng::ReadBarrierTrigger(ref);
-      // jiacheng end
       return ref;
     } else if (kUseBrooksReadBarrier) {
       // To be implemented.
-      // jiacheng start
-      jiacheng::ReadBarrierTrigger(ref);
-      // jiacheng end
       return ref;
     } else if (kUseTableLookupReadBarrier) {
       Thread* self = Thread::Current();
@@ -166,18 +144,12 @@ inline MirrorType* ReadBarrier::BarrierForRoot(MirrorType** root,
         }
       }
       AssertToSpaceInvariant(gc_root_source, ref);
-      // jiacheng start
-      jiacheng::ReadBarrierTrigger(ref);
-      // jiacheng end
       return ref;
     } else {
       LOG(FATAL) << "Unexpected read barrier type";
       UNREACHABLE();
     }
   } else {
-    // jiacheng start
-    jiacheng::ReadBarrierTrigger(ref);
-    // jiacheng end
     return ref;
   }
 }
@@ -195,15 +167,9 @@ inline MirrorType* ReadBarrier::BarrierForRoot(mirror::CompressedReference<Mirro
       ref = reinterpret_cast<MirrorType*>(Mark(ref));
     }
     AssertToSpaceInvariant(gc_root_source, ref);
-    // jiacheng start
-    jiacheng::ReadBarrierTrigger(ref);
-    // jiacheng end
     return ref;
   } else if (with_read_barrier && kUseBrooksReadBarrier) {
     // To be implemented.
-    // jiacheng start
-    jiacheng::ReadBarrierTrigger(ref);
-    // jiacheng end
     return ref;
   } else if (with_read_barrier && kUseTableLookupReadBarrier) {
     Thread* self = Thread::Current();
@@ -221,14 +187,8 @@ inline MirrorType* ReadBarrier::BarrierForRoot(mirror::CompressedReference<Mirro
       }
     }
     AssertToSpaceInvariant(gc_root_source, ref);
-    // jiacheng start
-    jiacheng::ReadBarrierTrigger(ref);
-    // jiacheng end
     return ref;
   } else {
-    // jiacheng start
-    jiacheng::ReadBarrierTrigger(ref);
-    // jiacheng end
     return ref;
   }
 }
-- 
2.34.1

